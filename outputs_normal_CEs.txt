Early stopping at epoch 124. Loss did not improve for 10 epochs.
Generate examples Step 124, Loss 0.19943359327316285
Epoch: 0
Negative Examples
['a', 'aa', 'aaa', 'aab', 'aaba', 'ab', 'aba', 'abaab', 'abbaaaba', 'abbb', 'b', 'baaabb', 'bab', 'babaab', 'babbaba', 'babbbaa', 'bb', 'bba', 'bbaabaa', 'bbaabab', 'bbaabbaa', 'bbabaa', 'bbbabb', 'bbbbaa', 'bbbbba']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aab', '', 'abaabab', 'aabaabaab', 'ab', 'abababaab', 'abaab', 'aaabaaaab', 'abaab', 'aaababaab', 'aabaab', 'aabaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7825971245765686
Train Epoch 1, Loss 0.6958279013633728
Train Epoch 2, Loss 0.6178799867630005
Accuracy at epoch 0: 0.1083984375, total training samples: 12
Early stopping at epoch 155. Loss did not improve for 10 epochs.
Generate examples Step 155, Loss 0.2204600786551451
Epoch: 1
Negative Examples
[]

Positive Examples
['aaaaab', 'aaaab', 'aaaabaa', 'aaabaaab', 'aabbaa', 'aabbab', 'aabbb', 'ab', 'abaab', 'abababbb', 'abbabb', 'abbb', 'abbbab', 'b', 'baaabaa', 'baabaab', 'baabab', 'baabb', 'bab', 'babaabb', 'bb', 'bbaaaab', 'bbaab', 'bbab', 'bbabbabb', 'bbbaab', 'bbbbbab', 'bbbbbb']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaa', 'aaabaaba', 'aaabaaaba', 'aaaba', 'aabbaa', 'aaaaabb', 'aaaaaabb', 'aabababb', 'aabbab', 'abaaaabb', 'abaaaaabb', 'aabaaabb', 'aabbb', 'abaaaabb', 'ababb', 'aaaaababb', 'abababbb', 'ababababb', 'ababb', 'aaabababb', 'abbabb', 'aababaabb', 'aaaababb', 'aaaabaabb', 'abbb', 'b', 'aabaababb', 'abaaababb', 'abbbab', 'abb', 'aabaaabb', 'aaaababb', 'b', 'aaaabb', 'aaaaabb', 'abaababb', 'baaabaa', 'aaaaaaabb', 'aaaababb', 'abb', 'baabaab', 'aabaaaabb', 'aaababb', 'aaaaabb', 'baabab', 'b', 'aabaabb', 'abaabb', 'baabb', 'aaabb', 'aababb', 'aaaaaaabb', 'bab', 'ababababb', 'aababaabb', 'aaaababb', 'babaabb', 'abababb', 'aaaababb', 'aaaabb', 'bb', 'aabb', 'aaaabb', 'aababaabb', 'bbaaaab', 'abaaaabb', 'aaaabb', 'abaaabb', 'bbaab', 'aaaaaabb', 'aabb', 'aaabaabb', 'bbab', 'aaabb', 'abaaaabb', 'abababb', 'bbabbabb', 'aaaaaabb', 'aaaaabb', 'aababaabb', 'bbbaab', 'aabaababb', 'ababb', 'aaabababb', 'bbbbbab', 'aaaababb', 'aaabaaabb', 'abaabaabb', 'bbbbbb', 'aabaabb', 'aabaaaabb', 'ababababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.7472671071688334
Train Epoch 1, Loss 0.5313515365123749
Train Epoch 2, Loss 0.3673974672953288
Accuracy at epoch 1: 0.892578125, total training samples: 104
Early stopping at epoch 232. Loss did not improve for 10 epochs.
Generate examples Step 232, Loss 0.4526545553759955
Epoch: 2
Negative Examples
['a', 'aa', 'aaaaabab', 'aaabaa', 'aabaa', 'aababaa', 'abaa', 'abab', 'abababab', 'b', 'baa', 'baaabaa', 'baaabab', 'baababaa', 'bab', 'babaa', 'babab', 'bababab', 'babbabab', 'bbabab', 'bbbbabaa']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaabab', 'aaabab', 'ababaaaab', 'abababaab', 'abab', 'abababab', 'aaaaaaab', 'aaababaab', 'abababab', 'abababaab', 'aaababaab', 'aababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.2937732934951782
Train Epoch 1, Loss 1.1268129348754883
Train Epoch 2, Loss 0.996732234954834
Accuracy at epoch 2: 0.9091796875, total training samples: 116
Early stopping at epoch 240. Loss did not improve for 10 epochs.
Generate examples Step 240, Loss 0.3009711416183171
Epoch: 3
Negative Examples
['aabab', 'aabbabab', 'ab', 'abaaabab', 'abaabab', 'abab', 'abbabab', 'b', 'baaaabab', 'baabab', 'bab', 'babab', 'bababab', 'bbab', 'bbabab', 'bbababab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aabab', 'abaabaaab', 'abaaaaaab', 'abaababab', 'ab', 'abaaab', 'aabaaabab', 'aaaaabaab', 'abaaabab', 'abaababab', 'ababaaaab', 'abaaaaaab', 'abaabab', 'aaabaabab', 'aabaaaaab', 'aababaaab', 'abab', 'abaab', 'ababab', 'aaaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.8834280967712402
Train Epoch 1, Loss 0.7870711088180542
Train Epoch 2, Loss 0.7022764086723328
Accuracy at epoch 3: 0.7900390625, total training samples: 136
Early stopping at epoch 180. Loss did not improve for 10 epochs.
Generate examples Step 180, Loss 0.18516462028685196
Epoch: 4
Negative Examples
['aa', 'aaaa', 'aab', 'aabbaa', 'aabbaab', 'aabbb', 'abaab', 'abaabbb', 'abbaa', 'abbbbbb', 'b', 'bababbbb', 'bb', 'bbaabbb', 'bbabbbbb', 'bbb', 'bbbaab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['ab', 'abaabab', 'abbaabab', 'bab', 'bbbbaa']
Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aabaaaab', 'abaaaab', 'abababab', 'abaab', 'abababaab', 'abaabab', 'abaaaaab', 'abbaabab', 'aaabb', 'abaababb', 'aabaabb', 'bab', 'aaabaaabb', 'aabaaaabb', 'aaaababb', 'bbbbaa', 'ababaabb', 'ababb', 'abaababb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.6221619844436646
Train Epoch 1, Loss 0.6021422147750854
Train Epoch 2, Loss 0.5823557376861572
Accuracy at epoch 4: 0.658203125, total training samples: 156
Early stopping at epoch 176. Loss did not improve for 10 epochs.
Generate examples Step 176, Loss 0.19717344086048966
Epoch: 5
Negative Examples
['aaa', 'ababbb', 'abbabbbb']
Neg Neg Neg
Positive Examples
['aaaab', 'aabaab', 'aabbb', 'aabbbaa', 'ab', 'abaa', 'abaab', 'abaabaa', 'abab', 'abbaabbb', 'abbbbbb', 'b', 'baa', 'baaab', 'bab', 'babbabbb', 'bbab', 'bbbab', 'bbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbb', 'abb', 'abaaabb', 'aabababb', 'aabbbaa', 'aaaaaaabb', 'aabaabb', 'ababb', 'abaa', 'aabaaa', 'aaabaaaaa', 'aaaaaaaba', 'abaabaa', 'ababaaa', 'aaaabaaaa', 'abaaaaba', 'abbaabbb', 'abaaababb', 'aaabb', 'aaabaaabb', 'abbbbbb', 'aabaababb', 'aabaaabb', 'aaabababb', 'b', 'ababababb', 'aabaabb', 'abb', 'baa', 'abaababb', 'aababaabb', 'ababb', 'baaab', 'abaababb', 'abaabb', 'aaaaababb', 'bab', 'abaabb', 'aabb', 'aababb', 'babbabbb', 'aababaabb', 'aabaaaabb', 'abababb', 'bbab', 'b', 'ababababb', 'aabaabb', 'bbbab', 'aaabaabb', 'abaaaaabb', 'aabababb', 'bbbbab', 'aaabaabb', 'aaaaaaabb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5650494992733002
Train Epoch 1, Loss 0.46455010771751404
Train Epoch 2, Loss 0.3757290840148926
Accuracy at epoch 5: 0.8798828125, total training samples: 212
Early stopping at epoch 260. Loss did not improve for 10 epochs.
Generate examples Step 260, Loss 0.23352340451830647
Epoch: 6
Negative Examples
['aabbbab', 'ab', 'b']
Neg Neg Neg
Positive Examples
['abab', 'ababab', 'baabab', 'baababab', 'bab', 'babab', 'bababab', 'bbaabab', 'bbabab', 'bbbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ab', 'ababaab', 'aaaabaaab', 'aaaaaaab', 'baabab', 'aababaabb', 'aababb', 'aaababb', 'baababab', 'aaaaababb', 'aaabaabb', 'aaabb', 'bab', 'aaaaaabb', 'aabababb', 'ababaabb', 'babab', 'aabaaabb', 'aaaaababb', 'aababaabb', 'bababab', 'aaababb', 'aabababb', 'ababaabb', 'bbaabab', 'abababb', 'aabaababb', 'aaabb', 'bbabab', 'aaaababb', 'b', 'abaaababb', 'bbbbabab', 'aababb', 'aaabaabb', 'ababababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5438082069158554
Train Epoch 1, Loss 0.5064085572957993
Train Epoch 2, Loss 0.48489782214164734
Accuracy at epoch 6: 0.896484375, total training samples: 248
Early stopping at epoch 246. Loss did not improve for 10 epochs.
Generate examples Step 246, Loss 0.253838148194286
Epoch: 7
Negative Examples
['aaaabab', 'aaabbbab', 'abab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaabbab', 'aaabbab', 'aababbab', 'ababbab', 'abbab', 'baabab', 'babbab', 'bbaabab', 'bbabbab', 'bbbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabab', 'aaabaaaab', 'aaaaaaaab', 'abababaab', 'abab', 'ababaab', 'abaaaaaab', 'aaaaabab', 'aaaabbab', 'aaabababb', 'aaaababb', 'aaabaabb', 'aaabbab', 'aabaaaabb', 'abaaabb', 'aaabaabb', 'aababbab', 'aaaababb', 'aaaabaabb', 'aabaabb', 'ababbab', 'abaaaabb', 'abaaababb', 'aabababb', 'abbab', 'abb', 'abaaaabb', 'aaaabb', 'baabab', 'abababb', 'aaaabb', 'abaabaabb', 'babbab', 'b', 'aaaabaabb', 'aaaaaaabb', 'bbaabab', 'abababb', 'aabaaaabb', 'abaaaaabb', 'bbabbab', 'abaabaabb', 'abaababb', 'aababb', 'bbbabbab', 'aabb', 'ababababb', 'aaabaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5295266211032867
Train Epoch 1, Loss 0.4850369691848755
Train Epoch 2, Loss 0.45984041690826416
Accuracy at epoch 7: 0.8466796875, total training samples: 296
Early stopping at epoch 227. Loss did not improve for 10 epochs.
Generate examples Step 227, Loss 0.2817356060994299
Epoch: 8
Negative Examples
['b']
Neg
Positive Examples
['aabab', 'aabbabab', 'ab', 'abab', 'abbaaab', 'abbabab', 'baababaa', 'bab', 'babaabaa', 'babab', 'babbabab', 'bbabab', 'bbbbab', 'bbbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbabab', 'ababababb', 'abababb', 'aabb', 'abbaaab', 'aaabaaabb', 'abaababb', 'aabb', 'abbabab', 'ababb', 'aaaabb', 'abaababb', 'baababaa', 'abb', 'ababaabb', 'abaababb', 'bab', 'aaaabaabb', 'abb', 'aaabababb', 'babaabaa', 'aabaaaabb', 'aababaabb', 'abb', 'babab', 'aabababb', 'aabaaaabb', 'aaaaabb', 'babbabab', 'aaaababb', 'aaaaabb', 'aabaaaabb', 'bbabab', 'aabaaabb', 'abaabaabb', 'abaaababb', 'bbbbab', 'ababb', 'aabaababb', 'b', 'bbbbabab', 'abaabaabb', 'aabaababb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3682176470756531
Train Epoch 1, Loss 0.23576254397630692
Train Epoch 2, Loss 0.13267739489674568
Accuracy at epoch 8: 0.9033203125, total training samples: 340
Early stopping at epoch 380. Loss did not improve for 10 epochs.
Generate examples Step 380, Loss 0.7153006569919936
Epoch: 9
Negative Examples
['aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'b', 'baabab', 'bab', 'babaabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aabaabab', 'ababaab', 'abababab', 'abaaaaaab', 'aabab', 'abab', 'ababaab', 'abaaabab', 'ab', 'aabaaaab', 'ababaabab', 'aaaaabaab', 'abaabab', 'abaaaaaab', 'aabaab', 'aaaaaabab', 'abab', 'abaababab', 'abaaaabab', 'aaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 2.0598018169403076
Train Epoch 1, Loss 1.6405324935913086
Train Epoch 2, Loss 1.2973978519439697
Accuracy at epoch 9: 0.91015625, total training samples: 360
Early stopping at epoch 324. Loss did not improve for 10 epochs.
Generate examples Step 324, Loss 0.3421617437784488
Epoch: 10
Negative Examples
['aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'b', 'baabab', 'bab', 'babaabab', 'bbaabab', 'bbbaabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aabaabab', 'abaaaaaab', 'aabaab', 'abaabab', 'aabab', 'abaabab', 'aaaaabab', 'abaaabab', 'ab', 'aababaaab', 'aaaaaaab', 'aaaaabab', 'abaabab', 'aaaabaab', 'abaaaabab', 'aaabaabab', 'abab', '', 'aaababaab', 'aabababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.0242713689804077
Train Epoch 1, Loss 0.8220940828323364
Train Epoch 2, Loss 0.6719465851783752
Accuracy at epoch 10: 0.82421875, total training samples: 380
Early stopping at epoch 178. Loss did not improve for 10 epochs.
Generate examples Step 178, Loss 0.2255034111232065
Epoch: 11
Negative Examples
['aa', 'aaaaa', 'aabbabbb', 'aabbb', 'abaaaaa', 'ababaab', 'abbaaaab', 'abbabbb', 'b', 'baaaabbb', 'baab', 'bbbabaab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaabab', 'ab', 'abaa', 'abaaaab', 'abab', 'baaaab', 'baaaabaa', 'baabaa', 'bab', 'babab', 'babbab', 'bbabab', 'bbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ababaab', 'aaabaabab', 'aaaaab', 'abaaaaaab', 'abaa', 'aabababa', 'ababaaaba', 'aaabababa', 'baaaab', 'aaaaababb', 'abaaabb', 'aaabb', 'baaaabaa', 'abaaababb', 'aaaaabb', 'abaaaabb', 'baabaa', 'aaabababb', 'abb', 'abaaaaabb', 'bab', 'abaaabb', 'aaabb', 'aaaaabb', 'babab', 'abb', 'aaaaaaabb', 'abaaaabb', 'babbab', 'abaaabb', 'aaabaabb', 'aaaabaabb', 'bbabab', 'abababb', 'abaabaabb', 'abaaabb', 'bbabbab', 'aaaaaaabb', 'abaabaabb', 'ababababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.49064864218235016
Train Epoch 1, Loss 0.4513087123632431
Train Epoch 2, Loss 0.42347653210163116
Accuracy at epoch 11: 0.8740234375, total training samples: 420
Early stopping at epoch 206. Loss did not improve for 10 epochs.
Generate examples Step 206, Loss 0.2390213676408869
Epoch: 12
Negative Examples
['aa', 'abbaa', 'b', 'bababbaa']
Neg Neg Neg Neg
Positive Examples
['aaaabab', 'aaabab', 'aaabbbab', 'aabab', 'aababbab', 'aabbab', 'ab', 'abbab', 'baab', 'bab', 'bababab', 'bababbab', 'babbab', 'babbbbab', 'bbaabab', 'bbab', 'bbabaab', 'bbbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbbab', 'abaabb', 'ababaabb', 'aaabaabb', 'aababbab', 'aaabaaabb', 'abb', 'aabaababb', 'aabbab', 'abaabb', 'aaaaaabb', 'aabababb', 'abbab', 'aaaabb', 'aaaaabb', 'aaaaaabb', 'baab', 'abaabaabb', 'aaaababb', 'ababaaabb', 'bab', 'aaabaabb', 'ababaabb', 'b', 'bababab', 'abb', 'aaaaaaabb', 'aaaaabb', 'bababbab', 'abaababb', 'aabaaaabb', 'aaaaaaabb', 'babbab', 'aaaaaaabb', 'aaabaaabb', 'ababababb', 'babbbbab', 'aaaababb', 'aababaabb', 'aabb', 'bbaabab', 'ababb', 'aabb', 'ababaabb', 'bbab', 'aaaaaaabb', 'abaaababb', 'aaabaabb', 'bbabaab', 'aabb', 'abaaababb', 'aaabaabb', 'bbbabbab', 'abaaaaabb', 'abababb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3117431402206421
Train Epoch 1, Loss 0.17885837703943253
Train Epoch 2, Loss 0.08872604742646217
Accuracy at epoch 12: 0.8828125, total training samples: 476
Early stopping at epoch 442. Loss did not improve for 10 epochs.
Generate examples Step 442, Loss 0.9529671373001339
Epoch: 13
Negative Examples
['aaaaabab', 'aaaabab', 'aaabab', 'aaababab', 'aabab', 'aababab', 'abab', 'ababab', 'b', 'baababab', 'bab', 'babab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaabab', 'abaaaaab', 'aababaab', 'aaaaabaab', 'aaaabab', 'aabaaabab', 'ab', 'aaaabaaab', 'aaabab', 'aaabaab', 'aaaaabaab', 'abaaabab', 'aaababab', 'abaaabaab', 'aaaaabaab', 'ab', 'aabab', 'aab', 'aaabaaab', 'ab', 'aababab', 'aaabaab', 'aabaabaab', 'ababaabab', 'abab', 'aabaaabab', 'ababab', 'aaaaaab', 'ababab', 'aaabab', '', 'aabaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 2.277496576309204
Train Epoch 1, Loss 1.8114209175109863
Train Epoch 2, Loss 1.4150365591049194
Accuracy at epoch 13: 0.8994140625, total training samples: 508
Early stopping at epoch 391. Loss did not improve for 10 epochs.
Generate examples Step 391, Loss 0.3793056612948374
Epoch: 14
Negative Examples
['aaababab', 'aababab', 'ab', 'abab', 'ababab', 'abababab', 'b', 'baababab', 'bab', 'babab', 'bababab', 'bbababab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaababab', 'aabaaaaab', 'aabaaaab', 'aaaaabab', 'aababab', 'abaaabaab', 'ab', 'aaab', 'ab', 'aababaaab', 'aaabaaaab', 'aaababaab', 'abab', 'aababaab', 'aaaab', '', 'ababab', 'aaaaabab', 'aabababab', 'abaab', 'abababab', 'aababab', '', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.1181403398513794
Train Epoch 1, Loss 0.8892537951469421
Train Epoch 2, Loss 0.7217442393302917
Accuracy at epoch 14: 0.8310546875, total training samples: 532
Early stopping at epoch 246. Loss did not improve for 10 epochs.
Generate examples Step 246, Loss 0.3030995440024596
Epoch: 15
Negative Examples
['b']
Neg
Positive Examples
['aaabab', 'aabab', 'aababab', 'ab', 'abaabaa', 'abab', 'ababab', 'abbabab', 'bab', 'babab', 'bababab', 'bbab', 'bbabab', 'bbababaa', 'bbabbbab', 'bbbab', 'bbbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaabaa', 'aaabaabaa', 'ababa', 'aabaaaba', 'abbabab', 'aabababb', 'aaaabaabb', 'b', 'bab', 'aabaababb', 'aaaabaabb', 'abaaaabb', 'babab', 'aaabaaabb', 'ababb', 'abaaaaabb', 'bababab', 'aabaaabb', 'abaabb', 'aaaaaabb', 'bbab', 'aaabb', 'aaaaababb', 'aaaabb', 'bbabab', 'abaaaaabb', 'ababaaabb', 'aabaababb', 'bbababaa', 'abaaababb', 'ababaabb', 'aaaaaaabb', 'bbabbbab', 'abababb', 'aabaababb', 'aaaabb', 'bbbab', 'abaababb', 'aabababb', 'abababb', 'bbbbabab', 'aababaabb', 'aabaaaabb', 'abaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3335057646036148
Train Epoch 1, Loss 0.19704169780015945
Train Epoch 2, Loss 0.10196441784501076
Accuracy at epoch 15: 0.89453125, total training samples: 576
Early stopping at epoch 429. Loss did not improve for 10 epochs.
Generate examples Step 429, Loss 0.9063203225302142
Epoch: 16
Negative Examples
['aaaaabab', 'aaab', 'aaabab', 'aab', 'aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'b', 'baaaab', 'baaaabab', 'baabab', 'bab', 'bababbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaabab', 'aabab', 'aaaaaaab', 'aaabaaab', 'aaab', 'aaaababab', 'aaabaab', 'abaab', 'aaabab', 'abaaabab', 'aaababab', 'ababaabab', 'aab', 'abaabaaab', 'aababaab', 'aabaabaab', 'aabaabab', 'ab', 'aaaaabab', 'aaaaaabab', 'aabab', 'aaaabab', 'abaaaaaab', 'aaaabaab', 'ab', 'aaabab', 'ababaaaab', '', 'abaabab', 'ababaaaab', 'aaaaaaab', 'aaaabaab', 'abab', 'aaaababab', 'ababaaab', 'aabaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.91891610622406
Train Epoch 1, Loss 1.1500874757766724
Train Epoch 2, Loss 0.6915539801120758
Accuracy at epoch 16: 0.8544921875, total training samples: 612
Early stopping at epoch 204. Loss did not improve for 10 epochs.
Generate examples Step 204, Loss 0.26925894872444434
Epoch: 17
Negative Examples
['b']
Neg
Positive Examples
['aaaaabab', 'aaab', 'aaabab', 'aabab', 'aababab', 'abaa', 'abab', 'ababab', 'abbab', 'baabbab', 'bab', 'babab', 'bababab', 'babbab', 'bbabab', 'bbbab', 'bbbabab', 'bbbbabab', 'bbbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaa', 'aaaababaa', 'ababaaa', 'abaaaaaa', 'abbab', 'aabb', 'abaaaaabb', 'aaaaababb', 'baabbab', 'aaabababb', 'aaababb', 'ababaabb', 'bab', 'abaaababb', 'aaaaabb', 'aaabaaabb', 'babab', 'aabaaabb', 'aaaabb', 'abaabb', 'bababab', 'aabaaaabb', 'aababaabb', 'aaabaabb', 'babbab', 'ababaabb', 'abaaababb', 'abaaaabb', 'bbabab', 'abb', 'abaabaabb', 'aaaabb', 'bbbab', 'aaaabb', 'aabababb', 'aaabaabb', 'bbbabab', 'aaaaabb', 'aaaaababb', 'abaabb', 'bbbbabab', 'abaabb', 'b', 'abaaababb', 'bbbbbab', 'ababb', 'ababaaabb', 'abaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3419242203235626
Train Epoch 1, Loss 0.20655856281518936
Train Epoch 2, Loss 0.10966770350933075
Accuracy at epoch 17: 0.904296875, total training samples: 660
Early stopping at epoch 483. Loss did not improve for 10 epochs.
Generate examples Step 483, Loss 1.2209197324662169
Epoch: 18
Negative Examples
['aaab', 'aabaabab', 'aabab', 'aababbab', 'aabbab', 'ab', 'abaabab', 'abab', 'ababbab', 'abbab', 'b', 'baabab', 'bab', 'babaabab', 'babbab', 'bbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaab', 'aaaababab', 'aabaaaaab', 'ababaaaab', 'aabaabab', 'abababab', 'aababaab', 'aaaaaaab', 'aabab', 'aabaabaab', 'abaaaabab', 'aabab', 'ab', 'aaaaaaaab', 'abababab', 'aaaaabaab', 'abaabab', 'ababaaab', 'aaabab', 'ababab', 'abab', 'aaabaaab', '', 'aabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 2.1189663410186768
Train Epoch 1, Loss 1.6935285329818726
Train Epoch 2, Loss 1.3304580450057983
Accuracy at epoch 18: 0.9013671875, total training samples: 684
Early stopping at epoch 382. Loss did not improve for 10 epochs.
Generate examples Step 382, Loss 0.4353737777424855
Epoch: 19
Negative Examples
['aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'abbab', 'b', 'baaaabab', 'baabab', 'bab', 'babaabab', 'bababbab', 'bbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aabaabab', 'aababaab', 'aaabaaaab', 'abaab', 'aabab', 'aabaabab', 'aabaab', 'aaaaaabab', 'ab', 'aaaaabaab', 'aaaab', 'abaaaab', 'abaabab', 'aabab', 'abaaaabab', 'aaababaab', 'abab', 'aabaab', 'abab', 'aabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.9946619272232056
Train Epoch 1, Loss 0.7591831088066101
Train Epoch 2, Loss 0.5851662158966064
Accuracy at epoch 19: 0.875, total training samples: 704
Early stopping at epoch 206. Loss did not improve for 10 epochs.
Generate examples Step 206, Loss 0.2863864347986553
Epoch: 20
Negative Examples
['b']
Neg
Positive Examples
['aaaabbab', 'aaabbaa', 'aabab', 'aababbab', 'aabbabab', 'ab', 'abbab', 'abbbbab', 'baaabbab', 'bab', 'bababbab', 'bbab', 'bbbab', 'bbbbab', 'bbbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'abaaabb', 'abaaaabb', 'b', 'aaabbaa', 'abaabaabb', 'aaaaababb', 'aabababb', 'aababbab', 'aaabababb', 'aaabb', 'abaabaabb', 'aabbabab', 'abaaababb', 'aaaabaabb', 'ababaabb', 'abbab', 'abaabb', 'aabaabb', 'aabababb', 'abbbbab', 'aaababb', 'abaaabb', 'aaaaaabb', 'baaabbab', 'aaabaaabb', 'b', 'aaaababb', 'bab', 'b', 'abaababb', 'aaabaaabb', 'bababbab', 'aaaaababb', 'ababaabb', 'aabaaabb', 'bbab', 'ababaaabb', 'aaaaaabb', 'aabaabb', 'bbbab', 'ababb', 'aaaabaabb', 'aabababb', 'bbbbab', 'aaaaabb', 'aabaaabb', 'ababb', 'bbbbbab', 'abb', 'abababb', 'aabababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3636227697134018
Train Epoch 1, Loss 0.2134408876299858
Train Epoch 2, Loss 0.11247044429183006
Accuracy at epoch 20: 0.8984375, total training samples: 756
Early stopping at epoch 473. Loss did not improve for 10 epochs.
Generate examples Step 473, Loss 1.0707489766400575
Epoch: 21
Negative Examples
['aaaaabab', 'aaabab', 'aaababab', 'ab', 'abab', 'ababab', 'b', 'baababab', 'bab', 'babab', 'bbababab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaabab', 'ababab', 'aabaabaab', 'aabaaab', 'aaabab', 'abaaaaaab', 'aaaaab', 'aaabaabab', 'aaababab', 'aab', 'aababaaab', 'aabaaab', 'ab', 'aaaabaaab', 'aaaaab', '', 'abab', 'abaaaab', 'ababaaab', 'aaababab', 'ababab', 'aabaaabab', 'ab', 'aaaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.8287601470947266
Train Epoch 1, Loss 1.4148069620132446
Train Epoch 2, Loss 1.0762242078781128
Accuracy at epoch 21: 0.939453125, total training samples: 780
Early stopping at epoch 325. Loss did not improve for 10 epochs.
Generate examples Step 325, Loss 0.3528994977748467
Epoch: 22
Negative Examples
['b', 'bab', 'bbbbabab']
Neg Neg Neg
Positive Examples
['ab', 'abab', 'ababab', 'abababab', 'babab', 'bababab', 'bbababab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['babab', 'aaabaaabb', 'aabababb', 'aaaabaabb', 'bababab', 'aaaabb', 'ababb', 'aaabaaabb', 'bbababab', 'aaaaaabb', 'aaaaaaabb', 'abaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.24715441465377808
Train Epoch 1, Loss 0.166120707988739
Train Epoch 2, Loss 0.1086084321141243
Accuracy at epoch 22: 0.9033203125, total training samples: 792
Early stopping at epoch 478. Loss did not improve for 10 epochs.
Generate examples Step 478, Loss 0.7525669581457071
Epoch: 23
Negative Examples
['aaaaabab', 'aaaabab', 'aaabab', 'aabab', 'ab', 'abaaabab', 'abab', 'b', 'bab', 'bbaaabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaabab', 'aabaaabab', 'abab', 'aabab', 'aaaabab', 'aaabaaab', '', 'ababaab', 'aaabab', 'abaaaaaab', 'ababaabab', 'ababaaab', 'aabab', 'abaabaab', 'aabaaaab', 'abaabaaab', 'ab', 'aaabaabab', 'aababaab', 'aaaabaab', 'abaaabab', 'abaaabaab', 'aab', 'ababaab', 'abab', 'aabaabaab', 'aababab', 'aabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.8772085905075073
Train Epoch 1, Loss 1.4719175100326538
Train Epoch 2, Loss 1.1389890909194946
Accuracy at epoch 23: 0.9326171875, total training samples: 820
Early stopping at epoch 319. Loss did not improve for 10 epochs.
Generate examples Step 319, Loss 0.327578899404034
Epoch: 24
Negative Examples
['aaaabab', 'aaabab', 'aabab', 'aabbabab', 'abaaabab', 'abab', 'b', 'baabab', 'baababab', 'bab', 'babab', 'bababab', 'bbaabab', 'bbabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['ab']
Pos
Counterexamples
['aaaabab', 'ababaaaab', 'aabaabab', 'ababaaab', 'aaabab', 'ababaabab', 'aaaaaabab', 'abaaaaab', 'aabab', 'ababaabab', 'aaababab', 'aaabaaab', 'abaaabab', 'ababab', 'aaaaaaaab', 'aabaaaab', 'abab', 'aaaababab', 'aabaabaab', 'aaabaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.820452868938446
Train Epoch 1, Loss 0.6108364462852478
Train Epoch 2, Loss 0.46388572454452515
Accuracy at epoch 24: 0.8037109375, total training samples: 840
Early stopping at epoch 202. Loss did not improve for 10 epochs.
Generate examples Step 202, Loss 0.2896123882291352
Epoch: 25
Negative Examples
['b', 'bbababbb']
Neg Neg
Positive Examples
['aa', 'aaaabab', 'ab', 'abaa', 'abab', 'abbab', 'abbbab', 'baaaabaa', 'baaabab', 'baabab', 'bab', 'babab', 'babbabaa', 'babbbbab', 'bbab', 'bbbab', 'bbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aa', 'abaababaa', 'aabababaa', 'aababa', 'abaa', 'aaaaaaaba', 'aababaaaa', 'aaaaaaaa', 'abbab', 'aaaaababb', 'aaaaaaabb', 'ababb', 'abbbab', 'aabaababb', 'aababb', 'ababb', 'baaaabaa', 'ababb', 'aabababb', 'abababb', 'baaabab', 'aaababb', 'abaabaabb', 'aaaabaabb', 'baabab', 'aabaaabb', 'ababababb', 'aaaabaabb', 'bab', 'aababb', 'aabaabb', 'aabababb', 'babab', 'ababababb', 'aabb', 'aabaaaabb', 'babbabaa', 'aabaabb', 'ababababb', 'abababb', 'babbbbab', 'ababaaabb', 'aaaaabb', 'abaabaabb', 'bbab', 'b', 'aaaabb', 'aaaaaabb', 'bbbab', 'abaababb', 'ababaabb', 'aabaaaabb', 'bbbbab', 'abb', 'abaaaaabb', 'aaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3833025395870209
Train Epoch 1, Loss 0.24035518616437912
Train Epoch 2, Loss 0.13598095253109932
Accuracy at epoch 25: 0.888671875, total training samples: 896
Early stopping at epoch 525. Loss did not improve for 10 epochs.
Generate examples Step 525, Loss 0.7826238016211942
Epoch: 26
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b', 'baaaab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'aaaabaaab', 'aaab', 'aababab', 'aaaaaab', 'aaababab', 'aabaaaab', 'aaabab', 'aaaaab', 'abaaabaab', 'abaab', 'aaaabaaab', 'aaaab', 'abaababab', 'abaaaaab', 'aaaaabab', 'aaab', 'abaabaab', 'abab', 'abaaab', 'aab', 'abaabaab', 'aababab', 'aaabaabab', 'ab', 'ababaab', 'abaaabab', 'abababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.6932305097579956
Train Epoch 1, Loss 1.3011454343795776
Train Epoch 2, Loss 0.9926162362098694
Accuracy at epoch 26: 0.9345703125, total training samples: 924
Early stopping at epoch 357. Loss did not improve for 10 epochs.
Generate examples Step 357, Loss 0.3171374280026505
Epoch: 27
Negative Examples
['aaaaabab', 'aabab', 'abaabab', 'abab', 'b', 'baaaabab', 'baaabab', 'baabab', 'baabbab', 'bab', 'babab', 'bbaabab', 'bbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['ab']
Pos
Counterexamples
['aaaaabab', 'abaaab', 'aabab', 'aaaaaabab', 'aabab', 'aababaaab', 'aabaaab', 'abaaabab', 'abaabab', 'abababab', 'abaabaab', 'abaababab', 'abab', 'abaaabaab', 'abaaaabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7747165560722351
Train Epoch 1, Loss 0.5748112797737122
Train Epoch 2, Loss 0.4305780231952667
Accuracy at epoch 27: 0.8623046875, total training samples: 940
Early stopping at epoch 258. Loss did not improve for 10 epochs.
Generate examples Step 258, Loss 0.2235530212118819
Epoch: 28
Negative Examples
['aa', 'aaabbaa', 'b', 'babbbaa', 'bbaa', 'bbbbaa']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aabab', 'aabbbab', 'ab', 'abaa', 'ababbab', 'abbab', 'abbbab', 'abbbbab', 'bab', 'bababaa', 'bababab', 'babbbab', 'babbbbab', 'bbab', 'bbbaabaa', 'bbbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbbab', 'abababb', 'b', 'aabaaaabb', 'abaa', 'aabababaa', 'aaaaba', 'aabaaaaa', 'ababbab', 'abaabb', 'abb', 'aabaababb', 'abbab', 'aaaababb', 'aababb', 'abaaaaabb', 'abbbab', 'b', 'abaaababb', 'aaababb', 'abbbbab', 'aabaabb', 'abababb', 'aaaababb', 'bab', 'ababb', 'aaaabb', 'aabb', 'bababaa', 'aaabababb', 'aaaabb', 'abaaababb', 'bababab', 'aaaabb', 'aababaabb', 'ababaaabb', 'babbbab', 'aabaababb', 'aaaabb', 'aaaaaaabb', 'babbbbab', 'ababababb', 'aabaabb', 'aabaababb', 'bbab', 'aaaaababb', 'aaababb', 'aaaaabb', 'bbbaabaa', 'aabaaaabb', 'abb', 'aaaabb', 'bbbabbab', 'aabababb', 'ababb', 'abaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.36475130915641785
Train Epoch 1, Loss 0.2276879921555519
Train Epoch 2, Loss 0.12391065061092377
Accuracy at epoch 28: 0.89453125, total training samples: 996
Early stopping at epoch 601. Loss did not improve for 10 epochs.
Generate examples Step 601, Loss 0.7498665578737608
Epoch: 29
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'abaaaaab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'ab', 'abaaabaab', 'ababab', 'aaaaaab', 'ababaaab', 'abab', 'aaaaabab', 'aaaaab', 'aaaaabaab', 'aabaaabab', 'abaabab', 'aaaab', 'aaabab', 'abaababab', 'aabab', 'aaab', 'aabaaab', 'ab', 'ababaaab', 'aab', 'abaababab', 'aaaaaaab', 'aabaaabab', 'ab', 'aabaaab', 'abaababab', 'ababab', 'abaaaaab', 'aaab', 'aaaabaaab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.5607335567474365
Train Epoch 1, Loss 1.1528961658477783
Train Epoch 2, Loss 0.841796338558197
Accuracy at epoch 29: 0.9541015625, total training samples: 1028
Early stopping at epoch 351. Loss did not improve for 10 epochs.
Generate examples Step 351, Loss 0.3731714827855202
Epoch: 30
Negative Examples
['b', 'bab']
Neg Neg
Positive Examples
['aaaaabab', 'aaab', 'ab', 'abab', 'ababab', 'abababab', 'baaab', 'babaaab', 'babab', 'bababab', 'bbabab', 'bbababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaab', 'abaabb', 'aaaaababb', 'aabababb', 'babaaab', 'aaaaaabb', 'aabaaaabb', 'b', 'babab', 'aababb', 'aaabababb', 'aaaababb', 'bababab', 'ababaaabb', 'abb', 'aaaaababb', 'bbabab', 'aaabaaabb', 'ababababb', 'aaaabb', 'bbababab', 'aaabababb', 'aaaabaabb', 'abaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.28593501448631287
Train Epoch 1, Loss 0.19595985114574432
Train Epoch 2, Loss 0.13080564141273499
Accuracy at epoch 30: 0.9111328125, total training samples: 1052
Early stopping at epoch 538. Loss did not improve for 10 epochs.
Generate examples Step 538, Loss 0.7183941716608179
Epoch: 31
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'abab', 'aaaabaab', 'aabaaaab', 'aaaaaab', 'abaabaab', 'aaaaab', 'aaaab', 'aaaaab', 'ababab', 'abaaaabab', '', 'aaaab', 'aaaabaab', 'aaababaab', 'abaaab', 'aaab', 'abaabaab', 'aabaabab', 'aaabab', 'aab', 'abaabaaab', 'aab', '', 'ab', 'ababaab', 'aaabaabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.5244827270507812
Train Epoch 1, Loss 1.1673243045806885
Train Epoch 2, Loss 0.8914772868156433
Accuracy at epoch 31: 0.970703125, total training samples: 1080
Early stopping at epoch 313. Loss did not improve for 10 epochs.
Generate examples Step 313, Loss 0.3687523302094192
Epoch: 32
Negative Examples
['aabab', 'abab', 'abbaabab', 'b', 'baabab', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aab', 'ab', 'abaaaaab', 'baaaab', 'baaabab', 'babaaaab', 'bbaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'aaaabaaab', 'aaababaab', 'aaaab', 'abab', 'aaaabaaab', 'aaabaaab', 'abababaab', 'baaaab', 'ababb', 'aaaabaabb', 'b', 'baaabab', 'abaaaabb', 'aaabaabb', 'aabaaaabb', 'babaaaab', 'abb', 'aaaabb', 'ababaaabb', 'bbaaabab', 'aaabaaabb', 'abaaaabb', 'abaabaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.49642622470855713
Train Epoch 1, Loss 0.43980154395103455
Train Epoch 2, Loss 0.40396830439567566
Accuracy at epoch 32: 0.8798828125, total training samples: 1104
Early stopping at epoch 288. Loss did not improve for 10 epochs.
Generate examples Step 288, Loss 0.23390888549052308
Epoch: 33
Negative Examples
['aa', 'aaabbaa', 'aabbbaa', 'ababbaa', 'abbabbaa', 'abbbaa', 'abbbbaa', 'abbbbbaa', 'b', 'baa', 'babbbbaa', 'bbaa', 'bbbaa', 'bbbbaa']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aabbbbab', 'ab', 'abbbab', 'bab', 'babbbab', 'bbabbbab', 'bbbab', 'bbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbbbab', 'aabb', 'aababb', 'aaaabb', 'abbbab', 'abaaabb', 'abb', 'abaabb', 'bab', 'ababaaabb', 'aaaaaabb', 'aaaabb', 'babbbab', 'aabaaaabb', 'ababaabb', 'abb', 'bbabbbab', 'aaabb', 'ababababb', 'aaabababb', 'bbbab', 'aabaabb', 'aabaababb', 'aababaabb', 'bbbbab', 'ababaaabb', 'aabb', 'aaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3906492590904236
Train Epoch 1, Loss 0.29601413011550903
Train Epoch 2, Loss 0.21421614289283752
Accuracy at epoch 33: 0.9423828125, total training samples: 1132
Early stopping at epoch 302. Loss did not improve for 10 epochs.
Generate examples Step 302, Loss 0.4156114234782682
Epoch: 34
Negative Examples
['abab', 'b', 'baabab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'ab', 'abaaaab', 'baaaaaab', 'baaaaab', 'baaaab', 'babaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abab', 'aaaabab', 'abaaabab', 'aaaaabaab', 'baaaaaab', 'aabaaabb', 'aabaaaabb', 'abaaababb', 'baaaaab', 'abb', 'aaaabaabb', 'aabaabb', 'baaaab', 'abaaaabb', 'aaaaababb', 'aaaaaabb', 'babaaaab', 'aaabaaabb', 'aaaaabb', 'ababaaabb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5408605933189392
Train Epoch 1, Loss 0.4457714557647705
Train Epoch 2, Loss 0.3860386610031128
Accuracy at epoch 34: 0.8359375, total training samples: 1152
Early stopping at epoch 239. Loss did not improve for 10 epochs.
Generate examples Step 239, Loss 0.26268899273127316
Epoch: 35
Negative Examples
['b', 'baa', 'babaa']
Neg Neg Neg
Positive Examples
['aa', 'aaaaaaab', 'aaabaa', 'aabbab', 'ab', 'abab', 'abbaabaa', 'abbab', 'baabab', 'baababaa', 'baababab', 'bab', 'babab', 'babbab', 'bbaaabaa', 'bbab', 'bbbabab', 'bbbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aa', 'abababa', 'aaaaaaaba', 'aaaabaa', 'aaabaa', 'aababaaba', 'abaaaa', 'aaaaaaaa', 'aabbab', 'abaaababb', 'aaabaaabb', 'ababb', 'abbaabaa', 'ababababb', 'abaaaaabb', 'ababaaabb', 'abbab', 'aaaaaaabb', 'aababb', 'aaabaabb', 'baabab', 'aababb', 'abaabb', 'ababaabb', 'baababaa', 'abaaababb', 'aaabaabb', 'aabaaaabb', 'baababab', 'abababb', 'aababb', 'aaaabaabb', 'bab', 'aaababb', 'ababababb', 'aaabababb', 'babab', 'b', 'abaabaabb', 'aabababb', 'babbab', 'aababb', 'b', 'abb', 'bbaaabaa', 'ababababb', 'abababb', 'abaaaabb', 'bbab', 'aaaabb', 'ababababb', 'ababaaabb', 'bbbabab', 'abaababb', 'ababb', 'abababb', 'bbbbbab', 'aabb', 'abaaaabb', 'aaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.32808099687099457
Train Epoch 1, Loss 0.18464116752147675
Train Epoch 2, Loss 0.09429942071437836
Accuracy at epoch 35: 0.908203125, total training samples: 1212
Early stopping at epoch 599. Loss did not improve for 10 epochs.
Generate examples Step 599, Loss 0.9172957928975424
Epoch: 36
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'aabaaaaab', 'aaaaaab', 'abaaaaaab', 'aaaaaab', 'aabaab', 'aabaaab', 'abab', 'aaaaab', 'ababaaab', 'ababab', 'aaababaab', 'aaaab', 'aabaaaaab', 'aabaabaab', 'aaaababab', 'aaab', 'aaaab', 'abaaaabab', 'aaaaaaaab', 'aab', 'aababaab', 'abaaabaab', 'aaababaab', 'ab', 'abab', 'aaabaaab', 'aabaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.863917350769043
Train Epoch 1, Loss 1.3363010883331299
Train Epoch 2, Loss 0.9372247457504272
Accuracy at epoch 36: 0.9560546875, total training samples: 1240
Early stopping at epoch 297. Loss did not improve for 10 epochs.
Generate examples Step 297, Loss 0.4494571474774572
Epoch: 37
Negative Examples
['aabab', 'abaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'ab', 'abaaaab', 'baaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'aaababab', 'abaaaaaab', 'abaab', 'abaab', 'aababab', 'aababaaab', 'abaababab', 'baaaab', 'aaabaabb', 'aaaababb', 'abaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.5443559288978577
Train Epoch 1, Loss 0.449431449174881
Train Epoch 2, Loss 0.38878223299980164
Accuracy at epoch 37: 0.880859375, total training samples: 1252
Early stopping at epoch 265. Loss did not improve for 10 epochs.
Generate examples Step 265, Loss 0.2913195182170187
Epoch: 38
Negative Examples
['aa', 'abaa', 'ababaa', 'abbbaa', 'b', 'baa']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaabab', 'aaabbbab', 'aababab', 'aabbab', 'ab', 'abab', 'ababab', 'abbab', 'abbabab', 'baababab', 'baabbab', 'bab', 'bbab', 'bbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbbab', 'abaaaabb', 'aaaabb', 'aaababb', 'aabbab', 'abaabaabb', 'aabaabb', 'abb', 'abbab', 'aaabaaabb', 'aababb', 'aaabababb', 'abbabab', 'aaaaaabb', 'ababb', 'aabaababb', 'baababab', 'aaaabaabb', 'aaaababb', 'ababb', 'baabbab', 'aaababb', 'aababb', 'aaaabaabb', 'bab', 'abaabb', 'ababaaabb', 'aaaabb', 'bbab', 'abaababb', 'abababb', 'aababaabb', 'bbbab', 'abaabaabb', 'aaabaaabb', 'aaaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3264779597520828
Train Epoch 1, Loss 0.1682017743587494
Train Epoch 2, Loss 0.07458791695535183
Accuracy at epoch 38: 0.8876953125, total training samples: 1288
Early stopping at epoch 553. Loss did not improve for 10 epochs.
Generate examples Step 553, Loss 0.8366100676223259
Epoch: 39
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'abaababab', 'aababaab', 'aaaababab', 'aaaaaab', 'abaabab', 'aaaaabab', 'aaaabaaab', 'aaaaab', 'aabaaabab', 'aaaaaaab', 'aaabab', 'aaaab', 'aab', 'aaaab', 'abababab', 'aab', 'aaabaab', 'ababaab', 'aababaab', 'ab', 'aabaaaaab', 'aaabaab', 'aabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.8725214004516602
Train Epoch 1, Loss 1.3463417291641235
Train Epoch 2, Loss 0.9462437629699707
Accuracy at epoch 39: 0.966796875, total training samples: 1312
Early stopping at epoch 425. Loss did not improve for 10 epochs.
Generate examples Step 425, Loss 0.6117806354179068
Epoch: 40
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 40: No counterexamples found, skipped.
Early stopping at epoch 304. Loss did not improve for 10 epochs.
Generate examples Step 304, Loss 0.4418942701132571
Epoch: 41
Negative Examples
['aa', 'aaabab', 'abab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'ab', 'baaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabab', 'abababab', 'aaabab', 'aaaaab', 'abab', 'aaababaab', 'aaabaaab', 'aaaabab', 'baaaaaab', 'b', 'aabaabb', 'ababaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.5404031276702881
Train Epoch 1, Loss 0.4562565088272095
Train Epoch 2, Loss 0.40718260407447815
Accuracy at epoch 41: 0.8173828125, total training samples: 1324
Early stopping at epoch 282. Loss did not improve for 10 epochs.
Generate examples Step 282, Loss 0.4318691709016321
Epoch: 42
Negative Examples
['b']
Neg
Positive Examples
['aa', 'aaaaabaa', 'aab', 'aabbabaa', 'aabbbab', 'ab', 'abaa', 'abab', 'ababbbab', 'abbab', 'bab', 'babab', 'bbab', 'bbabab', 'bbbab', 'bbbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aa', 'aabababa', 'abaabaa', 'abaaaaa', 'aaaaabaa', 'ababababa', 'ababa', 'aaba', 'aabbabaa', 'aaabaabb', 'aaaaabb', 'aaabababb', 'aabbbab', 'abaababb', 'abaaababb', 'abaaaabb', 'abaa', 'aabaaaaba', 'aaaaaaaba', 'aaba', 'ababbbab', 'aabaaaabb', 'abaaaaabb', 'aaababb', 'abbab', 'aabaababb', 'ababaabb', 'ababb', 'bab', 'aabb', 'aaaaaabb', 'aaababb', 'babab', 'abaaabb', 'aababaabb', 'aabaaabb', 'bbab', 'aaaaabb', 'ababaabb', 'ababababb', 'bbabab', 'aaaaababb', 'ababababb', 'aaaababb', 'bbbab', 'ababaabb', 'aabaababb', 'ababb', 'bbbbbab', 'ababb', 'abaaaabb', 'aaaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.29872964322566986
Train Epoch 1, Loss 0.15463777258992195
Train Epoch 2, Loss 0.07356659695506096
Accuracy at epoch 42: 0.9111328125, total training samples: 1376
Early stopping at epoch 566. Loss did not improve for 10 epochs.
Generate examples Step 566, Loss 0.7437893576933173
Epoch: 43
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'abaaaab', 'abab', 'aaabaaaab', 'aaaaaab', 'abaaaaaab', 'abaaaab', 'aaab', 'aaaaab', 'ababaaab', 'abaaaaaab', 'aaab', 'aaaab', 'abaaab', 'aabaabab', 'aaab', 'aaab', 'aaaabaab', 'abaaaab', 'aabaaaab', 'aab', 'aaaabaaab', 'abaabaab', 'aaaababab', 'ab', 'aaaabab', 'aaaaabab', 'ababaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.680532693862915
Train Epoch 1, Loss 1.1349223852157593
Train Epoch 2, Loss 0.7550163269042969
Accuracy at epoch 43: 0.9599609375, total training samples: 1404
Early stopping at epoch 316. Loss did not improve for 10 epochs.
Generate examples Step 316, Loss 0.4996685648002083
Epoch: 44
Negative Examples
['aaabaab', 'aaabab', 'b', 'baab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaab', 'aab', 'aabaaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabaab', 'aabababab', 'aaabab', 'aaabaab', 'aaabab', 'ababaaab', 'aaaabab', 'aaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7363453507423401
Train Epoch 1, Loss 0.4922705292701721
Train Epoch 2, Loss 0.3356369733810425
Accuracy at epoch 44: 0.861328125, total training samples: 1412
Early stopping at epoch 348. Loss did not improve for 10 epochs.
Generate examples Step 348, Loss 0.39079819845948316
Epoch: 45
Negative Examples
['b']
Neg
Positive Examples
['aaaaabab', 'aaaabbab', 'aaabab', 'aaabbab', 'aab', 'aabab', 'ab', 'abaabab', 'abab', 'abababab', 'abbab', 'abbabbab', 'baaaabab', 'baab', 'baabbab', 'bab', 'bababab', 'bbaaabab', 'bbaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'aaabababb', 'aaabaaabb', 'aabababb', 'aaabbab', 'aaabababb', 'aaaaababb', 'abaaababb', 'abbab', 'aaaabaabb', 'aaaabb', 'aaaababb', 'abbabbab', 'abaabaabb', 'abaababb', 'aaabaabb', 'baaaabab', 'aababb', 'aababaabb', 'aabb', 'baab', 'aaaaabb', 'aaaaaaabb', 'abb', 'baabbab', 'aababb', 'aaaaaabb', 'aabaaabb', 'bab', 'abaaababb', 'abaaabb', 'aaaababb', 'bababab', 'abaaaabb', 'ababaabb', 'aaaaaabb', 'bbaaabab', 'ababaaabb', 'aabaababb', 'aaaabb', 'bbaab', 'aabaababb', 'aaaaabb', 'abaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3794146627187729
Train Epoch 1, Loss 0.2021946907043457
Train Epoch 2, Loss 0.09157085046172142
Accuracy at epoch 45: 0.90234375, total training samples: 1456
Early stopping at epoch 547. Loss did not improve for 10 epochs.
Generate examples Step 547, Loss 0.7046158083707746
Epoch: 46
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'abaabaab', 'aaabab', 'aaaaabab', 'aaaaaab', 'aaaaaab', 'aaabab', 'aaaabab', 'aaaaab', 'ababaaaab', 'aababaaab', 'aaaabaab', 'aaaab', 'abaaabaab', 'aabababab', 'abaaab', 'aaab', 'aaabaabab', 'abaab', 'abab', 'aab', 'abababab', 'abaaaabab', 'abababaab', 'ab', 'abababaab', 'abaaabaab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.6278325319290161
Train Epoch 1, Loss 1.1388713121414185
Train Epoch 2, Loss 0.7895494699478149
Accuracy at epoch 46: 0.9638671875, total training samples: 1484
Early stopping at epoch 305. Loss did not improve for 10 epochs.
Generate examples Step 305, Loss 0.5156790223581339
Epoch: 47
Negative Examples
['b', 'baab', 'baababab', 'bab', 'babaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaaab', 'aab', 'aabaaab', 'ab', 'abaaab', 'abab', 'abbaaab', 'baaab', 'bbabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaaab', 'abaabb', 'ababb', 'abaaababb', 'baaab', 'aaaaaabb', 'aabaaabb', 'aaababb', 'bbabaaab', 'abaabb', 'ababb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3248206079006195
Train Epoch 1, Loss 0.19790129363536835
Train Epoch 2, Loss 0.11301165074110031
Accuracy at epoch 47: 0.908203125, total training samples: 1496
Early stopping at epoch 588. Loss did not improve for 10 epochs.
Generate examples Step 588, Loss 0.7765839924128229
Epoch: 48
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'aaaabab', 'abaaabaab', 'aaababaab', 'aaaaaab', 'aaaaab', 'aaabaaaab', 'aababaab', 'aaaaab', 'aabab', 'abab', 'aaaaabab', 'aaaab', 'aabaabaab', 'aaaabab', 'abaabab', 'aaab', 'ababaaaab', 'abaaab', 'aababaaab', 'aab', 'ababaaaab', 'aaaaaaaab', 'ababaab', 'ab', 'ababaabab', 'aababaab', 'aaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.2705764770507812
Train Epoch 1, Loss 0.8653621077537537
Train Epoch 2, Loss 0.5921153426170349
Accuracy at epoch 48: 0.9033203125, total training samples: 1524
Early stopping at epoch 354. Loss did not improve for 10 epochs.
Generate examples Step 354, Loss 0.46293606036145923
Epoch: 49
Negative Examples
['b']
Neg
Positive Examples
['aaaabab', 'aaab', 'aabaaaab', 'aabaabab', 'aabab', 'ab', 'abaaaab', 'abaabab', 'abab', 'ababaab', 'baabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baabab', 'aaabababb', 'aabaaaabb', 'aabaabb', 'bab', 'aabababb', 'aabb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2678295373916626
Train Epoch 1, Loss 0.17915630340576172
Train Epoch 2, Loss 0.11455602198839188
Accuracy at epoch 49: 0.90625, total training samples: 1532
Early stopping at epoch 388. Loss did not improve for 10 epochs.
Generate examples Step 388, Loss 0.5184726775611888
Epoch: 50
Negative Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab']
Pos Pos Pos
Counterexamples
['aaaab', 'abaaaab', 'abaaabab', 'abababab', 'aaaabaab', 'aaaabab', 'aaaabaaab', 'aabaaabab', 'aaab', 'aaaaabab', 'aaababaab', 'abaaabaab', 'aab', 'ababaabab', 'aaaaabab', 'ababaab', 'ab', 'aaabab', 'aaabaaab', 'abababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.3032547235488892
Train Epoch 1, Loss 0.8802872896194458
Train Epoch 2, Loss 0.5954720973968506
Accuracy at epoch 50: 0.91015625, total training samples: 1552
Early stopping at epoch 300. Loss did not improve for 10 epochs.
Generate examples Step 300, Loss 0.3243954080679884
Epoch: 51
Negative Examples
['aababaaa', 'b', 'bbab', 'bbbab']
Neg Neg Neg Neg
Positive Examples
['aaabbab', 'aababbab', 'aabbab', 'aabbbaab', 'ab', 'ababaab', 'ababbab', 'abbab', 'baab', 'bab', 'babaab', 'bbaab', 'bbabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbab', 'aaaaabb', 'aaaabb', 'abaaabb', 'aababbab', 'aaabaabb', 'aabaababb', 'ababaabb', 'aabbab', 'abababb', 'abaabb', 'abaaaaabb', 'aabbbaab', 'aaabababb', 'aabaababb', 'aaaababb', 'ababbab', 'aaabaaabb', 'ababaabb', 'aaaabb', 'abbab', 'aaaaababb', 'aaaaabb', 'aabaaaabb', 'baab', 'abaabaabb', 'aaaaababb', 'aabababb', 'bab', 'aaababb', 'ababababb', 'aaaaababb', 'babaab', 'abaaababb', 'abb', 'abaabaabb', 'bbaab', 'b', 'aaaaabb', 'abaaaabb', 'bbabaab', 'aaaaaaabb', 'ababaaabb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.23833315074443817
Train Epoch 1, Loss 0.0917515940964222
Train Epoch 2, Loss 0.039079733192920685
Accuracy at epoch 51: 0.8984375, total training samples: 1596
Early stopping at epoch 668. Loss did not improve for 10 epochs.
Generate examples Step 668, Loss 1.1094130793494494
Epoch: 52
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'ababaaaab', 'aabaabab', 'aaaabaaab', 'aaaaaab', 'abaabaaab', 'abaaabab', 'aaaaabaab', 'aaaaab', 'aabab', 'abababab', 'aaaaaab', 'aaaab', 'abaabab', 'abaabaab', 'aabaabaab', 'aaab', 'abaaaabab', 'aaaabaaab', 'aababaab', 'aab', 'aababab', 'aaabaaab', 'ababaaaab', 'ab', 'aaaabaab', 'aaabaab', 'abaaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 2.417046070098877
Train Epoch 1, Loss 1.7437845468521118
Train Epoch 2, Loss 1.1858443021774292
Accuracy at epoch 52: 0.9580078125, total training samples: 1624
Early stopping at epoch 466. Loss did not improve for 10 epochs.
Generate examples Step 466, Loss 0.5644067765175658
Epoch: 53
Negative Examples
['aab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'ababaab', 'aabababab', 'ab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.0777214765548706
Train Epoch 1, Loss 0.7287821769714355
Train Epoch 2, Loss 0.486240953207016
Accuracy at epoch 53: 0.83984375, total training samples: 1628
Early stopping at epoch 352. Loss did not improve for 10 epochs.
Generate examples Step 352, Loss 0.3521002994549511
Epoch: 54
Negative Examples
['aa', 'aababaa', 'b']
Neg Neg Neg
Positive Examples
['aaabbab', 'aab', 'aabab', 'ab', 'abab', 'abbaab', 'abbabab', 'abbbab', 'baaabbab', 'baab', 'bab', 'bbaaab', 'bbaab', 'bbabab', 'bbbab', 'bbbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbab', 'aaabaaabb', 'abb', 'abaabaabb', 'abbaab', 'aaabaaabb', 'aaaaaabb', 'aababb', 'abbabab', 'aaaababb', 'aaaaaaabb', 'aaaaaabb', 'abbbab', 'aaaaababb', 'aababb', 'abaaaaabb', 'baaabbab', 'aabaaabb', 'aabababb', 'abb', 'baab', 'aaaaabb', 'abaabb', 'abaaaabb', 'bab', 'abaababb', 'abb', 'aaaaaabb', 'bbaaab', 'aabababb', 'ababababb', 'aabaaaabb', 'bbaab', 'abb', 'abaabaabb', 'aaaabb', 'bbabab', 'abaababb', 'abaaaaabb', 'ababababb', 'bbbab', 'b', 'aaaaabb', 'abb', 'bbbabbab', 'ababaaabb', 'aaaaaaabb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.26474016159772873
Train Epoch 1, Loss 0.12121991440653801
Train Epoch 2, Loss 0.0504634790122509
Accuracy at epoch 54: 0.884765625, total training samples: 1676
Early stopping at epoch 660. Loss did not improve for 10 epochs.
Generate examples Step 660, Loss 0.9954427428397036
Epoch: 55
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'b']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'abaab', 'aaaabaab', 'aaaaaaab', 'aaaaaab', 'aaababaab', 'ababab', 'ababaaab', 'aaaaab', 'abaaaaaab', 'aababaaab', 'aaababab', 'aaaab', 'aabaaaaab', 'aaabaaab', 'abaab', 'aaab', 'aaaababab', 'abababab', 'abaaab', 'aab', 'abaabab', 'aaaaaaaab', 'aaabaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 2.0880916118621826
Train Epoch 1, Loss 1.4500761032104492
Train Epoch 2, Loss 0.9729184508323669
Accuracy at epoch 55: 0.9482421875, total training samples: 1700
Early stopping at epoch 383. Loss did not improve for 10 epochs.
Generate examples Step 383, Loss 0.4527672497788444
Epoch: 56
Negative Examples
['aab', 'aabab', 'abab', 'abbaabab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'ab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', '', 'abaabaaab', 'aaaabab', 'aabab', 'aaaaaab', 'aaaaaaab', 'aaaaaaaab', 'abab', 'abaabab', 'abaaaaab', 'aaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.5913525223731995
Train Epoch 1, Loss 0.4150432050228119
Train Epoch 2, Loss 0.307918518781662
Accuracy at epoch 56: 0.84375, total training samples: 1712
Early stopping at epoch 283. Loss did not improve for 10 epochs.
Generate examples Step 283, Loss 0.35996731528094117
Epoch: 57
Negative Examples
['abbaab', 'b']
Neg Neg
Positive Examples
['aa', 'aaabab', 'aaababaa', 'aaababab', 'aabab', 'aababab', 'aabbab', 'ab', 'abab', 'ababaaab', 'ababab', 'abababab', 'abbaaab', 'abbabab', 'baaab', 'baababab', 'bab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aa', 'aaaababaa', 'abababaa', 'aaabaaaa', 'aaababaa', 'aabaaaba', 'aaabaaaa', 'aababaaba', 'aabbab', 'ababaabb', 'aabaaaabb', 'aaaaabb', 'abbaaab', 'abababb', 'b', 'ababababb', 'abbabab', 'aababaabb', 'b', 'aaabaaabb', 'baaab', 'abaabb', 'b', 'aaaaabb', 'baababab', 'aabb', 'abaaabb', 'aaabb', 'bab', 'aaaabaabb', 'aaaaaabb', 'aababb', 'babab', 'aabb', 'ababaabb', 'aababaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4051172733306885
Train Epoch 1, Loss 0.17502597346901894
Train Epoch 2, Loss 0.07603505998849869
Accuracy at epoch 57: 0.890625, total training samples: 1748
Early stopping at epoch 383. Loss did not improve for 10 epochs.
Generate examples Step 383, Loss 0.7473174808546901
Epoch: 58
Negative Examples
['aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab']
Pos Pos Pos Pos
Counterexamples
['aaab', 'ab', 'abaabaaab', 'aabaaabab', 'aab', 'ababaab', 'aabaaab', 'aaabaab', 'ab', 'aaaabab', '', 'aab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.5091952085494995
Train Epoch 1, Loss 1.0464073419570923
Train Epoch 2, Loss 0.7032986283302307
Accuracy at epoch 58: 0.93359375, total training samples: 1760
Early stopping at epoch 403. Loss did not improve for 10 epochs.
Generate examples Step 403, Loss 0.501429062152263
Epoch: 59
Negative Examples
['aaabbaab', 'aaabbab', 'abaaa', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab', 'baaaaa', 'baaaab', 'baaab', 'babaab', 'bbaaaaab', 'bbaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaaa', 'ababaabb', 'aaabababb', 'abaaaabb', 'baaaab', 'aaaabb', 'aabaabb', 'abaaaabb', 'baaab', 'aaabaabb', 'ababaaabb', 'aabababb', 'babaab', 'aaabb', 'aaabaaabb', 'aaababb', 'bbaaaaab', 'aaaabaabb', 'aababaabb', 'abababb', 'bbaaaab', 'aabaaabb', 'abaaaaabb', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3812820017337799
Train Epoch 1, Loss 0.22818203270435333
Train Epoch 2, Loss 0.12482261657714844
Accuracy at epoch 59: 0.9423828125, total training samples: 1784
Early stopping at epoch 376. Loss did not improve for 10 epochs.
Generate examples Step 376, Loss 0.6186599623935608
Epoch: 60
Negative Examples
['aaaaabab', 'aaab', 'aaabab', 'aab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'ab']
Pos Pos Pos Pos Pos
Counterexamples
['aaaaabab', 'aababaaab', 'abababab', 'aabaaab', 'aaab', 'aabaaaaab', 'abaaabab', 'aaaabaab', 'aaabab', 'aababaaab', 'aaaabab', 'aaabaaab', 'aab', 'aaaaabaab', 'aaababab', 'aabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.4292298555374146
Train Epoch 1, Loss 0.936325192451477
Train Epoch 2, Loss 0.5869409441947937
Accuracy at epoch 60: 0.953125, total training samples: 1800
Early stopping at epoch 380. Loss did not improve for 10 epochs.
Generate examples Step 380, Loss 0.6589581256932787
Epoch: 61
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aaababab', 'aab', 'aabab', 'ab', 'abab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['bab', 'aabaabb', 'aabababb', 'aabaaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.2372678965330124
Train Epoch 1, Loss 0.15710289776325226
Train Epoch 2, Loss 0.10000910609960556
Accuracy at epoch 61: 0.9150390625, total training samples: 1804
Early stopping at epoch 398. Loss did not improve for 10 epochs.
Generate examples Step 398, Loss 0.7191080277724972
Epoch: 62
Negative Examples
['aab', 'ab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab']
Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aab', 'ababaabab', 'aabaaabab', 'ab', 'abababaab', 'aaaaab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.1814731359481812
Train Epoch 1, Loss 0.7795395851135254
Train Epoch 2, Loss 0.5008627772331238
Accuracy at epoch 62: 0.908203125, total training samples: 1812
Early stopping at epoch 275. Loss did not improve for 10 epochs.
Generate examples Step 275, Loss 0.43406400343646173
Epoch: 63
Negative Examples
['aa', 'abaabbab', 'abbab', 'b', 'baabbab', 'bbaaabaa']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabab', 'ab', 'abaab', 'baaaab', 'baab', 'babaab', 'bbaaaab', 'bbaaab', 'bbaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaab', 'aaabababb', 'abaabaabb', 'aabaababb', 'baab', 'abaaaaabb', 'aababaabb', 'ababaaabb', 'babaab', 'aabaaaabb', 'aabaababb', 'aaabaaabb', 'bbaaaab', 'aaaaabb', 'ababb', 'aaabababb', 'bbaaab', 'aaaabaabb', 'aaabaaabb', 'abaaabb', 'bbaabaab', 'abaaaaabb', 'aabb', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4292520582675934
Train Epoch 1, Loss 0.2750478684902191
Train Epoch 2, Loss 0.16098392009735107
Accuracy at epoch 63: 0.9482421875, total training samples: 1836
Early stopping at epoch 350. Loss did not improve for 10 epochs.
Generate examples Step 350, Loss 0.5217614099171087
Epoch: 64
Negative Examples
['aaaabab', 'aaabab', 'aab', 'abab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos
Counterexamples
['aaaabab', 'aaaabaaab', 'aabaabab', 'abaaabaab', 'aaabab', 'aabaabaab', 'aaab', 'aab', 'aab', 'aaaaaaaab', 'abaaabab', 'aabaaaab', 'abab', 'aaaababab', 'abaabab', 'abaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.9754981398582458
Train Epoch 1, Loss 0.6331407427787781
Train Epoch 2, Loss 0.4159667193889618
Accuracy at epoch 64: 0.923828125, total training samples: 1852
Early stopping at epoch 257. Loss did not improve for 10 epochs.
Generate examples Step 257, Loss 0.46411422663187796
Epoch: 65
Negative Examples
['abaa', 'b', 'bbaab']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabab', 'aaabab', 'aaabbab', 'aabab', 'ab', 'abaaabab', 'abaabab', 'abab', 'abababab', 'abbaaaab', 'baaabab', 'bab', 'bbaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbab', 'abaaaabb', 'ababababb', 'aaabaaabb', 'abbaaaab', 'aaaaabb', 'aabaababb', 'aaaaaaabb', 'baaabab', 'abaabb', 'abb', 'aababb', 'bab', 'aaaaababb', 'aaaaaabb', 'abababb', 'bbaaabab', 'abaabb', 'aabababb', 'aaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3910796642303467
Train Epoch 1, Loss 0.2704792320728302
Train Epoch 2, Loss 0.17489871382713318
Accuracy at epoch 65: 0.955078125, total training samples: 1872
Early stopping at epoch 368. Loss did not improve for 10 epochs.
Generate examples Step 368, Loss 0.574867630957911
Epoch: 66
Negative Examples
['aaaabab', 'aaabab', 'aab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'ab', 'baaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabab', 'abaaaabab', 'abaabab', 'aaaababab', 'aaabab', '', 'abaaab', 'aabaaabab', 'aab', 'aaababab', 'aabaab', 'abaabab', 'baaaaaab', 'abaaababb', 'aaaaaabb', 'aaababb']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.6439091563224792
Train Epoch 1, Loss 0.5101742148399353
Train Epoch 2, Loss 0.4264810383319855
Accuracy at epoch 66: 0.8818359375, total training samples: 1888
Early stopping at epoch 275. Loss did not improve for 10 epochs.
Generate examples Step 275, Loss 0.46144010229171184
Epoch: 67
Negative Examples
['aa', 'b']
Neg Neg
Positive Examples
['aaaaabaa', 'aaabaa', 'aaabab', 'aaababab', 'aabab', 'aabbbab', 'ab', 'abaa', 'abaaabaa', 'abab', 'ababaaab', 'ababab', 'abababab', 'baaaaab', 'bab', 'babab', 'bababab', 'bbab', 'bbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaabaa', 'ababaaaaa', 'aababaaba', 'abaababa', 'aaabaa', 'aababa', 'aaaaba', 'abaaaaaaa', 'aabbbab', 'abababb', 'aabaaabb', 'aaaaaabb', 'abaa', 'aaaaabaa', 'aaa', 'a', 'abaaabaa', 'aabaaa', 'aba', 'aaaabaaba', 'baaaaab', 'aaaaaabb', 'aaaabaabb', 'aabaaaabb', 'bab', 'aaaaaaabb', 'ababababb', 'aabb', 'babab', 'aabaabb', 'abb', 'aabababb', 'bababab', 'ababaaabb', 'aaaaaabb', 'abaaababb', 'bbab', 'aaabb', 'aaaaababb', 'aaaabb', 'bbabab', 'abaaaabb', 'aaaababb', 'abaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2885647416114807
Train Epoch 1, Loss 0.14190495386719704
Train Epoch 2, Loss 0.06608044914901257
Accuracy at epoch 67: 0.900390625, total training samples: 1932
Early stopping at epoch 595. Loss did not improve for 10 epochs.
Generate examples Step 595, Loss 0.862949483346619
Epoch: 68
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'aabaabab', 'abaaaaaab', 'abaab', 'aaaaaab', 'aabaabab', 'aabaaaaab', 'abaaabaab', 'aaaaab', 'ababaabab', 'abaaabab', 'aababaaab', 'aaaab', 'aaaaaabab', 'aaabaabab', 'aabaab', 'aaab', 'aababaaab', 'abaaaaaab', 'aaabaaaab', 'aab', 'aabababab', 'abab', 'aababab', 'ab', 'aaaabaaab', 'ab', 'aab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.9439668655395508
Train Epoch 1, Loss 1.42218816280365
Train Epoch 2, Loss 1.0049914121627808
Accuracy at epoch 68: 0.9716796875, total training samples: 1960
Early stopping at epoch 372. Loss did not improve for 10 epochs.
Generate examples Step 372, Loss 0.5693273299820621
Epoch: 69
Negative Examples
['aaaabab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabab', 'abaaaab', 'aaaaaaab', 'abaababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7095699310302734
Train Epoch 1, Loss 0.4655318856239319
Train Epoch 2, Loss 0.31008386611938477
Accuracy at epoch 69: 0.8984375, total training samples: 1964
Early stopping at epoch 263. Loss did not improve for 10 epochs.
Generate examples Step 263, Loss 0.3886131166734479
Epoch: 70
Negative Examples
['aa', 'aaaaaaa', 'aaabaa', 'aaababaa', 'aabaa', 'abbabaa', 'b', 'baa']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabab', 'abaaab', 'abab', 'ababab', 'abababab', 'abbab', 'abbbab', 'baabbab', 'bab', 'bbab', 'bbabab', 'bbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbab', 'aaaabaabb', 'abaaaaabb', 'ababababb', 'abbbab', 'aaaaabb', 'aabaabb', 'aabaaabb', 'baabbab', 'aaabaaabb', 'aabaabb', 'aaaaaabb', 'bab', 'aaaabaabb', 'abababb', 'abb', 'bbab', 'aabababb', 'abaabaabb', 'aaaaaabb', 'bbabab', 'aababaabb', 'aaabaaabb', 'ababaabb', 'bbbab', 'aabaaabb', 'aaabaabb', 'aaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2881789207458496
Train Epoch 1, Loss 0.20158635079860687
Train Epoch 2, Loss 0.1348419040441513
Accuracy at epoch 70: 0.958984375, total training samples: 1992
Early stopping at epoch 331. Loss did not improve for 10 epochs.
Generate examples Step 331, Loss 0.6905365823263145
Epoch: 71
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abaabaab', 'abaaab', 'aaababaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.0259569883346558
Train Epoch 1, Loss 0.5989769101142883
Train Epoch 2, Loss 0.3414909839630127
Accuracy at epoch 71: 0.9111328125, total training samples: 1996
Early stopping at epoch 274. Loss did not improve for 10 epochs.
Generate examples Step 274, Loss 0.283896586840803
Epoch: 72
Negative Examples
['aa', 'aaa', 'aabbbaaa', 'abaaa', 'ababaaa', 'abbab', 'abbabab', 'b', 'baaa', 'bbaabaaa', 'bbbab', 'bbbbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaabbaab', 'ab', 'abaab', 'ababaab', 'abbaab', 'baab', 'baabbaab', 'babaab', 'bbaab', 'bbabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'abaaabb', 'aabaaaabb', 'aabaabb', 'abbaab', 'aabaaabb', 'aaaaaaabb', 'ababababb', 'baab', 'abaababb', 'aaaaaaabb', 'aabaaaabb', 'baabbaab', 'ababababb', 'aaaaababb', 'aabaaaabb', 'babaab', 'aababb', 'ababaaabb', 'abaabb', 'bbaab', 'abaabb', 'aaabaaabb', 'abababb', 'bbabaab', 'abaaababb', 'aabb', 'aaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.42057564854621887
Train Epoch 1, Loss 0.2602921724319458
Train Epoch 2, Loss 0.14868353307247162
Accuracy at epoch 72: 0.939453125, total training samples: 2024
Early stopping at epoch 356. Loss did not improve for 10 epochs.
Generate examples Step 356, Loss 0.7239740321449205
Epoch: 73
Negative Examples
['aab', 'aabab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'ab', 'baaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aaaababab', 'ababab', 'abaaabaab', 'aabab', 'aaaabab', 'aababaaab', 'aaabaab', 'baaaaaab', 'ababababb', 'aaaababb', 'abababb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.6237543225288391
Train Epoch 1, Loss 0.4981875717639923
Train Epoch 2, Loss 0.4180941581726074
Accuracy at epoch 73: 0.90234375, total training samples: 2036
Early stopping at epoch 285. Loss did not improve for 10 epochs.
Generate examples Step 285, Loss 0.4637832951087218
Epoch: 74
Negative Examples
['aa', 'aaaa', 'b']
Neg Neg Neg
Positive Examples
['aaaabab', 'aaaabbab', 'aaabab', 'aabab', 'aababab', 'aabbabab', 'ab', 'abaaab', 'abab', 'abbaaab', 'bab', 'bababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'aabaaabb', 'aababb', 'ababaabb', 'aabbabab', 'abaababb', 'abaabb', 'aaaaaaabb', 'abbaaab', 'abaaaaabb', 'abaabaabb', 'aaaabb', 'bab', 'aaaaaaabb', 'abb', 'aaababb', 'bababab', 'abaababb', 'aaaaabb', 'ababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3425252139568329
Train Epoch 1, Loss 0.24268130958080292
Train Epoch 2, Loss 0.16196805238723755
Accuracy at epoch 74: 0.9482421875, total training samples: 2056
Early stopping at epoch 413. Loss did not improve for 10 epochs.
Generate examples Step 413, Loss 0.5956509649249666
Epoch: 75
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abababaab', 'abaababab', 'abaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.209599256515503
Train Epoch 1, Loss 0.8015956878662109
Train Epoch 2, Loss 0.5210729241371155
Accuracy at epoch 75: 0.890625, total training samples: 2060
Early stopping at epoch 287. Loss did not improve for 10 epochs.
Generate examples Step 287, Loss 0.43735152426072293
Epoch: 76
Negative Examples
['aaa', 'aabaaa', 'abaaa', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaabbab', 'aaabbab', 'aab', 'aabbab', 'ab', 'abbab', 'baaabaab', 'baab', 'baabaab', 'bab', 'bbaabbab', 'bbab', 'bbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'aaaaaabb', 'aaaaababb', 'aaabaaabb', 'aaabbab', 'abaabb', 'ababaabb', 'aaababb', 'aabbab', 'ababb', 'abaaaaabb', 'abababb', 'abbab', 'aabaaaabb', 'aabb', 'aaaaaaabb', 'baaabaab', 'aaababb', 'aabaaaabb', 'aabababb', 'baab', 'abababb', 'ababb', 'aaaabaabb', 'baabaab', 'aababaabb', 'ababaabb', 'aaaabaabb', 'bab', 'abaababb', 'aaaabaabb', 'aaabaabb', 'bbaabbab', 'aaaaaaabb', 'aaaabb', 'aabaabb', 'bbab', 'abaababb', 'abaabaabb', 'aaabb', 'bbbab', 'aaaabb', 'aabababb', 'aaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2707308605313301
Train Epoch 1, Loss 0.1194821409881115
Train Epoch 2, Loss 0.05182211473584175
Accuracy at epoch 76: 0.9013671875, total training samples: 2104
Early stopping at epoch 553. Loss did not improve for 10 epochs.
Generate examples Step 553, Loss 0.8665258948445751
Epoch: 77
Negative Examples
['aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab']
Pos Pos Pos
Counterexamples
['aaaab', '', 'aaababaab', 'aaaaab', 'aaab', 'aaaabab', 'aabaaaaab', 'aaababab', 'aab', 'abaaaab', 'aaaab', 'aaabaab', 'ab', 'aaabaabab', 'aaaababab', 'aaabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.5352137088775635
Train Epoch 1, Loss 1.0845081806182861
Train Epoch 2, Loss 0.7638018727302551
Accuracy at epoch 77: 0.9453125, total training samples: 2120
Early stopping at epoch 381. Loss did not improve for 10 epochs.
Generate examples Step 381, Loss 0.45943782786736315
Epoch: 78
Negative Examples
['abab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabab', 'aab', 'aabaaab', 'ab', 'abaaab', 'abbaaab', 'baaab', 'baabaaab', 'bbabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abab', 'aabab', 'aaaabaab', 'abaaaab', 'abbaaab', 'abaaaabb', 'aabababb', 'aaaababb', 'baaab', 'abaababb', 'aaaaababb', 'abaabb', 'baabaaab', 'aaabb', 'aaaaababb', 'abababb', 'bbabaaab', 'aaabaabb', 'aaabb', 'aaababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4841780662536621
Train Epoch 1, Loss 0.37908533215522766
Train Epoch 2, Loss 0.30203428864479065
Accuracy at epoch 78: 0.9345703125, total training samples: 2140
Early stopping at epoch 243. Loss did not improve for 10 epochs.
Generate examples Step 243, Loss 0.48915720364597975
Epoch: 79
Negative Examples
['aabaa', 'aababaaa', 'b']
Neg Neg Neg
Positive Examples
['aaaaa', 'aaaaaaa', 'aaaabab', 'aaab', 'aaabaa', 'aaabab', 'aab', 'aabaabab', 'aabab', 'ab', 'abab', 'abbab', 'baabaab', 'baabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaa', 'aaaaaabaa', 'aaabaaba', 'aaaabaaa', 'aaaaaaa', 'aaaababaa', 'aaaabaaba', 'aaaaaaa', 'aaabaa', 'aaabababa', 'aaababaa', 'aaaa', 'abbab', 'ababaaabb', 'abaaababb', 'abb', 'baabaab', 'aabaaaabb', 'ababaabb', 'abaaabb', 'baabab', 'aaaabb', 'aaaaaaabb', 'ababababb', 'bab', 'abaaaaabb', 'aaaaababb', 'ababababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.43246179819107056
Train Epoch 1, Loss 0.31285661458969116
Train Epoch 2, Loss 0.2247888296842575
Accuracy at epoch 79: 0.9599609375, total training samples: 2168
Early stopping at epoch 407. Loss did not improve for 10 epochs.
Generate examples Step 407, Loss 0.5037078693070832
Epoch: 80
Negative Examples
['aaabab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabab', 'aaaababab', 'aaabaabab', 'aabababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.9399408102035522
Train Epoch 1, Loss 0.5432911515235901
Train Epoch 2, Loss 0.2986869215965271
Accuracy at epoch 80: 0.904296875, total training samples: 2172
Early stopping at epoch 256. Loss did not improve for 10 epochs.
Generate examples Step 256, Loss 0.37850075890581897
Epoch: 81
Negative Examples
['aa', 'aaababaa', 'aababaab', 'abaa', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaabbab', 'aaabaa', 'aaabaaab', 'aaababab', 'aabaaab', 'aabab', 'aababab', 'aabbaaab', 'ab', 'abab', 'ababab', 'abbbab', 'bab', 'babab', 'babbbab', 'bbab', 'bbbbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aababaab', 'aaaab', 'aaaaab', 'abaababab', 'aaaabbab', 'ababaaabb', 'aababb', 'abaaabb', 'aaabaa', 'aaaaba', 'aaaaaaaaa', 'ababaa', 'aabbaaab', 'abaaaabb', 'abaabb', 'ababababb', 'abbbab', 'abaaababb', 'aaabaaabb', 'aaabb', 'bab', 'aaaaaaabb', 'abb', 'abaabb', 'babab', 'abaaababb', 'aaaaabb', 'aaababb', 'babbbab', 'aaabaabb', 'aababb', 'ababaaabb', 'bbab', 'aaaaabb', 'aaababb', 'aaaabaabb', 'bbbbab', 'aaababb', 'aabaabb', 'ababababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3182135820388794
Train Epoch 1, Loss 0.23415691405534744
Train Epoch 2, Loss 0.20003753900527954
Accuracy at epoch 81: 0.9287109375, total training samples: 2212
Early stopping at epoch 354. Loss did not improve for 10 epochs.
Generate examples Step 354, Loss 0.4696704232776669
Epoch: 82
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aabab', 'ab', 'abaab', 'abaabab', 'ababaab', 'baaaab', 'baabaab', 'bbaaaaab', 'bbaaaab', 'bbaaab', 'bbaabab', 'bbabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaab', 'aabababb', 'aaabb', 'aaaabb', 'baabaab', 'aababb', 'ababb', 'aabaaaabb', 'bbaaaaab', 'abb', 'aabababb', 'aaaaaaabb', 'bbaaaab', 'aababb', 'abaaaabb', 'ababaabb', 'bbaaab', 'aaaabaabb', 'b', 'ababaaabb', 'bbaabab', 'ababaaabb', 'aaaaabb', 'abb', 'bbabaab', 'b', 'abaabb', 'aabaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5073836445808411
Train Epoch 1, Loss 0.32185429334640503
Train Epoch 2, Loss 0.18513096868991852
Accuracy at epoch 82: 0.9716796875, total training samples: 2240
Early stopping at epoch 409. Loss did not improve for 10 epochs.
Generate examples Step 409, Loss 0.634502262749323
Epoch: 83
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abababab', 'aaaaaaab', 'abababaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.1555315256118774
Train Epoch 1, Loss 0.7849200367927551
Train Epoch 2, Loss 0.5064244270324707
Accuracy at epoch 83: 0.90625, total training samples: 2244
Early stopping at epoch 399. Loss did not improve for 10 epochs.
Generate examples Step 399, Loss 0.5115931086242199
Epoch: 84
Negative Examples
['aa', 'b']
Neg Neg
Positive Examples
['aaaabbab', 'aaab', 'aaabaab', 'aaabbab', 'aab', 'aabaab', 'aabab', 'ab', 'abaab', 'baab', 'baabab', 'bab', 'babaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'aaaaabb', 'aabababb', 'abaabaabb', 'aaabbab', 'aabaaabb', 'aaabaaabb', 'abaabb', 'baab', 'abaaababb', 'ababaabb', 'aababb', 'baabab', 'aaaababb', 'ababaaabb', 'b', 'bab', 'aaabaabb', 'aabaaaabb', 'aabaabb', 'babaab', 'ababababb', 'aabb', 'aaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.31340309977531433
Train Epoch 1, Loss 0.2080010324716568
Train Epoch 2, Loss 0.13181127607822418
Accuracy at epoch 84: 0.94140625, total training samples: 2268
Early stopping at epoch 328. Loss did not improve for 10 epochs.
Generate examples Step 328, Loss 0.5643126313718981
Epoch: 85
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'ab', 'baaaaaab', 'baaaaab', 'bbaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aabaab', 'aaaabaab', 'aaaaab', 'baaaaaab', 'abaaaabb', 'abb', 'abaaaaabb', 'baaaaab', 'b', 'aaabaabb', 'ababaabb', 'bbaaaaab', 'aaaabb', 'aaaaababb', 'aababaabb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5527490377426147
Train Epoch 1, Loss 0.4073347747325897
Train Epoch 2, Loss 0.330360472202301
Accuracy at epoch 85: 0.97265625, total training samples: 2284
Early stopping at epoch 307. Loss did not improve for 10 epochs.
Generate examples Step 307, Loss 0.47992821226452853
Epoch: 86
Negative Examples
['aabbab', 'b']
Neg Neg
Positive Examples
['aaaab', 'aaaabaaa', 'aaaabaab', 'aaabaaa', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaab', 'baab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaaa', 'abababaa', 'ababaaa', 'aabaaaaaa', 'aaabaaa', 'abaaa', 'aba', 'aabaaba', 'baab', 'abaaaabb', 'aaabb', 'abaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3222672641277313
Train Epoch 1, Loss 0.17649824917316437
Train Epoch 2, Loss 0.09644178301095963
Accuracy at epoch 86: 0.9462890625, total training samples: 2296
Early stopping at epoch 410. Loss did not improve for 10 epochs.
Generate examples Step 410, Loss 0.5645110065484569
Epoch: 87
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abaaaabab', 'aabaaaaab', 'aab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.904218316078186
Train Epoch 1, Loss 0.550868570804596
Train Epoch 2, Loss 0.335769385099411
Accuracy at epoch 87: 0.943359375, total training samples: 2300
Early stopping at epoch 285. Loss did not improve for 10 epochs.
Generate examples Step 285, Loss 0.4104119141201873
Epoch: 88
Negative Examples
['aa', 'aaaaa', 'b', 'baaaaaa']
Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaaabaab', 'aaaabab', 'aaababab', 'aabaaaab', 'aabaab', 'aababab', 'ab', 'abaaab', 'abab', 'ababab', 'abababab', 'abbaaab', 'baaab', 'baab', 'baabaaab', 'bab', 'babaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaaab', 'aaaabb', 'abaababb', 'aabb', 'baaab', 'aabaaabb', 'aaabababb', 'abb', 'baab', 'aaaaababb', 'aaaaabb', 'aaababb', 'baabaaab', 'abb', 'aaaabb', 'abaaababb', 'bab', 'aaaaaabb', 'abaabb', 'aaaababb', 'babaaab', 'aabaaabb', 'abaabaabb', 'ababaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.31905075907707214
Train Epoch 1, Loss 0.20014609396457672
Train Epoch 2, Loss 0.12202408909797668
Accuracy at epoch 88: 0.943359375, total training samples: 2324
Early stopping at epoch 455. Loss did not improve for 10 epochs.
Generate examples Step 455, Loss 0.713759269434632
Epoch: 89
Negative Examples
['aaab', 'aaabab', 'aab', 'aabab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'ab']
Pos Pos Pos Pos Pos
Counterexamples
['aaab', 'abab', 'aaaaaab', 'aabaabaab', 'aaabab', 'aaababab', 'aaaabaaab', 'aabaaaaab', 'aab', 'aaabab', 'abaaaaaab', 'aaabaaab', 'aabab', 'aabaabab', 'abaaaab', 'aaaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.8774639368057251
Train Epoch 1, Loss 0.5061652660369873
Train Epoch 2, Loss 0.2965410351753235
Accuracy at epoch 89: 0.939453125, total training samples: 2340
Early stopping at epoch 286. Loss did not improve for 10 epochs.
Generate examples Step 286, Loss 0.49588296871359755
Epoch: 90
Negative Examples
['aa', 'aabaa', 'b']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaaabaa', 'aaaaabab', 'aaaabaa', 'aaaabab', 'aaab', 'aaabab', 'aabab', 'ab', 'abaabbab', 'abab', 'ababab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaabaa', 'aaaaababa', 'ababaaba', 'aaaabaaa', 'aaaabaa', 'aaaababa', 'aaabaa', 'aabaaba', 'abaabbab', 'aaaababb', 'ababaaabb', 'aaabaabb', 'bab', 'aaaabaabb', 'aabababb', 'aaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.32717394828796387
Train Epoch 1, Loss 0.20460309088230133
Train Epoch 2, Loss 0.12624961137771606
Accuracy at epoch 90: 0.96484375, total training samples: 2356
Early stopping at epoch 305. Loss did not improve for 10 epochs.
Generate examples Step 305, Loss 0.6046582340609794
Epoch: 91
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 91: No counterexamples found, skipped.
Early stopping at epoch 295. Loss did not improve for 10 epochs.
Generate examples Step 295, Loss 0.6267830886550851
Epoch: 92
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 92: No counterexamples found, skipped.
Early stopping at epoch 334. Loss did not improve for 10 epochs.
Generate examples Step 334, Loss 0.6949017803170787
Epoch: 93
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'bbaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['bbaaaaab', 'aabaabb', 'aaababb', 'aaabaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.23694667220115662
Train Epoch 1, Loss 0.11373255401849747
Train Epoch 2, Loss 0.06061022728681564
Accuracy at epoch 93: 0.90234375, total training samples: 2360
Early stopping at epoch 647. Loss did not improve for 10 epochs.
Generate examples Step 647, Loss 0.6730180499546322
Epoch: 94
Negative Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
[]

Counterexamples
['aaaaaaab', 'aababaaab', 'abababab', 'aabab', 'aaaaaab', 'ababaabab', 'aaababab', 'aaababaab', 'aaaaab', 'aaaabab', 'abaaaabab', 'abaaaab', 'aaaab', 'ababaaaab', 'aab', 'aaaaaaaab', 'aaab', 'abaababab', 'aaaaabaab', 'aaabaaab', 'aab', 'aaabaabab', 'aaababaab', 'aaaaabaab', 'ab', 'abaaaabab', 'abaababab', 'aaabaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.7751487493515015
Train Epoch 1, Loss 1.2222908735275269
Train Epoch 2, Loss 0.8066521883010864
Accuracy at epoch 94: 0.9677734375, total training samples: 2388
Early stopping at epoch 342. Loss did not improve for 10 epochs.
Generate examples Step 342, Loss 0.5166745995641102
Epoch: 95
Negative Examples
['b', 'bbabab']
Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aab', 'aabab', 'ab', 'abab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['bab', 'aabaabb', 'abaaaaabb', 'ababaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.23973305523395538
Train Epoch 1, Loss 0.14753806591033936
Train Epoch 2, Loss 0.08806286752223969
Accuracy at epoch 95: 0.900390625, total training samples: 2392
Early stopping at epoch 362. Loss did not improve for 10 epochs.
Generate examples Step 362, Loss 0.7517677943322284
Epoch: 96
Negative Examples
['aaab', 'ab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab']
Pos Pos Pos Pos
Counterexamples
['aaab', 'aababaaab', 'aaaababab', 'aaabaab', 'ab', 'aaaab', 'aaabaaaab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.1917353868484497
Train Epoch 1, Loss 0.7407001256942749
Train Epoch 2, Loss 0.4489525854587555
Accuracy at epoch 96: 0.9580078125, total training samples: 2400
Early stopping at epoch 466. Loss did not improve for 10 epochs.
Generate examples Step 466, Loss 0.5603976843507693
Epoch: 97
Negative Examples
['b']
Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaab', 'baabaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baabaab', 'aaababb', 'aabaababb', 'abababb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.3224019706249237
Train Epoch 1, Loss 0.14987725019454956
Train Epoch 2, Loss 0.06886428594589233
Accuracy at epoch 97: 0.951171875, total training samples: 2404
Early stopping at epoch 354. Loss did not improve for 10 epochs.
Generate examples Step 354, Loss 0.6992993182279694
Epoch: 98
Negative Examples
['aabaaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaaab', 'aabaaab', 'aaaaabaab', 'abababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.9509193301200867
Train Epoch 1, Loss 0.5323118567466736
Train Epoch 2, Loss 0.3187882602214813
Accuracy at epoch 98: 0.958984375, total training samples: 2408
Early stopping at epoch 311. Loss did not improve for 10 epochs.
Generate examples Step 311, Loss 0.4706926801456855
Epoch: 99
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaabaaab', 'aaabaab', 'aaababab', 'aaabbaab', 'aab', 'aababab', 'ab', 'abaaabab', 'abab', 'ababab', 'abbbaaab', 'baaabab', 'baabaaab', 'babab', 'bababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'aaaaaabb', 'aaaaaaabb', 'b', 'abbbaaab', 'abaaaabb', 'aabaaabb', 'aaaaaaabb', 'baaabab', 'aaaabb', 'aaababb', 'aaaaababb', 'baabaaab', 'aababb', 'abaaaabb', 'aaaaaaabb', 'babab', 'abaaabb', 'ababababb', 'aabaababb', 'bababab', 'aababb', 'ababababb', 'aabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.39337560534477234
Train Epoch 1, Loss 0.2497176080942154
Train Epoch 2, Loss 0.1550397127866745
Accuracy at epoch 99: 0.9482421875, total training samples: 2432
Early stopping at epoch 445. Loss did not improve for 10 epochs.
Generate examples Step 445, Loss 0.6485332827263349
Epoch: 100
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aababab', 'aaabaab', 'abaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.130392074584961
Train Epoch 1, Loss 0.7300975322723389
Train Epoch 2, Loss 0.46723783016204834
Accuracy at epoch 100: 0.9189453125, total training samples: 2436
Early stopping at epoch 348. Loss did not improve for 10 epochs.
Generate examples Step 348, Loss 0.36894313867249257
Epoch: 101
Negative Examples
['aa', 'b']
Neg Neg
Positive Examples
['aaaaabab', 'aaaab', 'aaaabab', 'aaaabbab', 'aaabaab', 'aaabbaab', 'aab', 'aabaab', 'aabab', 'aababab', 'ab', 'abaaab', 'abaab', 'abab', 'ababaaab', 'babab', 'bbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'abaabaabb', 'aabaaaabb', 'aaaaabb', 'aaabbaab', 'abaaababb', 'ababb', 'aaaabaabb', 'babab', 'aaabaaabb', 'ababaabb', 'aaaababb', 'bbab', 'abaaaaabb', 'aabb', 'aaaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3297988474369049
Train Epoch 1, Loss 0.2107030302286148
Train Epoch 2, Loss 0.12729862332344055
Accuracy at epoch 101: 0.9541015625, total training samples: 2452
Early stopping at epoch 387. Loss did not improve for 10 epochs.
Generate examples Step 387, Loss 0.5216784404648334
Epoch: 102
Negative Examples
['aaababab', 'aab', 'aabab', 'abab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aabaaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaababab', 'aabababab', 'aab', 'abaaabab', 'aab', 'ababaabab', 'aabaabaab', 'abababaab', 'aabab', 'aaaabab', 'abababab', 'aaababab', 'abab', 'aababab', 'aaaaab', 'aaaababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.0776759386062622
Train Epoch 1, Loss 0.7004567980766296
Train Epoch 2, Loss 0.4531451463699341
Accuracy at epoch 102: 0.923828125, total training samples: 2468
Early stopping at epoch 306. Loss did not improve for 10 epochs.
Generate examples Step 306, Loss 0.5112033628097187
Epoch: 103
Negative Examples
['abaa', 'b', 'bbab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabab', 'aabab', 'aababab', 'ab', 'abab', 'ababab', 'bab', 'babab', 'bbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['bab', 'ababaaabb', 'aaaababb', 'abb', 'babab', 'aaaababb', 'abaaababb', 'aabaaaabb', 'bbabab', 'aababb', 'aaaaaaabb', 'abaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3341330587863922
Train Epoch 1, Loss 0.21956415474414825
Train Epoch 2, Loss 0.14000304043293
Accuracy at epoch 103: 0.9716796875, total training samples: 2480
Early stopping at epoch 483. Loss did not improve for 10 epochs.
Generate examples Step 483, Loss 0.6310594420541417
Epoch: 104
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aab', 'aabaaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 104: No counterexamples found, skipped.
Early stopping at epoch 394. Loss did not improve for 10 epochs.
Generate examples Step 394, Loss 0.7318265058571779
Epoch: 105
Negative Examples
['aaabab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabab', 'aaaababab', 'aaaaaab', 'ababaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7164268493652344
Train Epoch 1, Loss 0.37239184975624084
Train Epoch 2, Loss 0.18237057328224182
Accuracy at epoch 105: 0.9326171875, total training samples: 2484
Early stopping at epoch 300. Loss did not improve for 10 epochs.
Generate examples Step 300, Loss 0.3668615373464122
Epoch: 106
Negative Examples
['aa', 'aaaa', 'aaaaa', 'abaab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaa', 'aaabaa', 'aab', 'aabab', 'aabbaab', 'ab', 'abaaab', 'abab', 'baaaab', 'baaab', 'baabaaaa', 'bab', 'babab', 'bababab', 'bbaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaab', 'abaaabab', 'aaaaabab', 'abaaabaab', 'aaaaaa', 'aaaaba', 'a', 'aabaaa', 'aaabaa', 'abababaa', 'aaaaaaba', 'aaaaaaaaa', 'aabbaab', 'aaaaabb', 'ababaaabb', 'abaabaabb', 'baaaab', 'aaabababb', 'aabaaabb', 'aaaabb', 'baaab', 'abaabb', 'abaababb', 'aaaabb', 'baabaaaa', 'ababaabb', 'aabaabb', 'aaabaaabb', 'bab', 'aabaaaabb', 'aaaaababb', 'abaabb', 'babab', 'b', 'aabaabb', 'abaaabb', 'bababab', 'abaabb', 'abaabaabb', 'aaabaaabb', 'bbaaaab', 'aabaababb', 'ababababb', 'aababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.36462685465812683
Train Epoch 1, Loss 0.23330356925725937
Train Epoch 2, Loss 0.18468213081359863
Accuracy at epoch 106: 0.9638671875, total training samples: 2528
Early stopping at epoch 343. Loss did not improve for 10 epochs.
Generate examples Step 343, Loss 0.45547600510681785
Epoch: 107
Negative Examples
['aa', 'aaaaa', 'aabaaa', 'aababbab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaabaab', 'aaabbaab', 'aaabbab', 'aab', 'aabaab', 'ab', 'abaab', 'abaabaab', 'ababaab', 'baab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'abaaabb', 'aaaabb', 'aaaaabb', 'aaabbab', 'ababaabb', 'aabaaabb', 'ababaaabb', 'baab', 'aaabb', 'abaaaabb', 'aabaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3112800419330597
Train Epoch 1, Loss 0.158293217420578
Train Epoch 2, Loss 0.08228269964456558
Accuracy at epoch 107: 0.9306640625, total training samples: 2540
Early stopping at epoch 617. Loss did not improve for 10 epochs.
Generate examples Step 617, Loss 0.7665169973975247
Epoch: 108
Negative Examples
['aaaabab', 'aaab', 'aab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'ab']
Pos Pos Pos Pos Pos
Counterexamples
['aaaabab', 'abab', 'aaaaaaab', 'aaababaab', 'aaab', 'aaaaaaab', 'aaabab', 'abaabaab', 'aab', 'abaabab', 'aabaabaab', 'aaaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.1390835046768188
Train Epoch 1, Loss 0.7087915539741516
Train Epoch 2, Loss 0.41430962085723877
Accuracy at epoch 108: 0.9453125, total training samples: 2552
Early stopping at epoch 373. Loss did not improve for 10 epochs.
Generate examples Step 373, Loss 0.5451984803147495
Epoch: 109
Negative Examples
['abaaaaaa', 'abab', 'ababab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabab', 'aaab', 'aaabab', 'aaabbab', 'aab', 'aabaabab', 'aabab', 'ab', 'abaabab', 'baaabbab', 'baabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abab', 'abaaaaab', 'abababaab', 'aaaabaab', 'ababab', 'aabaaaab', 'aabaab', 'aabab', 'aaabbab', 'aaaababb', 'abaabaabb', 'aaabaaabb', 'baaabbab', 'abaaabb', 'aaaaaabb', 'aaaaabb', 'baabab', 'aaaaabb', 'aabb', 'aaaababb', 'bab', 'aaaaaabb', 'aaaaababb', 'aaaababb']
Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3553057909011841
Train Epoch 1, Loss 0.30814307928085327
Train Epoch 2, Loss 0.27705058455467224
Accuracy at epoch 109: 0.9013671875, total training samples: 2576
Early stopping at epoch 390. Loss did not improve for 10 epochs.
Generate examples Step 390, Loss 0.5619659479850393
Epoch: 110
Negative Examples
['aa', 'aaababaa', 'aabaa', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabab', 'aaabaab', 'aaabab', 'aab', 'aabaab', 'aabab', 'aabbaaab', 'ab', 'ababab', 'baab', 'baabab', 'baabbaab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaaab', 'aaabaaabb', 'abaabaabb', 'abaaababb', 'baab', 'ababaaabb', 'abaabaabb', 'abaababb', 'baabab', 'aaababb', 'abaabb', 'abaaababb', 'baabbaab', 'abaabaabb', 'aaaaababb', 'aabb', 'bab', 'aabaaaabb', 'aabaabb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.32843226194381714
Train Epoch 1, Loss 0.21000465750694275
Train Epoch 2, Loss 0.12829290330410004
Accuracy at epoch 110: 0.970703125, total training samples: 2596
Early stopping at epoch 387. Loss did not improve for 10 epochs.
Generate examples Step 387, Loss 0.6765111884505478
Epoch: 111
Negative Examples
['aabab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'aaaabab', 'aaabaaab', 'aabaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5455394983291626
Train Epoch 1, Loss 0.20849023759365082
Train Epoch 2, Loss 0.0853678286075592
Accuracy at epoch 111: 0.931640625, total training samples: 2600
Early stopping at epoch 339. Loss did not improve for 10 epochs.
Generate examples Step 339, Loss 0.5233804254847414
Epoch: 112
Negative Examples
['abaab', 'b', 'bbab']
Neg Neg Neg
Positive Examples
['aaaaabaa', 'aaaab', 'aaab', 'aaabaa', 'aaabab', 'aab', 'aabaaaa', 'aabaabaa', 'aababab', 'ab', 'abaaabaa', 'abab', 'ababab', 'baaaabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaab', 'abaaaab', 'aaaaab', 'aabababab', 'aaaaabaa', 'abaabaaaa', 'abababa', 'abaaaaaaa', 'aaabaa', 'aaa', 'abaaaabaa', 'aaaabaaba', 'aabaaaa', 'aaabababa', 'abaabaa', 'aabaababa', 'aabaabaa', 'aaaaaa', 'abaaaa', 'aaabaaa', 'abaaabaa', 'aaaaaaa', 'aaaaaaaa', 'aaaba', 'baaaabab', 'aaaabaabb', 'aababb', 'abaaaaabb', 'bab', 'ababaabb', 'aaaaaaabb', 'aabaaaabb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5410215854644775
Train Epoch 1, Loss 0.3795201778411865
Train Epoch 2, Loss 0.2890982925891876
Accuracy at epoch 112: 0.908203125, total training samples: 2632
Early stopping at epoch 308. Loss did not improve for 10 epochs.
Generate examples Step 308, Loss 0.5534065525894412
Epoch: 113
Negative Examples
['aa', 'abaaabaa', 'b']
Neg Neg Neg
Positive Examples
['aaaabbab', 'aaab', 'aaabaab', 'aaabab', 'aabaab', 'aabaabab', 'aabab', 'aababaab', 'ab', 'abaab', 'abaabab', 'abab', 'abababab', 'abbab', 'baabab', 'bab', 'babaab', 'bbabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbab', 'abababb', 'abaaabb', 'abaaaabb', 'abbab', 'aaabb', 'aabaababb', 'aaaabb', 'baabab', 'ababb', 'aaaaaabb', 'aababb', 'bab', 'abababb', 'abb', 'abaaaaabb', 'babaab', 'aaaabaabb', 'abaaaabb', 'abaababb', 'bbabbab', 'aabaabb', 'aaabababb', 'abaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.30245110392570496
Train Epoch 1, Loss 0.17952941358089447
Train Epoch 2, Loss 0.10253571718931198
Accuracy at epoch 113: 0.958984375, total training samples: 2656
Early stopping at epoch 320. Loss did not improve for 10 epochs.
Generate examples Step 320, Loss 0.7154785834276045
Epoch: 114
Negative Examples
['aaabab', 'aabab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaab', 'ab', 'abaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabab', 'aaaababab', 'aaabab', 'aaaabaab', 'aabab', 'ababaaaab', 'abaaaaab', 'aaabab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.815267026424408
Train Epoch 1, Loss 0.4057357907295227
Train Epoch 2, Loss 0.20351284742355347
Accuracy at epoch 114: 0.939453125, total training samples: 2664
Early stopping at epoch 398. Loss did not improve for 10 epochs.
Generate examples Step 398, Loss 0.5348797806895765
Epoch: 115
Negative Examples
['aabaa', 'b']
Neg Neg
Positive Examples
['aaaaaa', 'aaaab', 'aaaabaa', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabaab', 'aababab', 'ab', 'abab', 'ababab', 'abbaabab', 'baaab', 'baaabab', 'bab', 'babab', 'bababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaaa', 'aaaaaba', 'abaa', 'aaaaaaaba', 'aaaabaa', 'aaabaaaa', 'aaabaaaba', 'aabababaa', 'abbaabab', 'aaaababb', 'ababaabb', 'aabaababb', 'baaab', 'ababb', 'abaabb', 'ababaabb', 'baaabab', 'aaababb', 'abababb', 'ababaaabb', 'bab', 'aabaaaabb', 'aabaabb', 'aaaabaabb', 'babab', 'aabaabb', 'abaababb', 'aaaaabb', 'bababab', 'abaaaabb', 'aaabaabb', 'aaabababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.35712704062461853
Train Epoch 1, Loss 0.21557997167110443
Train Epoch 2, Loss 0.12859784066677094
Accuracy at epoch 115: 0.9658203125, total training samples: 2696
Early stopping at epoch 387. Loss did not improve for 10 epochs.
Generate examples Step 387, Loss 0.6289049222604516
Epoch: 116
Negative Examples
['aaabab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabab', 'aaaaabab', 'ababaaab', 'aaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7037647366523743
Train Epoch 1, Loss 0.3670428991317749
Train Epoch 2, Loss 0.17310690879821777
Accuracy at epoch 116: 0.93359375, total training samples: 2700
Early stopping at epoch 290. Loss did not improve for 10 epochs.
Generate examples Step 290, Loss 0.45484342428621966
Epoch: 117
Negative Examples
['b', 'baaaaaa', 'baab']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaabab', 'aaababab', 'aab', 'aabaab', 'aabab', 'ab', 'abaaab', 'abaab', 'abab', 'abababab', 'baaabab', 'baabaab', 'bababab', 'bbaaaab', 'bbabaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaabab', 'aabababb', 'aabb', 'abaabb', 'baabaab', 'ababb', 'aaaaababb', 'aaabaabb', 'bababab', 'abb', 'ababaaabb', 'b', 'bbaaaab', 'abababb', 'aabababb', 'abaaaaabb', 'bbabaaab', 'abaaabb', 'ababababb', 'ababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.37622469663619995
Train Epoch 1, Loss 0.21101541817188263
Train Epoch 2, Loss 0.12135301530361176
Accuracy at epoch 117: 0.9765625, total training samples: 2720
Early stopping at epoch 568. Loss did not improve for 10 epochs.
Generate examples Step 568, Loss 0.6750895870171867
Epoch: 118
Negative Examples
['aabaaab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaaab', 'abaaaaaab', 'aababab', 'abaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.905671238899231
Train Epoch 1, Loss 0.45697492361068726
Train Epoch 2, Loss 0.22700193524360657
Accuracy at epoch 118: 0.9248046875, total training samples: 2724
Early stopping at epoch 364. Loss did not improve for 10 epochs.
Generate examples Step 364, Loss 0.5091835537593659
Epoch: 119
Negative Examples
['aaaa', 'aabaa', 'aababaa', 'b', 'baaaabaa']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaabaa', 'aaaabab', 'aab', 'aabab', 'aababab', 'aabbbab', 'ab', 'abaaabab', 'ababaaab', 'abababab', 'baaabab', 'bab', 'babaaab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaa', 'abaaabaa', 'abaaaabaa', 'aaababaa', 'aabbbab', 'ababababb', 'ababaaabb', 'abababb', 'baaabab', 'aaaabaabb', 'aaaaababb', 'abababb', 'bab', 'abaaababb', 'abb', 'aabababb', 'babaaab', 'aaaaababb', 'abaabaabb', 'abaabb', 'babab', 'b', 'aaaabaabb', 'aababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.454943984746933
Train Epoch 1, Loss 0.27116063237190247
Train Epoch 2, Loss 0.1600077897310257
Accuracy at epoch 119: 0.98046875, total training samples: 2748
Early stopping at epoch 486. Loss did not improve for 10 epochs.
Generate examples Step 486, Loss 0.6924931429923192
Epoch: 120
Negative Examples
['aabab', 'b']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aaabaaab', 'aab', 'aabaaab', 'ab', 'baaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'abaabab', 'aabaab', 'ab', 'baaaaab', 'abb', 'aaaaaaabb', 'aababb']
Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.5202289819717407
Train Epoch 1, Loss 0.38393259048461914
Train Epoch 2, Loss 0.3001217246055603
Accuracy at epoch 120: 0.9169921875, total training samples: 2756
Early stopping at epoch 524. Loss did not improve for 10 epochs.
Generate examples Step 524, Loss 0.2878316637731734
Epoch: 121
Negative Examples
['aa', 'aaaaa', 'aaaaaaa', 'aaaabaa', 'aabaabaa', 'b']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaab', 'aab', 'aabaab', 'aababab', 'abaaaab', 'abab', 'abbab', 'bab', 'babab', 'bbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbab', 'aaabaabb', 'ababaaabb', 'aaaabaabb', 'bab', 'aaaabb', 'ababb', 'aababb', 'babab', 'aaaaababb', 'aaaabaabb', 'aaaaabb', 'bbabab', 'aabaabb', 'aaaabb', 'aaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3016616404056549
Train Epoch 1, Loss 0.1887032836675644
Train Epoch 2, Loss 0.11146213114261627
Accuracy at epoch 121: 0.970703125, total training samples: 2772
Early stopping at epoch 492. Loss did not improve for 10 epochs.
Generate examples Step 492, Loss 0.5212315204298279
Epoch: 122
Negative Examples
['aaaaaaa', 'aabaab', 'aabab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'aaaaaab', 'aaaab', 'aaabab', 'aabab', 'aabaaab', 'aaaaab', 'aaaababab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.6655547618865967
Train Epoch 1, Loss 0.3268907070159912
Train Epoch 2, Loss 0.1659727245569229
Accuracy at epoch 122: 0.9521484375, total training samples: 2780
Early stopping at epoch 334. Loss did not improve for 10 epochs.
Generate examples Step 334, Loss 0.6184946235880923
Epoch: 123
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabab', 'aaababab', 'aab', 'aabab', 'aababab', 'ab', 'abab', 'baaaaaab', 'baaabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaaaab', 'abaabb', 'aaaaabb', 'aabaabb', 'baaabab', 'aaaabaabb', 'aabaaaabb', 'abababb', 'bab', 'aabaabb', 'abababb', 'aaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4143159091472626
Train Epoch 1, Loss 0.2625568211078644
Train Epoch 2, Loss 0.14670802652835846
Accuracy at epoch 123: 0.96484375, total training samples: 2792
Early stopping at epoch 444. Loss did not improve for 10 epochs.
Generate examples Step 444, Loss 0.7826332476031914
Epoch: 124
Negative Examples
['aabab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'aabaabab', 'abab', 'abaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.1717420816421509
Train Epoch 1, Loss 0.6298239231109619
Train Epoch 2, Loss 0.2899519205093384
Accuracy at epoch 124: 0.9326171875, total training samples: 2796
Early stopping at epoch 506. Loss did not improve for 10 epochs.
Generate examples Step 506, Loss 0.32352353482556767
Epoch: 125
Negative Examples
['aa', 'aaaaaaaa', 'aaabaa', 'aaababaa', 'abaa', 'abaaaaa', 'b']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aabab', 'ab', 'abaaaaab', 'ababab', 'bab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['bab', 'aabaabb', 'ababaabb', 'abaabaabb', 'babab', 'ababaabb', 'aaaababb', 'aaabb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3490588665008545
Train Epoch 1, Loss 0.21619462966918945
Train Epoch 2, Loss 0.12650340795516968
Accuracy at epoch 125: 0.9794921875, total training samples: 2804
Early stopping at epoch 485. Loss did not improve for 10 epochs.
Generate examples Step 485, Loss 0.6782910753608731
Epoch: 126
Negative Examples
['aabaabab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabaaaab', 'ab', 'abaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaabab', 'abaabaaab', 'aaabaab', 'ab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7613577246665955
Train Epoch 1, Loss 0.3625776171684265
Train Epoch 2, Loss 0.17219001054763794
Accuracy at epoch 126: 0.9638671875, total training samples: 2808
Early stopping at epoch 375. Loss did not improve for 10 epochs.
Generate examples Step 375, Loss 0.5840084364122533
Epoch: 127
Negative Examples
['abaabaa', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aaabab', 'aab', 'aabab', 'ab', 'abaabab', 'abab', 'ababab', 'abababab', 'baaaaab', 'baabaaab', 'babaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaaab', 'abb', 'abaaabb', 'ababababb', 'baabaaab', 'aaaaaabb', 'aabaababb', 'aababb', 'babaaab', 'abaababb', 'abaaabb', 'abaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.48176249861717224
Train Epoch 1, Loss 0.26736828684806824
Train Epoch 2, Loss 0.15306586027145386
Accuracy at epoch 127: 0.9794921875, total training samples: 2820
Early stopping at epoch 488. Loss did not improve for 10 epochs.
Generate examples Step 488, Loss 0.43624190388891104
Epoch: 128
Negative Examples
['aab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aabaabab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abababaab', 'aabaaaab', 'aaababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.6656079292297363
Train Epoch 1, Loss 0.4242403507232666
Train Epoch 2, Loss 0.2639477252960205
Accuracy at epoch 128: 0.90234375, total training samples: 2824
Early stopping at epoch 638. Loss did not improve for 10 epochs.
Generate examples Step 638, Loss 0.27276393765341694
Epoch: 129
Negative Examples
['aa', 'aaa', 'aaaabaaa', 'aaabaa', 'aaabaaa', 'aaabbaa', 'aaabbbaa', 'aabaaa', 'aabaabaa', 'b', 'baaa']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaabbaa', 'aab', 'aababaaa', 'aabbab', 'ab', 'baab', 'baabbab', 'babbab', 'bbaaaab', 'bbaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabbaa', 'aaaaabb', 'aaaaababb', 'abaaaabb', 'aababaaa', 'aababaaaa', 'abaabaaba', 'aaaaba', 'aabbab', 'abaabb', 'aaabaabb', 'aaaababb', 'baab', 'abaabaabb', 'aabaababb', 'aaaabaabb', 'baabbab', 'b', 'abaaaaabb', 'abaaaabb', 'babbab', 'aaaaaabb', 'abaaaabb', 'abaababb', 'bbaaaab', 'aaabaaabb', 'aabb', 'aabaaaabb', 'bbaabaab', 'abaaabb', 'aaaaaaabb', 'abaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.37446898221969604
Train Epoch 1, Loss 0.24758678674697876
Train Epoch 2, Loss 0.159489706158638
Accuracy at epoch 129: 0.98828125, total training samples: 2856
Early stopping at epoch 432. Loss did not improve for 10 epochs.
Generate examples Step 432, Loss 0.6472703335466892
Epoch: 130
Negative Examples
['b', 'bab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aabaabab', 'aabab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 130: No counterexamples found, skipped.
Early stopping at epoch 429. Loss did not improve for 10 epochs.
Generate examples Step 429, Loss 0.5317723984981693
Epoch: 131
Negative Examples
['aabbabab', 'abaaab', 'b', 'bab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'aabaaaaab', 'abaaaaab', 'aaaaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.4514581263065338
Train Epoch 1, Loss 0.2101716250181198
Train Epoch 2, Loss 0.09807389974594116
Accuracy at epoch 131: 0.9345703125, total training samples: 2860
Early stopping at epoch 459. Loss did not improve for 10 epochs.
Generate examples Step 459, Loss 0.6685348802286646
Epoch: 132
Negative Examples
['aabaa', 'b']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaab', 'aabaabab', 'aabab', 'aababab', 'ab', 'abaaab', 'abab', 'ababab', 'abbaab', 'bab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaab', 'aaabaabb', 'aaaabb', 'aababaabb', 'bab', 'ababb', 'aabaabb', 'aabaaabb', 'babab', 'aababaabb', 'aaaaaabb', 'abaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.29165858030319214
Train Epoch 1, Loss 0.1716071367263794
Train Epoch 2, Loss 0.10420449823141098
Accuracy at epoch 132: 0.9736328125, total training samples: 2872
Early stopping at epoch 332. Loss did not improve for 10 epochs.
Generate examples Step 332, Loss 0.792258015087059
Epoch: 133
Negative Examples
['aababaab', 'b']
Neg Neg
Positive Examples
['aaaaaaa', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabaaaab', 'aabab', 'ab', 'abaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aababaab', 'aabab', 'aaabaabab', 'aaabaaaab', 'aaaaaaa', 'aa', 'aaabaaa', 'aaa']
Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.45178717374801636
Train Epoch 1, Loss 0.2913230061531067
Train Epoch 2, Loss 0.21280868351459503
Accuracy at epoch 133: 0.962890625, total training samples: 2880
Early stopping at epoch 423. Loss did not improve for 10 epochs.
Generate examples Step 423, Loss 0.5713050901046339
Epoch: 134
Negative Examples
['aabaabaa', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabab', 'aab', 'aabab', 'aababaab', 'ab', 'abaaab', 'abaabab', 'abab', 'ababaab', 'abbaaaab', 'baaaab', 'baaaabab', 'baaab', 'baabab', 'babaabab', 'bbaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaaaab', 'aabaababb', 'abababb', 'aaabababb', 'baaaab', 'abaaaaabb', 'abaabb', 'aaabb', 'baaaabab', 'ababababb', 'aaabb', 'abaaaabb', 'baaab', 'abaabb', 'aaaabaabb', 'abababb', 'baabab', 'aabababb', 'aaaababb', 'abababb', 'babaabab', 'aabaaaabb', 'aaabababb', 'abb', 'bbaaaab', 'aaabaaabb', 'aabaababb', 'abaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.44586512446403503
Train Epoch 1, Loss 0.26778584718704224
Train Epoch 2, Loss 0.1504424512386322
Accuracy at epoch 134: 0.95703125, total training samples: 2908
Early stopping at epoch 443. Loss did not improve for 10 epochs.
Generate examples Step 443, Loss 0.5571379357495824
Epoch: 135
Negative Examples
['aab', 'aabaabab', 'abaaaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabaab', 'aaabab', 'aabaaaab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abaaaabab', 'abababaab', 'ababab', 'aabaabab', 'aaabaaaab', 'ababab', 'aaaaabab', 'abaaaab', 'aabababab', 'abaababab', 'aabaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.0265589952468872
Train Epoch 1, Loss 0.6123520731925964
Train Epoch 2, Loss 0.37277722358703613
Accuracy at epoch 135: 0.9033203125, total training samples: 2920
Early stopping at epoch 386. Loss did not improve for 10 epochs.
Generate examples Step 386, Loss 0.4185417505890824
Epoch: 136
Negative Examples
['aa', 'aaabaa', 'aabaa', 'aabaabaa', 'abaabaa', 'b']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaabbab', 'aab', 'aabab', 'ab', 'abaaab', 'abaaabab', 'abaabab', 'abab', 'abbab', 'abbabab', 'bab', 'babaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbab', 'abaaababb', 'aaaabaabb', 'aaaaaabb', 'abbab', 'aabaababb', 'aaabb', 'b', 'abbabab', 'aabaabb', 'aabaaabb', 'ababababb', 'bab', 'ababb', 'aababb', 'aaabaaabb', 'babaab', 'aaaaababb', 'abaaababb', 'abaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3278312087059021
Train Epoch 1, Loss 0.2065211981534958
Train Epoch 2, Loss 0.12137903273105621
Accuracy at epoch 136: 0.9609375, total training samples: 2940
Early stopping at epoch 497. Loss did not improve for 10 epochs.
Generate examples Step 497, Loss 0.685866969536586
Epoch: 137
Negative Examples
['aab', 'aababab', 'abab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabab', 'aaababab', 'aabaabab', 'aabab', 'ab', 'abaaaab', 'abaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'abaabaab', 'aabaaaaab', 'aaaaaaab', 'aababab', 'abaabaab', 'abaaabaab', 'aababaaab', 'abab', 'aaaaabaab', 'aaabaaaab', 'abaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7481847405433655
Train Epoch 1, Loss 0.4062061011791229
Train Epoch 2, Loss 0.22738005220890045
Accuracy at epoch 137: 0.9384765625, total training samples: 2952
Early stopping at epoch 358. Loss did not improve for 10 epochs.
Generate examples Step 358, Loss 0.5377030972816818
Epoch: 138
Negative Examples
['aabaaa', 'aabaaaaa', 'b']
Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaabab', 'aabab', 'aababaab', 'ab', 'abaab', 'abab', 'abbaab', 'baaab', 'baab', 'baabab', 'babaab', 'bababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaab', 'aabababb', 'abaabb', 'abaaababb', 'baaab', 'aaababb', 'ababaaabb', 'aaabababb', 'baab', 'abaababb', 'abaaabb', 'abababb', 'baabab', 'aaabaabb', 'aabaabb', 'aaaabb', 'babaab', 'aaaababb', 'aaabb', 'aababb', 'bababaab', 'aaaaaaabb', 'aaaaaabb', 'aaabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3657251298427582
Train Epoch 1, Loss 0.20744647085666656
Train Epoch 2, Loss 0.11987427622079849
Accuracy at epoch 138: 0.95703125, total training samples: 2976
Early stopping at epoch 481. Loss did not improve for 10 epochs.
Generate examples Step 481, Loss 0.5686185066568901
Epoch: 139
Negative Examples
['aab', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaaaabaa', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aabaaab', 'aabaabab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aaabaabab', 'abababaab', 'abaab', 'aaaaabaa', 'aaaaaabaa', 'abaaaba', 'abababa']
Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.7529640793800354
Train Epoch 1, Loss 0.46204620599746704
Train Epoch 2, Loss 0.27152663469314575
Accuracy at epoch 139: 0.94921875, total training samples: 2984
Early stopping at epoch 388. Loss did not improve for 10 epochs.
Generate examples Step 388, Loss 0.6864158847491355
Epoch: 140
Negative Examples
['aababbab', 'b', 'baabab']
Neg Neg Neg
Positive Examples
['aaaab', 'aab', 'aabaab', 'aababaab', 'aabbaab', 'ab', 'abaab', 'ababaab', 'abbaab', 'abbbaab', 'baaaab', 'baaabaab', 'baab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaab', 'aababaabb', 'abaabaabb', 'aaaabb', 'abbaab', 'aabaababb', 'aaababb', 'aaaaaaabb', 'abbbaab', 'aaaaaabb', 'aaabababb', 'abaaabb', 'baaaab', 'b', 'aababaabb', 'aaaaabb', 'baaabaab', 'abaabaabb', 'aaabaabb', 'b', 'baab', 'aababb', 'abaaabb', 'aabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3783923089504242
Train Epoch 1, Loss 0.2273881584405899
Train Epoch 2, Loss 0.12891709804534912
Accuracy at epoch 140: 0.9482421875, total training samples: 3008
Early stopping at epoch 515. Loss did not improve for 10 epochs.
Generate examples Step 515, Loss 0.4571217630895995
Epoch: 141
Negative Examples
['aaabaab', 'aab', 'aabab', 'abaaaab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabaab', 'aaaabab', 'aaaabaab', 'aaaaaaab', 'aab', 'aaababaab', 'aaaaaaab', '', 'aabab', 'aaaabab', 'aaab', 'aabaabab', 'abaaaab', 'aababaaab', 'aaaababab', 'aaabaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7771602272987366
Train Epoch 1, Loss 0.4706016480922699
Train Epoch 2, Loss 0.3156747817993164
Accuracy at epoch 141: 0.9853515625, total training samples: 3024
Early stopping at epoch 305. Loss did not improve for 10 epochs.
Generate examples Step 305, Loss 0.7372079661566447
Epoch: 142
Negative Examples
['aaaaa', 'aaaabaa', 'aabaa', 'aababbab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabab', 'aab', 'aabaabab', 'aabab', 'aabbabab', 'ab', 'abaaaab', 'abaaabab', 'baaaaaab', 'baaaaab', 'baabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbabab', 'ababaaabb', 'abb', 'aabaaabb', 'baaaaaab', 'b', 'aaabaaabb', 'ababaabb', 'baaaaab', 'aaaabaabb', 'ababaaabb', 'aababb', 'baabaab', 'aaabb', 'ababaaabb', 'aababaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3976662755012512
Train Epoch 1, Loss 0.2548954486846924
Train Epoch 2, Loss 0.1539180874824524
Accuracy at epoch 142: 0.97265625, total training samples: 3040
Early stopping at epoch 521. Loss did not improve for 10 epochs.
Generate examples Step 521, Loss 0.3982607365596568
Epoch: 143
Negative Examples
['aab', 'bab', 'bbbbabab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabab', 'aaababab', 'aabaabab', 'aabab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aaaababab', 'abaaabab', 'aaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5499391555786133
Train Epoch 1, Loss 0.32621803879737854
Train Epoch 2, Loss 0.20261549949645996
Accuracy at epoch 143: 0.94140625, total training samples: 3044
Early stopping at epoch 397. Loss did not improve for 10 epochs.
Generate examples Step 397, Loss 0.36688680958058967
Epoch: 144
Negative Examples
['aa', 'aaaa', 'aabaa', 'b', 'bbbab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaabaa', 'aaab', 'aaabab', 'aaababab', 'aaabbbab', 'aab', 'aabaaab', 'aababab', 'aabbaaab', 'aabbaab', 'ab', 'abbabab', 'baababab', 'bab', 'babaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaa', 'aaaabaaa', 'aaaaaaaba', 'aaaaababa', 'aaabbbab', 'aabb', 'aaaabaabb', 'aaaaaaabb', 'aabbaaab', 'aababaabb', 'aaaaabb', 'aabaaabb', 'aabbaab', 'aaaaabb', 'abaaabb', 'b', 'abbabab', 'aaaaababb', 'aababb', 'aabababb', 'baababab', 'aababb', 'abaaababb', 'aaaaabb', 'bab', 'ababababb', 'ababaaabb', 'aaabaabb', 'babaabab', 'ababababb', 'abaaababb', 'aabababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3122468888759613
Train Epoch 1, Loss 0.19776444137096405
Train Epoch 2, Loss 0.12576653063297272
Accuracy at epoch 144: 0.9814453125, total training samples: 3076
Early stopping at epoch 400. Loss did not improve for 10 epochs.
Generate examples Step 400, Loss 0.6701976054921709
Epoch: 145
Negative Examples
['aaaaabaa', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaab', 'aab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 145: No counterexamples found, skipped.
Early stopping at epoch 407. Loss did not improve for 10 epochs.
Generate examples Step 407, Loss 0.6167039405189308
Epoch: 146
Negative Examples
['b', 'bab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 146: No counterexamples found, skipped.
Early stopping at epoch 438. Loss did not improve for 10 epochs.
Generate examples Step 438, Loss 0.6883573652943066
Epoch: 147
Negative Examples
['abaaaaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaaaab', 'aabaaabab', 'aabaaaaab', 'aaaabaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.47542616724967957
Train Epoch 1, Loss 0.15721803903579712
Train Epoch 2, Loss 0.07579158246517181
Accuracy at epoch 147: 0.9697265625, total training samples: 3080
Early stopping at epoch 253. Loss did not improve for 10 epochs.
Generate examples Step 253, Loss 0.6009086728624002
Epoch: 148
Negative Examples
[]

Positive Examples
['aaaaabaa', 'aaaaabab', 'aaaab', 'aaaabaa', 'aaaabab', 'aaab', 'aaabaab', 'aaabab', 'aab', 'aabaabab', 'aabab', 'aabbaaab', 'ab', 'abaaaaab', 'abaaaab', 'abaaabab', 'abaab', 'ababaaab', 'baaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaabaa', 'aababaa', 'abaaaaa', 'abaaaaba', 'aaaabaa', 'aabaaaaaa', 'aabababa', 'abaababaa', 'aabbaaab', 'aaabaabb', 'b', 'aabaabb', 'baaaab', 'ababb', 'aaaababb', 'abaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.399309366941452
Train Epoch 1, Loss 0.22505119442939758
Train Epoch 2, Loss 0.13652871549129486
Accuracy at epoch 148: 0.974609375, total training samples: 3096
Early stopping at epoch 440. Loss did not improve for 10 epochs.
Generate examples Step 440, Loss 0.6654519197486696
Epoch: 149
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 149: No counterexamples found, skipped.
Early stopping at epoch 446. Loss did not improve for 10 epochs.
Generate examples Step 446, Loss 0.6879330847487354
Epoch: 150
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 150: No counterexamples found, skipped.
Early stopping at epoch 360. Loss did not improve for 10 epochs.
Generate examples Step 360, Loss 0.6146190225087375
Epoch: 151
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 151: No counterexamples found, skipped.
Early stopping at epoch 375. Loss did not improve for 10 epochs.
Generate examples Step 375, Loss 0.5436645047739148
Epoch: 152
Negative Examples
['abaaabab', 'abaab', 'abab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaabab', 'abaab', 'aababaab', 'ab', 'abaab', 'aaababab', 'aaabaaaab', 'ababaabab', 'abab', 'aaaabaaab', 'ababaaab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.8684622645378113
Train Epoch 1, Loss 0.5098102688789368
Train Epoch 2, Loss 0.2985454201698303
Accuracy at epoch 152: 0.90234375, total training samples: 3108
Early stopping at epoch 427. Loss did not improve for 10 epochs.
Generate examples Step 427, Loss 0.3457997596570265
Epoch: 153
Negative Examples
['aaabaa', 'b']
Neg Neg
Positive Examples
['aaaaabab', 'aab', 'aabaab', 'aabaabab', 'aabab', 'ab', 'abaabbab', 'abbaaaab', 'abbbbab', 'baaabab', 'baab', 'baabbbab', 'bab', 'bbaabbab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaabbab', 'aaaaaaabb', 'aaaabaabb', 'aabababb', 'abbaaaab', 'abaabb', 'aaabababb', 'abaabaabb', 'abbbbab', 'abaabaabb', 'aaabaabb', 'ababb', 'baaabab', 'aaabaaabb', 'aababb', 'aaaabb', 'baab', 'b', 'abaaaaabb', 'ababaabb', 'baabbbab', 'aaaabb', 'abababb', 'ababb', 'bab', 'aababb', 'aaaabb', 'aaabaaabb', 'bbaabbab', 'abababb', 'aaabaaabb', 'aaaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.32788828015327454
Train Epoch 1, Loss 0.21457412838935852
Train Epoch 2, Loss 0.1359032839536667
Accuracy at epoch 153: 0.9794921875, total training samples: 3140
Early stopping at epoch 519. Loss did not improve for 10 epochs.
Generate examples Step 519, Loss 0.6291602448775218
Epoch: 154
Negative Examples
['abaaab', 'ababaaab', 'b', 'bab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aabaaab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'ababaab', 'ababab', 'aab', 'ababaaab', 'abaaaabab', 'abaabaab', 'abababab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.0596877336502075
Train Epoch 1, Loss 0.6018756628036499
Train Epoch 2, Loss 0.32719114422798157
Accuracy at epoch 154: 0.892578125, total training samples: 3148
Early stopping at epoch 409. Loss did not improve for 10 epochs.
Generate examples Step 409, Loss 0.6082536098797147
Epoch: 155
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaabab', 'aababab', 'aabbaab', 'ab', 'abab', 'abababab', 'baaaaab', 'baaab', 'baab', 'bab', 'babaaab', 'bbaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaab', 'b', 'aababb', 'aaababb', 'baaaaab', 'aabababb', 'abaaababb', 'aaaaaaabb', 'baaab', 'ababaabb', 'ababaaabb', 'aaabababb', 'baab', 'aaabaaabb', 'aaaaaaabb', 'aaababb', 'bab', 'abaabaabb', 'aaababb', 'abaaaaabb', 'babaaab', 'aaabaabb', 'aabb', 'aababaabb', 'bbaab', 'aababb', 'aabb', 'aabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3886938989162445
Train Epoch 1, Loss 0.26251786947250366
Train Epoch 2, Loss 0.16882304847240448
Accuracy at epoch 155: 0.9833984375, total training samples: 3176
Early stopping at epoch 453. Loss did not improve for 10 epochs.
Generate examples Step 453, Loss 0.6897949535678661
Epoch: 156
Negative Examples
['aaabbab', 'abaabab', 'b', 'bab', 'bbbabab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabab', 'ab', 'abaaabab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaabab', 'abaaaaab', 'ababab', 'ab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.6240531206130981
Train Epoch 1, Loss 0.3248549997806549
Train Epoch 2, Loss 0.17056168615818024
Accuracy at epoch 156: 0.927734375, total training samples: 3180
Early stopping at epoch 365. Loss did not improve for 10 epochs.
Generate examples Step 365, Loss 0.3805762733755216
Epoch: 157
Negative Examples
['aa', 'aaaabbb', 'aabaa', 'aababaa', 'abaa', 'ababbb', 'b', 'bbaaabaa']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaaab', 'aabbab', 'ab', 'abab', 'baaab', 'bab', 'babab', 'bababab', 'babbbab', 'bbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbab', 'aabababb', 'aababb', 'abaaaabb', 'baaab', 'aaababb', 'abaaaabb', 'abaababb', 'bab', 'aaaaabb', 'aabaaaabb', 'abaaaabb', 'babab', 'b', 'abaabaabb', 'abaababb', 'bababab', 'ababababb', 'aaabaaabb', 'abaaaabb', 'babbbab', 'ababaabb', 'aaaaaaabb', 'aabaabb', 'bbbabab', 'aaabb', 'ababaabb', 'abaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3754834234714508
Train Epoch 1, Loss 0.22786642611026764
Train Epoch 2, Loss 0.13464190065860748
Accuracy at epoch 157: 0.9755859375, total training samples: 3208
Early stopping at epoch 492. Loss did not improve for 10 epochs.
Generate examples Step 492, Loss 0.6658494470085624
Epoch: 158
Negative Examples
['abab', 'b', 'baaabab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'aabaaaab', 'aabaabab', 'aabab', 'ab', 'abaaabab', 'baaaaab', 'baaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abab', 'abab', 'abababab', 'abababaab', 'baaaaab', 'aaaababb', 'aababaabb', 'ababababb', 'baaaabab', 'abaaaabb', 'ababb', 'ababababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.6766188144683838
Train Epoch 1, Loss 0.5129572749137878
Train Epoch 2, Loss 0.4200676381587982
Accuracy at epoch 158: 0.916015625, total training samples: 3220
Early stopping at epoch 392. Loss did not improve for 10 epochs.
Generate examples Step 392, Loss 0.38140988922452806
Epoch: 159
Negative Examples
['aaabaa', 'aabaa', 'abaa', 'b']
Neg Neg Neg Neg
Positive Examples
['aaabab', 'aaababab', 'aab', 'aabab', 'aababab', 'aabbabab', 'ab', 'abab', 'abbabab', 'baaaaab', 'baaab', 'baab', 'bab', 'babbab', 'bbab', 'bbbab', 'bbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbabab', 'b', 'abaaababb', 'aaaabb', 'abbabab', 'aaabb', 'abaabaabb', 'aaabababb', 'baaaaab', 'aaaabb', 'aaaaaaabb', 'abb', 'baaab', 'aaaaabb', 'aabb', 'aabaabb', 'baab', 'aaabaaabb', 'abaabaabb', 'aababb', 'bab', 'abaabaabb', 'abaaaaabb', 'abaaaabb', 'babbab', 'abaababb', 'aaabababb', 'aaaabb', 'bbab', 'abaababb', 'aaaaaaabb', 'aabaababb', 'bbbab', 'aaaababb', 'aabb', 'ababaaabb', 'bbbabab', 'aaaababb', 'aababb', 'aaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.21138878911733627
Train Epoch 1, Loss 0.08497012034058571
Train Epoch 2, Loss 0.04267532005906105
Accuracy at epoch 159: 0.896484375, total training samples: 3260
Early stopping at epoch 674. Loss did not improve for 10 epochs.
Generate examples Step 674, Loss 1.2663062480643943
Epoch: 160
Negative Examples
['aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab']
Pos Pos Pos
Counterexamples
['aaaab', 'aaabaaaab', 'aabaaaab', 'aaaaab', 'aaab', 'aab', 'aaababaab', 'ab', 'aab', 'aababab', 'aababaaab', 'aabaabaab', 'ab', 'abaab', 'aabaaaaab', 'aaababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.551965355873108
Train Epoch 1, Loss 0.8947985172271729
Train Epoch 2, Loss 0.4780910313129425
Accuracy at epoch 160: 0.970703125, total training samples: 3276
Early stopping at epoch 431. Loss did not improve for 10 epochs.
Generate examples Step 431, Loss 0.8931842102082791
Epoch: 161
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aaabab', 'aaabbaab', 'aab', 'aabaab', 'aabab', 'ab', 'abaab', 'abaabaab', 'abaabab', 'baaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'aaaabaabb', 'abaaaaabb', 'aabaaabb', 'baaaabab', 'abb', 'ababababb', 'abaababb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4497753083705902
Train Epoch 1, Loss 0.18911658227443695
Train Epoch 2, Loss 0.08070841431617737
Accuracy at epoch 161: 0.9384765625, total training samples: 3284
Early stopping at epoch 481. Loss did not improve for 10 epochs.
Generate examples Step 481, Loss 0.7617673595663917
Epoch: 162
Negative Examples
['aaab', 'aab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aaab', 'aababaaab', 'aaaaaaaab', 'aaabab', 'aab', 'aaaabaab', 'aabaaabab', 'aabaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.0842386484146118
Train Epoch 1, Loss 0.6081790328025818
Train Epoch 2, Loss 0.3289450407028198
Accuracy at epoch 162: 0.9794921875, total training samples: 3292
Early stopping at epoch 325. Loss did not improve for 10 epochs.
Generate examples Step 325, Loss 0.5927246451103614
Epoch: 163
Negative Examples
['aaaaaaaa', 'ababab', 'b', 'baab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaabab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aabaabab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'baaabaab', 'baabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ababab', 'aaaaaab', 'aababaaab', 'aabaaab', 'baaabaab', 'abb', 'ababaaabb', 'aabababb', 'baabaab', 'aaaaababb', 'aabaaaabb', 'aaaababb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4495491683483124
Train Epoch 1, Loss 0.3045494854450226
Train Epoch 2, Loss 0.2046746164560318
Accuracy at epoch 163: 0.974609375, total training samples: 3304
Early stopping at epoch 303. Loss did not improve for 10 epochs.
Generate examples Step 303, Loss 0.5907639117029152
Epoch: 164
Negative Examples
['aaaaaa', 'aaababaa', 'aababaa', 'abbaaab', 'b', 'baab', 'bababab', 'bbaabab', 'bbabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaabaaab', 'aaabab', 'aab', 'aabaaab', 'aabaabab', 'aabab', 'aababab', 'ab', 'abaaaab', 'abab', 'ababab', 'abababab', 'baaaabab', 'baaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaabab', 'aabababb', 'abaaabb', 'aaaaabb', 'baaab', 'aababb', 'aabaaabb', 'b']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.40994971990585327
Train Epoch 1, Loss 0.2155793309211731
Train Epoch 2, Loss 0.11668416857719421
Accuracy at epoch 164: 0.9658203125, total training samples: 3312
Early stopping at epoch 415. Loss did not improve for 10 epochs.
Generate examples Step 415, Loss 0.6131378885430212
Epoch: 165
Negative Examples
['aaabbaab', 'abbaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aaabab', 'aaababab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 165: No counterexamples found, skipped.
Early stopping at epoch 560. Loss did not improve for 10 epochs.
Generate examples Step 560, Loss 0.6249395888863187
Epoch: 166
Negative Examples
['aaabbaab', 'aabaaaab', 'aabaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaababab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaaaab', 'aababaab', 'aaaaabaab', 'aaaabaaab', 'aabaab', 'aaabaaaab', 'aabaaaab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7035239934921265
Train Epoch 1, Loss 0.3150402903556824
Train Epoch 2, Loss 0.14142978191375732
Accuracy at epoch 166: 0.974609375, total training samples: 3320
Early stopping at epoch 268. Loss did not improve for 10 epochs.
Generate examples Step 268, Loss 0.5064985218932194
Epoch: 167
Negative Examples
['aaaaaa', 'baabab']
Neg Neg
Positive Examples
['aaaaab', 'aaabaab', 'aaabbaab', 'aaabbab', 'aab', 'aabaaaab', 'aabaab', 'aabab', 'aababaab', 'aabbaab', 'aabbbaab', 'ab', 'abaab', 'abab', 'abbaab', 'baab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'aababaabb', 'abababb', 'ababababb', 'aaabbab', 'abaaaaabb', 'abaababb', 'aabaaaabb', 'aabbaab', 'abb', 'aaabaabb', 'aaabababb', 'aabbbaab', 'aabaabb', 'aabaaabb', 'abaaaabb', 'abbaab', 'aaaababb', 'aaaaababb', 'abaaabb', 'baab', 'abaaabb', 'aababaabb', 'aaabababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3845200836658478
Train Epoch 1, Loss 0.20264805853366852
Train Epoch 2, Loss 0.0939251109957695
Accuracy at epoch 167: 0.9814453125, total training samples: 3344
Early stopping at epoch 445. Loss did not improve for 10 epochs.
Generate examples Step 445, Loss 0.74466580419797
Epoch: 168
Negative Examples
['aaaaaaaa', 'abaaaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aab', 'aabaaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaaab', 'aaabaaaab', 'abaaabab', 'aaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7278977632522583
Train Epoch 1, Loss 0.25622957944869995
Train Epoch 2, Loss 0.09417460858821869
Accuracy at epoch 168: 0.984375, total training samples: 3348
Early stopping at epoch 401. Loss did not improve for 10 epochs.
Generate examples Step 401, Loss 0.8017603984816157
Epoch: 169
Negative Examples
['abaabaa', 'b', 'baabaa']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaababab', 'aab', 'aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'abbaabab', 'baabab', 'babaaaab', 'bbaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaabab', 'aaababb', 'aababb', 'aaaaabb', 'baabab', 'aababaabb', 'aabababb', 'aaabaaabb', 'babaaaab', 'abaaabb', 'aabaababb', 'aaaabaabb', 'bbaabab', 'aaaaaabb', 'aaaababb', 'aaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.43054795265197754
Train Epoch 1, Loss 0.18977127969264984
Train Epoch 2, Loss 0.09507076442241669
Accuracy at epoch 169: 0.958984375, total training samples: 3364
Early stopping at epoch 461. Loss did not improve for 10 epochs.
Generate examples Step 461, Loss 0.9276896622596364
Epoch: 170
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'aaabab', 'aabaaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aaaab', 'aaab', 'abaabaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.8669357895851135
Train Epoch 1, Loss 0.4862266480922699
Train Epoch 2, Loss 0.22161079943180084
Accuracy at epoch 170: 0.9580078125, total training samples: 3368
Early stopping at epoch 263. Loss did not improve for 10 epochs.
Generate examples Step 263, Loss 0.4922048009819154
Epoch: 171
Negative Examples
['aabaaa', 'aabbaaaa', 'ababab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaab', 'aab', 'aabaab', 'aabab', 'ab', 'abaab', 'abab', 'abbabaab', 'baaab', 'baabaab', 'baabab', 'bababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ababab', 'aaaaaaab', 'aaaaaaaab', 'ababaabab', 'abbabaab', 'ababababb', 'aaaabaabb', 'aaaaababb', 'baaab', 'aabababb', 'aaaabb', 'ababababb', 'baabaab', 'aabaabb', 'aaabb', 'aabaaaabb', 'baabab', 'ababaabb', 'aaabaaabb', 'aabababb', 'bababaab', 'aabaaabb', 'abb', 'abaabaabb']
Pos Pos Pos Pos Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.31841030716896057
Train Epoch 1, Loss 0.24421186745166779
Train Epoch 2, Loss 0.19676142930984497
Accuracy at epoch 171: 0.9638671875, total training samples: 3392
Early stopping at epoch 377. Loss did not improve for 10 epochs.
Generate examples Step 377, Loss 0.38009808200692374
Epoch: 172
Negative Examples
['aabaa', 'b', 'bab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabab', 'aaababab', 'aab', 'aabab', 'aababab', 'aabbaaab', 'ab', 'abaabab', 'abbabab', 'baaaaab', 'baabab', 'babaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaaab', 'aababb', 'aaaaabb', 'aaaaaabb', 'abbabab', 'aaababb', 'aabababb', 'abaaababb', 'baaaaab', 'aaaaaabb', 'aaaabaabb', 'b', 'baabab', 'aaaaabb', 'aabb', 'ababaabb', 'babaaab', 'aabaaabb', 'aabaabb', 'aabababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3856796622276306
Train Epoch 1, Loss 0.20473435521125793
Train Epoch 2, Loss 0.11308716237545013
Accuracy at epoch 172: 0.9619140625, total training samples: 3412
Early stopping at epoch 573. Loss did not improve for 10 epochs.
Generate examples Step 573, Loss 0.6614539052135853
Epoch: 173
Negative Examples
['aab', 'abaaabab', 'b']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabab', 'aaabab', 'aabaaaab', 'aabaabab', 'aabab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'ababaaab', 'aaab', 'abababab', 'abaaabab', 'abaaaaaab', 'aabababab', 'abaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.07443368434906
Train Epoch 1, Loss 0.5412377119064331
Train Epoch 2, Loss 0.2581930458545685
Accuracy at epoch 173: 0.955078125, total training samples: 3420
Early stopping at epoch 335. Loss did not improve for 10 epochs.
Generate examples Step 335, Loss 0.3828514203695314
Epoch: 174
Negative Examples
['aabaa', 'aabaabaa', 'b', 'baaabbab', 'bbabab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaabab', 'aaababab', 'aab', 'aabab', 'ab', 'abaabbab', 'abab', 'baaaaab', 'baabab', 'bab', 'bababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaabbab', 'aababb', 'aaaaaaabb', 'abb', 'baaaaab', 'ababaaabb', 'b', 'abaaaabb', 'baabab', 'aabaaabb', 'aaababb', 'abaaababb', 'bab', 'abaaaabb', 'aaabb', 'aababaabb', 'bababab', 'abb', 'abaaababb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3307393193244934
Train Epoch 1, Loss 0.17965616285800934
Train Epoch 2, Loss 0.10277503728866577
Accuracy at epoch 174: 0.9775390625, total training samples: 3440
Early stopping at epoch 534. Loss did not improve for 10 epochs.
Generate examples Step 534, Loss 0.7897285349458177
Epoch: 175
Negative Examples
['aaabbaab', 'aabaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabab', 'aab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'abaaaaab', 'aabaaaab', 'aaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5711097717285156
Train Epoch 1, Loss 0.21628156304359436
Train Epoch 2, Loss 0.10122520476579666
Accuracy at epoch 175: 0.9716796875, total training samples: 3444
Early stopping at epoch 316. Loss did not improve for 10 epochs.
Generate examples Step 316, Loss 0.7202862180557913
Epoch: 176
Negative Examples
['abaaaaa', 'b']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aabab', 'abaab', 'abaabaab', 'abab', 'ababaaab', 'ababaab', 'baaaaab', 'baabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaaab', 'abaaabb', 'aabaabb', 'aaaaaabb', 'baabaab', 'aaaaababb', 'abaaabb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4447811543941498
Train Epoch 1, Loss 0.20609036087989807
Train Epoch 2, Loss 0.10513421893119812
Accuracy at epoch 176: 0.986328125, total training samples: 3452
Early stopping at epoch 422. Loss did not improve for 10 epochs.
Generate examples Step 422, Loss 0.7902066267269441
Epoch: 177
Negative Examples
['b']
Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaabab', 'aaab', 'aaabab', 'aaababab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 177: No counterexamples found, skipped.
Early stopping at epoch 530. Loss did not improve for 10 epochs.
Generate examples Step 530, Loss 0.7072708837393313
Epoch: 178
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaabaab', 'aaaabab', 'aaab', 'aaabab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 178: No counterexamples found, skipped.
Early stopping at epoch 527. Loss did not improve for 10 epochs.
Generate examples Step 527, Loss 0.9065461022722902
Epoch: 179
Negative Examples
['aabaab', 'b', 'bbbbaab', 'bbbbbab']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aaababab', 'aab', 'aabab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'aaaaaab', 'aaabaaaab', 'aabaabaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5108675360679626
Train Epoch 1, Loss 0.18011507391929626
Train Epoch 2, Loss 0.08460468053817749
Accuracy at epoch 179: 0.9755859375, total training samples: 3456
Early stopping at epoch 326. Loss did not improve for 10 epochs.
Generate examples Step 326, Loss 0.9742609270668905
Epoch: 180
Negative Examples
['aabbbaab', 'abaabbab', 'b']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aaabbaab', 'aaabbab', 'aab', 'aabaab', 'ab', 'abaaaab', 'abaab', 'baaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'abaaababb', 'aaaabaabb', 'aabababb', 'aaabbab', 'abababb', 'abaaababb', 'aabb', 'baaabaab', 'abaaaabb', 'aaaaaaabb', 'aaabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.626626193523407
Train Epoch 1, Loss 0.34055235981941223
Train Epoch 2, Loss 0.14653028547763824
Accuracy at epoch 180: 0.9619140625, total training samples: 3468
Early stopping at epoch 473. Loss did not improve for 10 epochs.
Generate examples Step 473, Loss 1.0757330706350914
Epoch: 181
Negative Examples
['aabaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'abaaaaab', 'aaaaaabab', 'aababaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.755711555480957
Train Epoch 1, Loss 0.31136247515678406
Train Epoch 2, Loss 0.1355452835559845
Accuracy at epoch 181: 0.97265625, total training samples: 3472
Early stopping at epoch 306. Loss did not improve for 10 epochs.
Generate examples Step 306, Loss 0.5379966770447426
Epoch: 182
Negative Examples
['abbaaab', 'b', 'babbaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabab', 'aab', 'aabaabab', 'ab', 'abaaab', 'abaab', 'ababab', 'abbaab', 'baaabab', 'baabaab', 'baabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaab', 'aaabaabb', 'aaabb', 'aabaaaabb', 'baaabab', 'abaabb', 'aabaaaabb', 'abaabaabb', 'baabaab', 'aabaababb', 'aaaaaabb', 'abb', 'baabab', 'aabaaaabb', 'aabaababb', 'aaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.31331804394721985
Train Epoch 1, Loss 0.1561390608549118
Train Epoch 2, Loss 0.08313795179128647
Accuracy at epoch 182: 0.9658203125, total training samples: 3488
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.9981569060237278
Epoch: 183
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 183: No counterexamples found, skipped.
Early stopping at epoch 397. Loss did not improve for 10 epochs.
Generate examples Step 397, Loss 0.8296299902113837
Epoch: 184
Negative Examples
['aaabbaab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 184: No counterexamples found, skipped.
Early stopping at epoch 396. Loss did not improve for 10 epochs.
Generate examples Step 396, Loss 0.6975915984858193
Epoch: 185
Negative Examples
['aaabbaab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 185: No counterexamples found, skipped.
Early stopping at epoch 493. Loss did not improve for 10 epochs.
Generate examples Step 493, Loss 0.7964377050035396
Epoch: 186
Negative Examples
['aaabbaab', 'abaaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'aaab', 'aaabab', 'aabababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.987571120262146
Train Epoch 1, Loss 0.4498961567878723
Train Epoch 2, Loss 0.15896621346473694
Accuracy at epoch 186: 0.9716796875, total training samples: 3492
Early stopping at epoch 392. Loss did not improve for 10 epochs.
Generate examples Step 392, Loss 0.5630450169093736
Epoch: 187
Negative Examples
['aaaa', 'abaa', 'b', 'baabaaaa']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaaab', 'aaabab', 'aab', 'aabaab', 'ab', 'abaaab', 'abaaabab', 'abaabaab', 'abaabab', 'abab', 'baaab', 'babaaab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaab', 'abaaabb', 'aabababb', 'abaabb', 'babaaab', 'aaaababb', 'ababb', 'aabaababb', 'babab', 'aabaababb', 'aaaaaaabb', 'abaabaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2624024748802185
Train Epoch 1, Loss 0.13449831306934357
Train Epoch 2, Loss 0.08418550342321396
Accuracy at epoch 187: 0.98046875, total training samples: 3504
Early stopping at epoch 313. Loss did not improve for 10 epochs.
Generate examples Step 313, Loss 0.994722601429672
Epoch: 188
Negative Examples
['aabbaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabaab', 'aaabab', 'aab', 'aabaaab', 'aabaab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 188: No counterexamples found, skipped.
Early stopping at epoch 419. Loss did not improve for 10 epochs.
Generate examples Step 419, Loss 1.149722734022708
Epoch: 189
Negative Examples
['b', 'babbaab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaab', 'aaabaab', 'aaabab', 'aaabbaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'aaaaababb', 'aabaaabb', 'abaaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.1988363116979599
Train Epoch 1, Loss 0.05182889103889465
Train Epoch 2, Loss 0.02869904600083828
Accuracy at epoch 189: 0.90234375, total training samples: 3508
Early stopping at epoch 621. Loss did not improve for 10 epochs.
Generate examples Step 621, Loss 1.2320893119385772
Epoch: 190
Negative Examples
['aaaab', 'aaab', 'aab', 'ab', 'b']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab']
Pos Pos Pos
Counterexamples
['aaaab', 'aabaabaab', 'abababab', '', 'aaab', 'aabaab', 'aabaaaaab', 'aaaaab', 'aab', 'ababaaaab', 'aabaaaaab', 'abaaaab', 'ab', 'aaaab', 'abaab', 'aaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.7724517583847046
Train Epoch 1, Loss 1.1713703870773315
Train Epoch 2, Loss 0.7435563206672668
Accuracy at epoch 190: 0.9892578125, total training samples: 3524
Early stopping at epoch 394. Loss did not improve for 10 epochs.
Generate examples Step 394, Loss 0.9426353962361058
Epoch: 191
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaabab', 'aab', 'aabaaab', 'aabaabab', 'ab', 'abaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 191: No counterexamples found, skipped.
Early stopping at epoch 287. Loss did not improve for 10 epochs.
Generate examples Step 287, Loss 0.8155427883482642
Epoch: 192
Negative Examples
['b', 'baaaab', 'baaaabab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aabab', 'ab', 'abaaaab', 'baaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaaab', 'aaababb', 'ababaaabb', 'aaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.22026991844177246
Train Epoch 1, Loss 0.08675786107778549
Train Epoch 2, Loss 0.049974676221609116
Accuracy at epoch 192: 0.9404296875, total training samples: 3528
Early stopping at epoch 699. Loss did not improve for 10 epochs.
Generate examples Step 699, Loss 0.9867592544215066
Epoch: 193
Negative Examples
['aaab', 'aaabaaab', 'aab', 'aabaaaab', 'ababbaab', 'b', 'babbaab', 'bbbabab']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aaab', 'aaabaaab', 'ab', 'ababaaaab', 'aaabaaab', 'ababab', 'aaaaaaab', 'aab', 'aab', 'ababaab', 'abaabaab', 'aaaaabab', 'aabaaaab', 'ababab', 'abaaaaab', 'ababaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.4216095209121704
Train Epoch 1, Loss 0.9303127527236938
Train Epoch 2, Loss 0.5878415107727051
Accuracy at epoch 193: 0.9951171875, total training samples: 3544
Early stopping at epoch 548. Loss did not improve for 10 epochs.
Generate examples Step 548, Loss 0.6498687530041609
Epoch: 194
Negative Examples
['aabaa', 'abaa', 'b', 'baaab', 'baabab', 'babab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaaab', 'aaaabab', 'aaabaaab', 'aab', 'aabaabab', 'aabab', 'aabbaaab', 'aabbabab', 'ab', 'abaaaab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaaab', 'ababaaabb', 'aabaababb', 'aaabababb', 'aabbabab', 'aaababb', 'aaabaaabb', 'aaaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.20792929828166962
Train Epoch 1, Loss 0.1007581353187561
Train Epoch 2, Loss 0.06262916326522827
Accuracy at epoch 194: 0.9443359375, total training samples: 3552
Early stopping at epoch 669. Loss did not improve for 10 epochs.
Generate examples Step 669, Loss 0.6412015354455407
Epoch: 195
Negative Examples
['aaabaab', 'aab', 'aabaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabaab', 'aabaaab', 'abaaab', 'abaaaaaab', 'aab', 'aaababab', 'abaaaab', 'aaabab', 'aabaab', 'abab', 'abaaabaab', 'abaababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.381223201751709
Train Epoch 1, Loss 0.7740293145179749
Train Epoch 2, Loss 0.3781076669692993
Accuracy at epoch 195: 0.9853515625, total training samples: 3564
Early stopping at epoch 427. Loss did not improve for 10 epochs.
Generate examples Step 427, Loss 0.4334150489210804
Epoch: 196
Negative Examples
['abaabbab', 'abbaab', 'b', 'bab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabab', 'aaab', 'aaabab', 'aaabbaab', 'aab', 'aabaaab', 'aabab', 'aabbaab', 'ab', 'abaaab', 'abaab', 'abab', 'abababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'abaaababb', 'aaaaababb', 'abaababb', 'aabbaab', 'aaaaaaabb', 'aaabaabb', 'aaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.35454630851745605
Train Epoch 1, Loss 0.15029726922512054
Train Epoch 2, Loss 0.06851021200418472
Accuracy at epoch 196: 0.9560546875, total training samples: 3572
Early stopping at epoch 625. Loss did not improve for 10 epochs.
Generate examples Step 625, Loss 0.7741755468015092
Epoch: 197
Negative Examples
['aab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabab', 'aaab', 'aaabab', 'aabaaaab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'ababaaaab', 'aab', 'aaabaaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.7517368197441101
Train Epoch 1, Loss 0.359225869178772
Train Epoch 2, Loss 0.16175656020641327
Accuracy at epoch 197: 0.9599609375, total training samples: 3576
Early stopping at epoch 344. Loss did not improve for 10 epochs.
Generate examples Step 344, Loss 0.4881504686198373
Epoch: 198
Negative Examples
['aabbaaaa', 'aabbaab', 'b', 'bbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaa', 'aaaaabab', 'aaaabaab', 'aaab', 'aab', 'aabaaaaa', 'aabbaaab', 'ab', 'abaaaab', 'abab', 'abbaabab', 'baaaab', 'baaab', 'baaabaab', 'baaabab', 'baabaab', 'baabab', 'baabbaab', 'bbaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaa', 'aaaaaa', 'aaba', 'aaaa', 'aabaaaaa', 'aaabaaa', 'aabaaabaa', 'aaabaaaaa', 'aabbaaab', 'ababaaabb', 'ababaabb', 'aaaabaabb', 'abbaabab', 'abb', 'aaabb', 'aaabababb', 'baaaab', 'abaaababb', 'aaaaaaabb', 'ababb', 'baaab', 'abaababb', 'aabaabb', 'ababababb', 'baaabaab', 'abaaabb', 'abaabaabb', 'abaaaaabb', 'baaabab', 'aaabaaabb', 'aaaaabb', 'aaababb', 'baabaab', 'ababaabb', 'aaababb', 'abaabb', 'baabab', 'aabaabb', 'aabb', 'ababaaabb', 'baabbaab', 'aabaabb', 'aaaabaabb', 'aaabaaabb', 'bbaaaab', 'aaaababb', 'aabaabb', 'aaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.34720877557992935
Train Epoch 1, Loss 0.11742188036441803
Train Epoch 2, Loss 0.0565879438072443
Accuracy at epoch 198: 0.9248046875, total training samples: 3624
Early stopping at epoch 806. Loss did not improve for 10 epochs.
Generate examples Step 806, Loss 0.9018700947105663
Epoch: 199
Negative Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'b']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'ab']
Pos Pos
Counterexamples
['aaaaaab', 'aaab', 'aaaaabaab', 'ababaaab', 'aaaaab', 'aabababab', 'abaabaab', 'abaaabab', 'aaaab', 'abaabaaab', 'aaaabaaab', 'aaaaaaaab', 'aaab', 'aaaaab', 'aababaab', 'aabaab', 'aab', 'aabababab', 'aaababab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.467500925064087
Train Epoch 1, Loss 0.9914660453796387
Train Epoch 2, Loss 0.6565985679626465
Accuracy at epoch 199: 0.9794921875, total training samples: 3644
Early stopping at epoch 508. Loss did not improve for 10 epochs.
Generate examples Step 508, Loss 0.6458731729881234
Epoch: 200
Negative Examples
['b', 'babab', 'bbbab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aaababab', 'aab', 'aabaaab', 'aabaab', 'aabab', 'aababab', 'ab', 'abaaab', 'abab', 'ababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 200: No counterexamples found, skipped.
Early stopping at epoch 430. Loss did not improve for 10 epochs.
Generate examples Step 430, Loss 0.3766510263603967
Epoch: 201
Negative Examples
['aabbaab', 'abaa', 'b', 'baab', 'babbbab', 'bbbab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaababab', 'aab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 201: No counterexamples found, skipped.
Early stopping at epoch 418. Loss did not improve for 10 epochs.
Generate examples Step 418, Loss 0.46538009976430267
Epoch: 202
Negative Examples
['b', 'baab', 'babab']
Neg Neg Neg
Positive Examples
['aaab', 'aaababab', 'aaabbaab', 'aab', 'aabaab', 'aababab', 'ab', 'abab', 'ababab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'abababb', 'ababaabb', 'abaabb', 'bab', 'aabababb', 'aaaaaabb', 'abb']
Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.20467638969421387
Train Epoch 1, Loss 0.10961508750915527
Train Epoch 2, Loss 0.06281179189682007
Accuracy at epoch 202: 0.9609375, total training samples: 3652
Early stopping at epoch 488. Loss did not improve for 10 epochs.
Generate examples Step 488, Loss 0.972944062545987
Epoch: 203
Negative Examples
['aaabaaab', 'aab', 'ababbaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'ab']
Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabaaab', 'aabaabab', 'abaaaaaab', 'abaaab', 'aab', 'aabaaaaab', 'aaababaab', 'aaaaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.1582622528076172
Train Epoch 1, Loss 0.6205164790153503
Train Epoch 2, Loss 0.334552526473999
Accuracy at epoch 203: 0.9794921875, total training samples: 3660
Early stopping at epoch 524. Loss did not improve for 10 epochs.
Generate examples Step 524, Loss 0.5917074238402503
Epoch: 204
Negative Examples
['abbaaab', 'b', 'bbbabab']
Neg Neg Neg
Positive Examples
['aaaabaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aabaabab', 'aabab', 'aabbaaab', 'ab', 'abaaab', 'abaaabab', 'abaab', 'abab', 'ababaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaaab', 'ababaabb', 'aabaaaabb', 'abaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.23105081915855408
Train Epoch 1, Loss 0.09860226511955261
Train Epoch 2, Loss 0.05907837674021721
Accuracy at epoch 204: 0.96875, total training samples: 3664
Early stopping at epoch 510. Loss did not improve for 10 epochs.
Generate examples Step 510, Loss 0.671662221041211
Epoch: 205
Negative Examples
['aaabaab', 'aabaab', 'aabab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabaab', 'ababab', 'abab', 'abaabaab', 'aabaab', 'ababaab', 'ababaaaab', 'aaabab', 'aabab', 'aabaaab', 'aaabab', '']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 1.2940995693206787
Train Epoch 1, Loss 0.8352808356285095
Train Epoch 2, Loss 0.5245141983032227
Accuracy at epoch 205: 0.9814453125, total training samples: 3676
Early stopping at epoch 475. Loss did not improve for 10 epochs.
Generate examples Step 475, Loss 0.6038086478825376
Epoch: 206
Negative Examples
['aabbaab', 'abbab', 'abbbabab', 'b', 'bab']
Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aaabab', 'aab', 'aabaab', 'aabab', 'ab', 'abaabab', 'abab', 'ababab', 'baabaab', 'baabab', 'bababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baabaab', 'ababb', 'aaaabaabb', 'aababaabb', 'baabab', 'aaaabaabb', 'aaabb', 'ababaabb', 'bababab', 'aaababb', 'abaaaabb', 'aabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2772578001022339
Train Epoch 1, Loss 0.13713841140270233
Train Epoch 2, Loss 0.08002599328756332
Accuracy at epoch 206: 0.97265625, total training samples: 3688
Early stopping at epoch 421. Loss did not improve for 10 epochs.
Generate examples Step 421, Loss 0.9946856912560937
Epoch: 207
Negative Examples
['abaaabab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaabab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aaababab', 'aab', 'aabaab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaabab', 'aaababab', 'aaaaab', 'abaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.8258064985275269
Train Epoch 1, Loss 0.3151804506778717
Train Epoch 2, Loss 0.12336055189371109
Accuracy at epoch 207: 0.9765625, total training samples: 3692
Early stopping at epoch 429. Loss did not improve for 10 epochs.
Generate examples Step 429, Loss 0.5106963038791058
Epoch: 208
Negative Examples
['aa', 'ababbbab', 'abbab', 'abbabab', 'b', 'baaaabaa', 'baaabaa', 'bab', 'babab', 'bbabab', 'bbbabab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aab', 'aabab', 'aababab', 'ab', 'abab', 'ababab', 'abbaabab', 'baaaabab', 'baaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abbaabab', 'aaabb', 'abaaababb', 'aaabababb', 'baaaabab', 'abaaaaabb', 'abaabb', 'aaababb', 'baaabab', 'abaaaabb', 'aaaabb', 'aaaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.5394105315208435
Train Epoch 1, Loss 0.27496206760406494
Train Epoch 2, Loss 0.12833593785762787
Accuracy at epoch 208: 0.9755859375, total training samples: 3704
Early stopping at epoch 412. Loss did not improve for 10 epochs.
Generate examples Step 412, Loss 0.7296744141249623
Epoch: 209
Negative Examples
['aababab', 'abaaabab', 'abaab', 'abab', 'b', 'bab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaaabab', 'aaaab', 'aaaabab', 'aaaabbab', 'aaab', 'aaabab', 'aaababab', 'aabab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aababab', 'aaab', 'abaaaaab', 'aababaab', 'abaaabab', 'abaaabaab', 'aaabaabab', 'aabab', 'abaab', 'aaababab', 'aabaaaaab', 'ababaab', 'abab', 'aaabaabab', 'abaaaabab', 'aaabaaab', 'aaaabbab', 'b', 'aaaabaabb', 'abaaaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.5727263689041138
Train Epoch 1, Loss 0.39343520998954773
Train Epoch 2, Loss 0.2801153063774109
Accuracy at epoch 209: 0.9873046875, total training samples: 3724
Early stopping at epoch 486. Loss did not improve for 10 epochs.
Generate examples Step 486, Loss 0.7607705498255743
Epoch: 210
Negative Examples
['b', 'baaab', 'baab', 'bab', 'babab']
Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabab', 'aab', 'aabaab', 'aabab', 'aababab', 'ab', 'abaab', 'ababab', 'abababab', 'baabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baabab', 'aabababb', 'ababaaabb', 'aabaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.22404003143310547
Train Epoch 1, Loss 0.10516899824142456
Train Epoch 2, Loss 0.0584317222237587
Accuracy at epoch 210: 0.9716796875, total training samples: 3728
Early stopping at epoch 461. Loss did not improve for 10 epochs.
Generate examples Step 461, Loss 0.7680085884221705
Epoch: 211
Negative Examples
['aaabbaab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 211: No counterexamples found, skipped.
Early stopping at epoch 464. Loss did not improve for 10 epochs.
Generate examples Step 464, Loss 0.7955520543520168
Epoch: 212
Negative Examples
['b']
Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 212: No counterexamples found, skipped.
Early stopping at epoch 421. Loss did not improve for 10 epochs.
Generate examples Step 421, Loss 0.8408065538553265
Epoch: 213
Negative Examples
['aaabbaab', 'aabab', 'b']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabab', 'abaaabab', 'aaabaaaab', 'ababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.0917541980743408
Train Epoch 1, Loss 0.4834252893924713
Train Epoch 2, Loss 0.20162349939346313
Accuracy at epoch 213: 0.9755859375, total training samples: 3732
Early stopping at epoch 413. Loss did not improve for 10 epochs.
Generate examples Step 413, Loss 0.6480637272630912
Epoch: 214
Negative Examples
['aaabbbab', 'aababaa', 'aabbbab', 'b', 'bab', 'babab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaaab', 'aaababab', 'aab', 'aabaab', 'aabaabab', 'aabab', 'ab', 'abaabab', 'abab', 'ababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 214: No counterexamples found, skipped.
Early stopping at epoch 469. Loss did not improve for 10 epochs.
Generate examples Step 469, Loss 0.4907369297552616
Epoch: 215
Negative Examples
['aababaa', 'abbbab', 'b', 'bab']
Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaabaab', 'aaabab', 'aab', 'aabab', 'ab', 'abab', 'ababaaab', 'ababab', 'abababab', 'baabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baabab', 'aababb', 'abaabaabb', 'b']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.21539677679538727
Train Epoch 1, Loss 0.09920672327280045
Train Epoch 2, Loss 0.06273005902767181
Accuracy at epoch 215: 0.9755859375, total training samples: 3736
Early stopping at epoch 796. Loss did not improve for 10 epochs.
Generate examples Step 796, Loss 0.9290018116066716
Epoch: 216
Negative Examples
['aabbaab', 'abaaab', 'b', 'bbaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaababab', 'aaabbaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'aaabaab', 'abaabaab', 'aabaaaaab', 'aaabbaab', 'aaabb', 'ababababb', 'b']
Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.4920842945575714
Train Epoch 1, Loss 0.29331058263778687
Train Epoch 2, Loss 0.2003668248653412
Accuracy at epoch 216: 0.984375, total training samples: 3744
Early stopping at epoch 368. Loss did not improve for 10 epochs.
Generate examples Step 368, Loss 0.7651062786256072
Epoch: 217
Negative Examples
['aabbaab', 'abbaab', 'b', 'baaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aaabab', 'aab', 'aabaaaab', 'aabaaab', 'aabab', 'ab', 'abaab', 'ababaaab', 'baaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaab', 'aaaabb', 'aabb', 'abb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.29302021861076355
Train Epoch 1, Loss 0.0839528888463974
Train Epoch 2, Loss 0.036573536694049835
Accuracy at epoch 217: 0.966796875, total training samples: 3748
Early stopping at epoch 712. Loss did not improve for 10 epochs.
Generate examples Step 712, Loss 0.8321810354691568
Epoch: 218
Negative Examples
['aaabbaab', 'b']
Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 218: No counterexamples found, skipped.
Early stopping at epoch 570. Loss did not improve for 10 epochs.
Generate examples Step 570, Loss 0.8516321767858782
Epoch: 219
Negative Examples
['aabaab', 'abaaab', 'b']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'aaabab', 'aaaaaabab', 'abaaabaab', 'abaaab', 'abaaaaaab', 'abaaabab', 'aaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.7364820241928101
Train Epoch 1, Loss 0.2566152811050415
Train Epoch 2, Loss 0.12109801173210144
Accuracy at epoch 219: 0.978515625, total training samples: 3756
Early stopping at epoch 423. Loss did not improve for 10 epochs.
Generate examples Step 423, Loss 1.0265701379416123
Epoch: 220
Negative Examples
['aabbbab', 'abbaabab', 'b', 'baaabaaa']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabab', 'aab', 'aabab', 'aabbaab', 'ab', 'abaaabab', 'abaab', 'ababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaab', 'aabaaaabb', 'aabababb', 'abb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.3207862377166748
Train Epoch 1, Loss 0.10525334626436234
Train Epoch 2, Loss 0.046389784663915634
Accuracy at epoch 220: 0.9521484375, total training samples: 3760
Early stopping at epoch 458. Loss did not improve for 10 epochs.
Generate examples Step 458, Loss 0.7808644667040548
Epoch: 221
Negative Examples
['aab', 'aabaab', 'abaab', 'abab', 'abbbbab', 'b']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aabaaab', 'aabab', 'ab', 'abaaabab', 'baaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aab', 'aabaaabab', 'abababaab', 'aaaaabab', 'aabaab', 'abab', 'abababab', 'aabaaab', 'abaab', 'abaaaaaab', 'abaaaab', 'aababaab', 'abab', 'ababaaab', 'aabaabaab', 'aabaab', 'baaaaaab', 'aaaaaaabb', 'abaababb', 'aabaabb']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Neg Neg Neg Neg
Train Epoch 0, Loss 0.657470703125
Train Epoch 1, Loss 0.4618197977542877
Train Epoch 2, Loss 0.34990352392196655
Accuracy at epoch 221: 0.9873046875, total training samples: 3780
Early stopping at epoch 454. Loss did not improve for 10 epochs.
Generate examples Step 454, Loss 0.7363404104342828
Epoch: 222
Negative Examples
['aaabbbab', 'abbab', 'b', 'baab']
Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabab', 'aaabbab', 'aab', 'aabaab', 'aabaabab', 'aababab', 'aabbab', 'ab', 'abaabab', 'abab', 'abababab', 'baaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbab', 'aaaaaaabb', 'abaabaabb', 'abb', 'aabbab', 'aabaababb', 'aaababb', 'aaabaabb', 'baaaabab', 'aabaaabb', 'abaaaabb', 'aabaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3389633595943451
Train Epoch 1, Loss 0.1559750735759735
Train Epoch 2, Loss 0.0679498016834259
Accuracy at epoch 222: 0.9609375, total training samples: 3792
Early stopping at epoch 407. Loss did not improve for 10 epochs.
Generate examples Step 407, Loss 0.7163603461402304
Epoch: 223
Negative Examples
['aaaabaab', 'aaabaab', 'abaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaab', 'aaaabab', 'ababaab', 'aabab', 'aaabaab', 'aabababab', 'aabaaaaab', 'abaaaabab', 'abaab', 'aaabab', 'aaababaab', 'aaaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.8680159449577332
Train Epoch 1, Loss 0.43174251914024353
Train Epoch 2, Loss 0.22356808185577393
Accuracy at epoch 223: 0.9873046875, total training samples: 3804
Early stopping at epoch 408. Loss did not improve for 10 epochs.
Generate examples Step 408, Loss 0.5720913463014845
Epoch: 224
Negative Examples
['abbaab', 'abbab', 'b', 'baab', 'bababaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaabaab', 'aab', 'aabab', 'aabbab', 'ab', 'abaab', 'abaabbab', 'abab', 'ababaab', 'baabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbab', 'ababb', 'aaabababb', 'aaaabb', 'abaabbab', 'aabaababb', 'abaaaabb', 'aabababb', 'baabaab', 'aaaaaaabb', 'aaaaaabb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.2750426232814789
Train Epoch 1, Loss 0.11387169361114502
Train Epoch 2, Loss 0.06054389104247093
Accuracy at epoch 224: 0.9873046875, total training samples: 3816
Early stopping at epoch 436. Loss did not improve for 10 epochs.
Generate examples Step 436, Loss 0.7084476774903675
Epoch: 225
Negative Examples
['aabaab', 'aabbaab', 'abaaab', 'b']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'ab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'abaaaabab', 'aaaaaaaab', 'aaaaabaab', 'abaaab', 'aabab', 'abab', 'aaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.4840778708457947
Train Epoch 1, Loss 0.2115444839000702
Train Epoch 2, Loss 0.11934074014425278
Accuracy at epoch 225: 0.9609375, total training samples: 3824
Early stopping at epoch 390. Loss did not improve for 10 epochs.
Generate examples Step 390, Loss 0.8133552644563757
Epoch: 226
Negative Examples
['abaa', 'abbbaab', 'b', 'bab', 'babab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaabab', 'aaab', 'aab', 'aabaab', 'aabab', 'aabbaab', 'ab', 'abaab', 'abaabab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaab', 'abaabb', 'aaaabb', 'ababababb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.2832638919353485
Train Epoch 1, Loss 0.08798146992921829
Train Epoch 2, Loss 0.04145205765962601
Accuracy at epoch 226: 0.98828125, total training samples: 3828
Early stopping at epoch 476. Loss did not improve for 10 epochs.
Generate examples Step 476, Loss 0.8168045151158698
Epoch: 227
Negative Examples
['aaaa', 'abaabab', 'b', 'baaaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaabab', 'aab', 'aabaaaab', 'aabaaab', 'ab', 'abaaaaab', 'abaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaabab', 'aab', 'abaababab', 'aababaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.0633692741394043
Train Epoch 1, Loss 0.40218985080718994
Train Epoch 2, Loss 0.1629633605480194
Accuracy at epoch 227: 0.9580078125, total training samples: 3832
Early stopping at epoch 336. Loss did not improve for 10 epochs.
Generate examples Step 336, Loss 0.6309529915673089
Epoch: 228
Negative Examples
['aa', 'abaa', 'abaaa', 'abbab', 'abbabbab', 'abbbabab', 'b', 'baabbab', 'bab', 'babbab', 'bbabaab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaa', 'aab', 'ab', 'abaaaaa', 'abaaaab', 'abaab', 'abab', 'abbaabab', 'baaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaaa', 'aababaa', 'aaabaaba', 'abaabaa', 'abaaaaa', 'aaabaaba', 'aababaaba', 'aaaabaaba', 'abbaabab', 'aaaababb', 'ababaabb', 'aaabaabb', 'baaaab', 'abaaaaabb', 'abaabb', 'ababababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.43828311562538147
Train Epoch 1, Loss 0.18968015909194946
Train Epoch 2, Loss 0.08687566965818405
Accuracy at epoch 228: 0.994140625, total training samples: 3848
Early stopping at epoch 460. Loss did not improve for 10 epochs.
Generate examples Step 460, Loss 0.8559287340418635
Epoch: 229
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaabaab', 'aaab', 'aaabab', 'aab', 'aabaab', 'aabaabab', 'aabab', 'ab', 'abaab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 229: No counterexamples found, skipped.
Early stopping at epoch 394. Loss did not improve for 10 epochs.
Generate examples Step 394, Loss 0.7936350786987739
Epoch: 230
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aab', 'aabaaab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 230: No counterexamples found, skipped.
Early stopping at epoch 497. Loss did not improve for 10 epochs.
Generate examples Step 497, Loss 0.6807642109602331
Epoch: 231
Negative Examples
['abaaab', 'b']
Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaab', 'aabab', 'ab', 'abaab', 'abaabaab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'ababaaab', 'aaaaab', 'abaabaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.9193271994590759
Train Epoch 1, Loss 0.2730441093444824
Train Epoch 2, Loss 0.09332676231861115
Accuracy at epoch 231: 0.9658203125, total training samples: 3852
Early stopping at epoch 368. Loss did not improve for 10 epochs.
Generate examples Step 368, Loss 0.4240748470391684
Epoch: 232
Negative Examples
['abaa', 'b', 'baab', 'bab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabab', 'aabbaab', 'ab', 'abaaab', 'abab', 'ababaaaa', 'ababab', 'ababbaab', 'baaaab', 'baaab', 'baabaab', 'babab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaab', 'abaabaabb', 'aaaababb', 'abb', 'ababaaaa', 'abaaaabaa', 'aaaaababa', 'aabaaa', 'ababbaab', 'ababaabb', 'aaaabb', 'abababb', 'baaaab', 'aabababb', 'ababaaabb', 'abababb', 'baaab', 'aaaaabb', 'abaaabb', 'ababb', 'baabaab', 'ababb', 'abaababb', 'ababaaabb', 'babab', 'aaaaabb', 'abaaaaabb', 'ababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.31372228264808655
Train Epoch 1, Loss 0.150131493806839
Train Epoch 2, Loss 0.08142374455928802
Accuracy at epoch 232: 0.9912109375, total training samples: 3880
Early stopping at epoch 518. Loss did not improve for 10 epochs.
Generate examples Step 518, Loss 0.6013878759908309
Epoch: 233
Negative Examples
['abaab', 'b', 'bab', 'bbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaab', 'aaaabaaab', 'abaaaab', 'aaabaaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5585677027702332
Train Epoch 1, Loss 0.22822800278663635
Train Epoch 2, Loss 0.09328562021255493
Accuracy at epoch 233: 0.9697265625, total training samples: 3884
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.9275030324549687
Epoch: 234
Negative Examples
['b']
Neg
Positive Examples
['aaab', 'aaabaab', 'aaabbaab', 'aab', 'aabab', 'ab', 'abaab', 'abaabaab', 'abab', 'ababaab', 'baaabaab', 'babaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaabbaab', 'aabaaabb', 'ababb', 'abaababb', 'baaabaab', 'aaaabaabb', 'abaababb', 'ababaabb', 'babaab', 'aababb', 'ababababb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3472260534763336
Train Epoch 1, Loss 0.14982055127620697
Train Epoch 2, Loss 0.07304524630308151
Accuracy at epoch 234: 0.98828125, total training samples: 3896
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.7612046679380104
Epoch: 235
Negative Examples
['abbbbaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaaab', 'ab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 235: No counterexamples found, skipped.
Early stopping at epoch 469. Loss did not improve for 10 epochs.
Generate examples Step 469, Loss 0.7149815305116328
Epoch: 236
Negative Examples
['aabaab', 'b', 'baaaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabaab', 'aaababab', 'aaaabab', 'abab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.5750133395195007
Train Epoch 1, Loss 0.21341052651405334
Train Epoch 2, Loss 0.11025141179561615
Accuracy at epoch 236: 0.990234375, total training samples: 3900
Early stopping at epoch 441. Loss did not improve for 10 epochs.
Generate examples Step 441, Loss 0.34889729042870427
Epoch: 237
Negative Examples
['aa', 'aabaaaa', 'aabbbaab', 'abaa', 'abaaabaa', 'abbab', 'b', 'baaab', 'baab', 'baabaaab', 'bab', 'bbbbab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aabab', 'ab', 'abaab', 'abab', 'ababab', 'baaaabab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['baaaabab', 'abaababb', 'b', 'abaaaabb']
Neg Neg Neg Neg
Train Epoch 0, Loss 0.48268240690231323
Train Epoch 1, Loss 0.16521677374839783
Train Epoch 2, Loss 0.08949527889490128
Accuracy at epoch 237: 0.9912109375, total training samples: 3904
Early stopping at epoch 545. Loss did not improve for 10 epochs.
Generate examples Step 545, Loss 0.7483031625821913
Epoch: 238
Negative Examples
['aababaab', 'abbaab', 'b']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aababaab', 'aaabaabab', 'abaabab', 'aaaaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.64336097240448
Train Epoch 1, Loss 0.23383577167987823
Train Epoch 2, Loss 0.09402543306350708
Accuracy at epoch 238: 0.9794921875, total training samples: 3908
Early stopping at epoch 536. Loss did not improve for 10 epochs.
Generate examples Step 536, Loss 0.5531412596143158
Epoch: 239
Negative Examples
['abaa', 'abbabaa', 'b', 'baab', 'babaab', 'bababaab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabab', 'aabab', 'aababaab', 'aabbab', 'aabbabab', 'ab', 'abaab', 'abab', 'ababaab', 'abbab', 'baabab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbab', 'aabb', 'aaaaababb', 'ababababb', 'aabbabab', 'aaaaaaabb', 'aaaaaabb', 'abaababb', 'abbab', 'aaabaabb', 'ababb', 'aaababb', 'baabab', 'aaaaababb', 'aaababb', 'abababb', 'bab', 'abaaaaabb', 'ababababb', 'abaaababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3403932452201843
Train Epoch 1, Loss 0.16010794043540955
Train Epoch 2, Loss 0.08460839837789536
Accuracy at epoch 239: 0.98828125, total training samples: 3928
Early stopping at epoch 487. Loss did not improve for 10 epochs.
Generate examples Step 487, Loss 1.1417110873172518
Epoch: 240
Negative Examples
['aababaab', 'abbbaab', 'b']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aababaab', 'aaabaaaab', 'aaaabab', 'ab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.3610859513282776
Train Epoch 1, Loss 0.13352572917938232
Train Epoch 2, Loss 0.07381437718868256
Accuracy at epoch 240: 0.9892578125, total training samples: 3932
Early stopping at epoch 424. Loss did not improve for 10 epochs.
Generate examples Step 424, Loss 0.7590685585667105
Epoch: 241
Negative Examples
['aaabaaa', 'aabbbaab', 'abbab', 'abbabaaa', 'b', 'baabaab', 'baabab', 'babaab']
Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaa', 'aaab', 'aab', 'aabaab', 'aababaaa', 'aabbab', 'ab', 'abaab', 'abaabaab', 'abab', 'ababaab', 'ababab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aaaabaa', 'aaaaaaaba', 'aaaababaa', 'aba', 'aababaaa', 'aaaabaaaa', 'aabaaba', 'ababaabaa', 'aabbab', 'ababb', 'ababaabb', 'aabaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.3502921760082245
Train Epoch 1, Loss 0.17516975104808807
Train Epoch 2, Loss 0.09636852145195007
Accuracy at epoch 241: 0.9990234375, total training samples: 3944
Early stopping at epoch 448. Loss did not improve for 10 epochs.
Generate examples Step 448, Loss 0.836296429214605
Epoch: 242
Negative Examples
['b']
Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 242: No counterexamples found, skipped.
Early stopping at epoch 437. Loss did not improve for 10 epochs.
Generate examples Step 437, Loss 0.5158346397759708
Epoch: 243
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 243: No counterexamples found, skipped.
Early stopping at epoch 490. Loss did not improve for 10 epochs.
Generate examples Step 490, Loss 0.6756204231632703
Epoch: 244
Negative Examples
['b', 'babaab', 'babbaab', 'bbbaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 244: No counterexamples found, skipped.
Early stopping at epoch 490. Loss did not improve for 10 epochs.
Generate examples Step 490, Loss 0.6151742819552509
Epoch: 245
Negative Examples
['b', 'baaaab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aaabab', 'aab', 'aabaaaab', 'aabaab', 'aabaabab', 'aababaab', 'ab', 'abaaaaab', 'abaaaab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 245: No counterexamples found, skipped.
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.5960247370098096
Epoch: 246
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 246: No counterexamples found, skipped.
Early stopping at epoch 457. Loss did not improve for 10 epochs.
Generate examples Step 457, Loss 0.8320323185889481
Epoch: 247
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 247: No counterexamples found, skipped.
Early stopping at epoch 496. Loss did not improve for 10 epochs.
Generate examples Step 496, Loss 0.561615943159136
Epoch: 248
Negative Examples
['b', 'baaaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaaab', 'abaaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 248: No counterexamples found, skipped.
Early stopping at epoch 551. Loss did not improve for 10 epochs.
Generate examples Step 551, Loss 0.511077362018219
Epoch: 249
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 249: No counterexamples found, skipped.
Early stopping at epoch 404. Loss did not improve for 10 epochs.
Generate examples Step 404, Loss 0.7513621939921085
Epoch: 250
Negative Examples
['b']
Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 250: No counterexamples found, skipped.
Early stopping at epoch 457. Loss did not improve for 10 epochs.
Generate examples Step 457, Loss 0.6456384071226203
Epoch: 251
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaaaaab', 'abaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 251: No counterexamples found, skipped.
Early stopping at epoch 313. Loss did not improve for 10 epochs.
Generate examples Step 313, Loss 0.5668992149364797
Epoch: 252
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abaabab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 252: No counterexamples found, skipped.
Early stopping at epoch 403. Loss did not improve for 10 epochs.
Generate examples Step 403, Loss 0.649649558902377
Epoch: 253
Negative Examples
['aabbaaab', 'b', 'baab', 'bbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 253: No counterexamples found, skipped.
Early stopping at epoch 421. Loss did not improve for 10 epochs.
Generate examples Step 421, Loss 0.5677882236256419
Epoch: 254
Negative Examples
['aaaaaaaa', 'b', 'baab', 'babaab', 'bbbaab', 'bbbbaab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 254: No counterexamples found, skipped.
Early stopping at epoch 470. Loss did not improve for 10 epochs.
Generate examples Step 470, Loss 0.7008500254837571
Epoch: 255
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaab', 'aaabaab', 'aaabab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 255: No counterexamples found, skipped.
Early stopping at epoch 395. Loss did not improve for 10 epochs.
Generate examples Step 395, Loss 0.8999428326132322
Epoch: 256
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 256: No counterexamples found, skipped.
Early stopping at epoch 480. Loss did not improve for 10 epochs.
Generate examples Step 480, Loss 0.5282852290635793
Epoch: 257
Negative Examples
['b', 'baabaab']
Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 257: No counterexamples found, skipped.
Early stopping at epoch 622. Loss did not improve for 10 epochs.
Generate examples Step 622, Loss 0.7131910056689004
Epoch: 258
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 258: No counterexamples found, skipped.
Early stopping at epoch 554. Loss did not improve for 10 epochs.
Generate examples Step 554, Loss 0.46304557291237086
Epoch: 259
Negative Examples
['aaaaa', 'b', 'baaab', 'babaab', 'bbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 259: No counterexamples found, skipped.
Early stopping at epoch 406. Loss did not improve for 10 epochs.
Generate examples Step 406, Loss 0.8938664666557781
Epoch: 260
Negative Examples
['b']
Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 260: No counterexamples found, skipped.
Early stopping at epoch 508. Loss did not improve for 10 epochs.
Generate examples Step 508, Loss 0.4123886412628039
Epoch: 261
Negative Examples
['b', 'baaaaab', 'baaab', 'baabaab', 'babaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 261: No counterexamples found, skipped.
Early stopping at epoch 565. Loss did not improve for 10 epochs.
Generate examples Step 565, Loss 0.5646362095386738
Epoch: 262
Negative Examples
['b', 'baabaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 262: No counterexamples found, skipped.
Early stopping at epoch 402. Loss did not improve for 10 epochs.
Generate examples Step 402, Loss 0.7177922724937978
Epoch: 263
Negative Examples
['aabbaaab', 'abaaa', 'b', 'baaaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 263: No counterexamples found, skipped.
Early stopping at epoch 601. Loss did not improve for 10 epochs.
Generate examples Step 601, Loss 0.37098921577993815
Epoch: 264
Negative Examples
['b', 'baab', 'baabaab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 264: No counterexamples found, skipped.
Early stopping at epoch 476. Loss did not improve for 10 epochs.
Generate examples Step 476, Loss 0.6984113976203171
Epoch: 265
Negative Examples
['b']
Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 265: No counterexamples found, skipped.
Early stopping at epoch 441. Loss did not improve for 10 epochs.
Generate examples Step 441, Loss 0.65625438293046
Epoch: 266
Negative Examples
['b', 'baab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 266: No counterexamples found, skipped.
Early stopping at epoch 510. Loss did not improve for 10 epochs.
Generate examples Step 510, Loss 0.5417789216727427
Epoch: 267
Negative Examples
['aabbaaab', 'b', 'baab', 'baabaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 267: No counterexamples found, skipped.
Early stopping at epoch 445. Loss did not improve for 10 epochs.
Generate examples Step 445, Loss 0.5968776580798252
Epoch: 268
Negative Examples
['b', 'baaaab', 'baabaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 268: No counterexamples found, skipped.
Early stopping at epoch 520. Loss did not improve for 10 epochs.
Generate examples Step 520, Loss 0.6566677469896035
Epoch: 269
Negative Examples
['b', 'baab', 'baabaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 269: No counterexamples found, skipped.
Early stopping at epoch 507. Loss did not improve for 10 epochs.
Generate examples Step 507, Loss 0.7483942481124495
Epoch: 270
Negative Examples
['b', 'baaaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 270: No counterexamples found, skipped.
Early stopping at epoch 522. Loss did not improve for 10 epochs.
Generate examples Step 522, Loss 0.7218163651672421
Epoch: 271
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 271: No counterexamples found, skipped.
Early stopping at epoch 486. Loss did not improve for 10 epochs.
Generate examples Step 486, Loss 0.5723116413156599
Epoch: 272
Negative Examples
['b', 'baaab', 'baab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 272: No counterexamples found, skipped.
Early stopping at epoch 419. Loss did not improve for 10 epochs.
Generate examples Step 419, Loss 0.5125013948196456
Epoch: 273
Negative Examples
['b', 'bbbaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 273: No counterexamples found, skipped.
Early stopping at epoch 542. Loss did not improve for 10 epochs.
Generate examples Step 542, Loss 0.7091304503422415
Epoch: 274
Negative Examples
['b', 'baaaab', 'baaab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 274: No counterexamples found, skipped.
Early stopping at epoch 434. Loss did not improve for 10 epochs.
Generate examples Step 434, Loss 0.6891979580980608
Epoch: 275
Negative Examples
['b', 'baabaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 275: No counterexamples found, skipped.
Early stopping at epoch 479. Loss did not improve for 10 epochs.
Generate examples Step 479, Loss 0.6319591954350472
Epoch: 276
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 276: No counterexamples found, skipped.
Early stopping at epoch 498. Loss did not improve for 10 epochs.
Generate examples Step 498, Loss 0.8431721822412793
Epoch: 277
Negative Examples
['aabbaaab', 'b', 'baab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaabab', 'aaab', 'aaabaab', 'aab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 277: No counterexamples found, skipped.
Early stopping at epoch 526. Loss did not improve for 10 epochs.
Generate examples Step 526, Loss 0.5688942186180962
Epoch: 278
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 278: No counterexamples found, skipped.
Early stopping at epoch 656. Loss did not improve for 10 epochs.
Generate examples Step 656, Loss 0.5630431639050422
Epoch: 279
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 279: No counterexamples found, skipped.
Early stopping at epoch 442. Loss did not improve for 10 epochs.
Generate examples Step 442, Loss 0.6259242180507824
Epoch: 280
Negative Examples
['b', 'baaaab', 'baab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 280: No counterexamples found, skipped.
Early stopping at epoch 574. Loss did not improve for 10 epochs.
Generate examples Step 574, Loss 0.6433025121429692
Epoch: 281
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 281: No counterexamples found, skipped.
Early stopping at epoch 457. Loss did not improve for 10 epochs.
Generate examples Step 457, Loss 0.5162872820604576
Epoch: 282
Negative Examples
['b', 'baab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 282: No counterexamples found, skipped.
Early stopping at epoch 425. Loss did not improve for 10 epochs.
Generate examples Step 425, Loss 0.5230390791881812
Epoch: 283
Negative Examples
['b', 'bbbbab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 283: No counterexamples found, skipped.
Early stopping at epoch 536. Loss did not improve for 10 epochs.
Generate examples Step 536, Loss 0.6212718672148564
Epoch: 284
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abaabab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 284: No counterexamples found, skipped.
Early stopping at epoch 379. Loss did not improve for 10 epochs.
Generate examples Step 379, Loss 0.6264073100137083
Epoch: 285
Negative Examples
['b', 'babbaab']
Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 285: No counterexamples found, skipped.
Early stopping at epoch 514. Loss did not improve for 10 epochs.
Generate examples Step 514, Loss 0.6160847615848467
Epoch: 286
Negative Examples
['b', 'baaaab', 'baabaab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 286: No counterexamples found, skipped.
Early stopping at epoch 415. Loss did not improve for 10 epochs.
Generate examples Step 415, Loss 0.45106045984161586
Epoch: 287
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 287: No counterexamples found, skipped.
Early stopping at epoch 458. Loss did not improve for 10 epochs.
Generate examples Step 458, Loss 0.4604518738187736
Epoch: 288
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 288: No counterexamples found, skipped.
Early stopping at epoch 510. Loss did not improve for 10 epochs.
Generate examples Step 510, Loss 0.6025329201597057
Epoch: 289
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 289: No counterexamples found, skipped.
Early stopping at epoch 406. Loss did not improve for 10 epochs.
Generate examples Step 406, Loss 0.5136517353300967
Epoch: 290
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 290: No counterexamples found, skipped.
Early stopping at epoch 427. Loss did not improve for 10 epochs.
Generate examples Step 427, Loss 0.456651627425557
Epoch: 291
Negative Examples
['b', 'baaab', 'baab', 'baabaab', 'babbaab', 'bbbaab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 291: No counterexamples found, skipped.
Early stopping at epoch 461. Loss did not improve for 10 epochs.
Generate examples Step 461, Loss 0.5664413715208764
Epoch: 292
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 292: No counterexamples found, skipped.
Early stopping at epoch 421. Loss did not improve for 10 epochs.
Generate examples Step 421, Loss 0.7588433481717561
Epoch: 293
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 293: No counterexamples found, skipped.
Early stopping at epoch 502. Loss did not improve for 10 epochs.
Generate examples Step 502, Loss 0.7008544321562613
Epoch: 294
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aaabaab', 'aab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 294: No counterexamples found, skipped.
Early stopping at epoch 481. Loss did not improve for 10 epochs.
Generate examples Step 481, Loss 0.4829630051967514
Epoch: 295
Negative Examples
['b', 'baab', 'babaab', 'babbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 295: No counterexamples found, skipped.
Early stopping at epoch 410. Loss did not improve for 10 epochs.
Generate examples Step 410, Loss 0.5817441622706225
Epoch: 296
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 296: No counterexamples found, skipped.
Early stopping at epoch 415. Loss did not improve for 10 epochs.
Generate examples Step 415, Loss 0.48531997674861205
Epoch: 297
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 297: No counterexamples found, skipped.
Early stopping at epoch 452. Loss did not improve for 10 epochs.
Generate examples Step 452, Loss 0.7960717634649466
Epoch: 298
Negative Examples
['b']
Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 298: No counterexamples found, skipped.
Early stopping at epoch 501. Loss did not improve for 10 epochs.
Generate examples Step 501, Loss 0.44788687780083886
Epoch: 299
Negative Examples
['aabbbaab', 'b', 'babaab', 'babbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 299: No counterexamples found, skipped.
Early stopping at epoch 414. Loss did not improve for 10 epochs.
Generate examples Step 414, Loss 0.5308096796274185
Epoch: 300
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 300: No counterexamples found, skipped.
Early stopping at epoch 552. Loss did not improve for 10 epochs.
Generate examples Step 552, Loss 0.5206985414890442
Epoch: 301
Negative Examples
['b', 'baab', 'baabaab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 301: No counterexamples found, skipped.
Early stopping at epoch 421. Loss did not improve for 10 epochs.
Generate examples Step 421, Loss 0.7736044682880149
Epoch: 302
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 302: No counterexamples found, skipped.
Early stopping at epoch 496. Loss did not improve for 10 epochs.
Generate examples Step 496, Loss 0.45176546125704614
Epoch: 303
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 303: No counterexamples found, skipped.
Early stopping at epoch 414. Loss did not improve for 10 epochs.
Generate examples Step 414, Loss 0.4767435142613319
Epoch: 304
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 304: No counterexamples found, skipped.
Early stopping at epoch 451. Loss did not improve for 10 epochs.
Generate examples Step 451, Loss 0.6061053565184099
Epoch: 305
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 305: No counterexamples found, skipped.
Early stopping at epoch 615. Loss did not improve for 10 epochs.
Generate examples Step 615, Loss 0.48653224836309233
Epoch: 306
Negative Examples
['abbaaab', 'b', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 306: No counterexamples found, skipped.
Early stopping at epoch 473. Loss did not improve for 10 epochs.
Generate examples Step 473, Loss 0.5286372089876404
Epoch: 307
Negative Examples
['b', 'baaaab', 'baab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaaaab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 307: No counterexamples found, skipped.
Early stopping at epoch 461. Loss did not improve for 10 epochs.
Generate examples Step 461, Loss 0.5216329072267463
Epoch: 308
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 308: No counterexamples found, skipped.
Early stopping at epoch 367. Loss did not improve for 10 epochs.
Generate examples Step 367, Loss 0.4717091778293252
Epoch: 309
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 309: No counterexamples found, skipped.
Early stopping at epoch 543. Loss did not improve for 10 epochs.
Generate examples Step 543, Loss 0.5476564879748312
Epoch: 310
Negative Examples
['b', 'baabaab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aaabab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 310: No counterexamples found, skipped.
Early stopping at epoch 455. Loss did not improve for 10 epochs.
Generate examples Step 455, Loss 0.5432651955307576
Epoch: 311
Negative Examples
['b', 'baaab', 'bab', 'babbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 311: No counterexamples found, skipped.
Early stopping at epoch 470. Loss did not improve for 10 epochs.
Generate examples Step 470, Loss 0.5787183865746621
Epoch: 312
Negative Examples
['aaaaa', 'abaaa', 'abbaaab', 'b', 'baab', 'bbbbaab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 312: No counterexamples found, skipped.
Early stopping at epoch 621. Loss did not improve for 10 epochs.
Generate examples Step 621, Loss 0.8391625019227577
Epoch: 313
Negative Examples
['aaaaa', 'b', 'baabaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 313: No counterexamples found, skipped.
Early stopping at epoch 426. Loss did not improve for 10 epochs.
Generate examples Step 426, Loss 0.39078224755701474
Epoch: 314
Negative Examples
['aabbaaab', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 314: No counterexamples found, skipped.
Early stopping at epoch 493. Loss did not improve for 10 epochs.
Generate examples Step 493, Loss 0.5716817675512812
Epoch: 315
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 315: No counterexamples found, skipped.
Early stopping at epoch 433. Loss did not improve for 10 epochs.
Generate examples Step 433, Loss 0.667493144556674
Epoch: 316
Negative Examples
['aaaaa', 'b', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 316: No counterexamples found, skipped.
Early stopping at epoch 485. Loss did not improve for 10 epochs.
Generate examples Step 485, Loss 0.5954419834991541
Epoch: 317
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 317: No counterexamples found, skipped.
Early stopping at epoch 514. Loss did not improve for 10 epochs.
Generate examples Step 514, Loss 0.6654288127584365
Epoch: 318
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 318: No counterexamples found, skipped.
Early stopping at epoch 474. Loss did not improve for 10 epochs.
Generate examples Step 474, Loss 0.6022662662204943
Epoch: 319
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 319: No counterexamples found, skipped.
Early stopping at epoch 532. Loss did not improve for 10 epochs.
Generate examples Step 532, Loss 0.6566612223411367
Epoch: 320
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 320: No counterexamples found, skipped.
Early stopping at epoch 364. Loss did not improve for 10 epochs.
Generate examples Step 364, Loss 0.6246152462208108
Epoch: 321
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 321: No counterexamples found, skipped.
Early stopping at epoch 552. Loss did not improve for 10 epochs.
Generate examples Step 552, Loss 0.5452105664323079
Epoch: 322
Negative Examples
['b', 'baab', 'baabaab', 'babaab', 'babbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 322: No counterexamples found, skipped.
Early stopping at epoch 453. Loss did not improve for 10 epochs.
Generate examples Step 453, Loss 0.5230722411285413
Epoch: 323
Negative Examples
['b', 'baab', 'babbaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 323: No counterexamples found, skipped.
Early stopping at epoch 331. Loss did not improve for 10 epochs.
Generate examples Step 331, Loss 0.4899698302867901
Epoch: 324
Negative Examples
['abbbaab', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 324: No counterexamples found, skipped.
Early stopping at epoch 538. Loss did not improve for 10 epochs.
Generate examples Step 538, Loss 0.6666564409221921
Epoch: 325
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 325: No counterexamples found, skipped.
Early stopping at epoch 448. Loss did not improve for 10 epochs.
Generate examples Step 448, Loss 0.5909061300794372
Epoch: 326
Negative Examples
['aaaaa', 'b']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 326: No counterexamples found, skipped.
Early stopping at epoch 541. Loss did not improve for 10 epochs.
Generate examples Step 541, Loss 0.4373590990736036
Epoch: 327
Negative Examples
['b', 'baab', 'baabaab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aababaab', 'abaaaab', 'abaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 327: No counterexamples found, skipped.
Early stopping at epoch 434. Loss did not improve for 10 epochs.
Generate examples Step 434, Loss 0.5610470721091347
Epoch: 328
Negative Examples
['b', 'baaaab', 'baab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 328: No counterexamples found, skipped.
Early stopping at epoch 382. Loss did not improve for 10 epochs.
Generate examples Step 382, Loss 0.5692704225411302
Epoch: 329
Negative Examples
['b', 'baab', 'baabaab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 329: No counterexamples found, skipped.
Early stopping at epoch 530. Loss did not improve for 10 epochs.
Generate examples Step 530, Loss 0.6098484648374065
Epoch: 330
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 330: No counterexamples found, skipped.
Early stopping at epoch 511. Loss did not improve for 10 epochs.
Generate examples Step 511, Loss 0.7694834255671594
Epoch: 331
Negative Examples
['b']
Neg
Positive Examples
['aaaaabab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 331: No counterexamples found, skipped.
Early stopping at epoch 422. Loss did not improve for 10 epochs.
Generate examples Step 422, Loss 0.5083691637707658
Epoch: 332
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 332: No counterexamples found, skipped.
Early stopping at epoch 508. Loss did not improve for 10 epochs.
Generate examples Step 508, Loss 0.5635005029280669
Epoch: 333
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 333: No counterexamples found, skipped.
Early stopping at epoch 446. Loss did not improve for 10 epochs.
Generate examples Step 446, Loss 0.540715236958508
Epoch: 334
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaabab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 334: No counterexamples found, skipped.
Early stopping at epoch 536. Loss did not improve for 10 epochs.
Generate examples Step 536, Loss 0.6254465557232471
Epoch: 335
Negative Examples
['b', 'baabaab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 335: No counterexamples found, skipped.
Early stopping at epoch 575. Loss did not improve for 10 epochs.
Generate examples Step 575, Loss 0.5390962873999443
Epoch: 336
Negative Examples
['b', 'baaab', 'baabaab']
Neg Neg Neg
Positive Examples
['aaaaabab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 336: No counterexamples found, skipped.
Early stopping at epoch 471. Loss did not improve for 10 epochs.
Generate examples Step 471, Loss 0.4581610564205606
Epoch: 337
Negative Examples
['b', 'baab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 337: No counterexamples found, skipped.
Early stopping at epoch 522. Loss did not improve for 10 epochs.
Generate examples Step 522, Loss 0.6002520771259103
Epoch: 338
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 338: No counterexamples found, skipped.
Early stopping at epoch 502. Loss did not improve for 10 epochs.
Generate examples Step 502, Loss 0.5307810956512247
Epoch: 339
Negative Examples
['aabbaaab', 'b', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 339: No counterexamples found, skipped.
Early stopping at epoch 560. Loss did not improve for 10 epochs.
Generate examples Step 560, Loss 0.6017178293324197
Epoch: 340
Negative Examples
['b', 'baabaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 340: No counterexamples found, skipped.
Early stopping at epoch 475. Loss did not improve for 10 epochs.
Generate examples Step 475, Loss 0.5406841366481381
Epoch: 341
Negative Examples
['b', 'baaab', 'baab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 341: No counterexamples found, skipped.
Early stopping at epoch 541. Loss did not improve for 10 epochs.
Generate examples Step 541, Loss 0.5164944819858593
Epoch: 342
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 342: No counterexamples found, skipped.
Early stopping at epoch 501. Loss did not improve for 10 epochs.
Generate examples Step 501, Loss 0.46678642324539293
Epoch: 343
Negative Examples
['b', 'baab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 343: No counterexamples found, skipped.
Early stopping at epoch 409. Loss did not improve for 10 epochs.
Generate examples Step 409, Loss 0.5799075478097288
Epoch: 344
Negative Examples
['aaaaa', 'b', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 344: No counterexamples found, skipped.
Early stopping at epoch 559. Loss did not improve for 10 epochs.
Generate examples Step 559, Loss 0.4653096972831658
Epoch: 345
Negative Examples
['b', 'baaaab', 'baab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 345: No counterexamples found, skipped.
Early stopping at epoch 455. Loss did not improve for 10 epochs.
Generate examples Step 455, Loss 0.4175380919651504
Epoch: 346
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 346: No counterexamples found, skipped.
Early stopping at epoch 414. Loss did not improve for 10 epochs.
Generate examples Step 414, Loss 0.4029439828841083
Epoch: 347
Negative Examples
['b', 'baab', 'babaab', 'babbaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 347: No counterexamples found, skipped.
Early stopping at epoch 508. Loss did not improve for 10 epochs.
Generate examples Step 508, Loss 0.647388954352302
Epoch: 348
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 348: No counterexamples found, skipped.
Early stopping at epoch 440. Loss did not improve for 10 epochs.
Generate examples Step 440, Loss 0.5579411925034188
Epoch: 349
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 349: No counterexamples found, skipped.
Early stopping at epoch 336. Loss did not improve for 10 epochs.
Generate examples Step 336, Loss 0.6114930904274171
Epoch: 350
Negative Examples
['b', 'baaaab', 'baaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 350: No counterexamples found, skipped.
Early stopping at epoch 328. Loss did not improve for 10 epochs.
Generate examples Step 328, Loss 0.6423897957457597
Epoch: 351
Negative Examples
['aabbaaab', 'b']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 351: No counterexamples found, skipped.
Early stopping at epoch 524. Loss did not improve for 10 epochs.
Generate examples Step 524, Loss 0.792747539622443
Epoch: 352
Negative Examples
['aabbaaab', 'b', 'bbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 352: No counterexamples found, skipped.
Early stopping at epoch 460. Loss did not improve for 10 epochs.
Generate examples Step 460, Loss 0.5608145120087001
Epoch: 353
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 353: No counterexamples found, skipped.
Early stopping at epoch 437. Loss did not improve for 10 epochs.
Generate examples Step 437, Loss 0.600183474622905
Epoch: 354
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 354: No counterexamples found, skipped.
Early stopping at epoch 419. Loss did not improve for 10 epochs.
Generate examples Step 419, Loss 0.4102576170648847
Epoch: 355
Negative Examples
['b', 'baaab', 'baab', 'baabaab', 'babaab', 'bbaab']
Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 355: No counterexamples found, skipped.
Early stopping at epoch 408. Loss did not improve for 10 epochs.
Generate examples Step 408, Loss 0.6784435553990833
Epoch: 356
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 356: No counterexamples found, skipped.
Early stopping at epoch 342. Loss did not improve for 10 epochs.
Generate examples Step 342, Loss 0.7160241995712758
Epoch: 357
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 357: No counterexamples found, skipped.
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.48863477282880885
Epoch: 358
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 358: No counterexamples found, skipped.
Early stopping at epoch 673. Loss did not improve for 10 epochs.
Generate examples Step 673, Loss 0.48364352172887287
Epoch: 359
Negative Examples
['b', 'baabaab']
Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaaaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 359: No counterexamples found, skipped.
Early stopping at epoch 399. Loss did not improve for 10 epochs.
Generate examples Step 399, Loss 0.5910373049229384
Epoch: 360
Negative Examples
['b', 'baab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 360: No counterexamples found, skipped.
Early stopping at epoch 452. Loss did not improve for 10 epochs.
Generate examples Step 452, Loss 0.6115806942875548
Epoch: 361
Negative Examples
['aabbaaab', 'b', 'baaaab', 'baab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 361: No counterexamples found, skipped.
Early stopping at epoch 427. Loss did not improve for 10 epochs.
Generate examples Step 427, Loss 0.5885777930581124
Epoch: 362
Negative Examples
['b', 'baaab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 362: No counterexamples found, skipped.
Early stopping at epoch 501. Loss did not improve for 10 epochs.
Generate examples Step 501, Loss 0.6167963370680809
Epoch: 363
Negative Examples
['b', 'baab', 'baabaab', 'babbaab']
Neg Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 363: No counterexamples found, skipped.
Early stopping at epoch 500. Loss did not improve for 10 epochs.
Generate examples Step 500, Loss 0.7003180759395667
Epoch: 364
Negative Examples
['b', 'baaaab', 'baab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 364: No counterexamples found, skipped.
Early stopping at epoch 461. Loss did not improve for 10 epochs.
Generate examples Step 461, Loss 0.7563397698588186
Epoch: 365
Negative Examples
['aabbaaab', 'b', 'baaab', 'baab', 'babaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaabaab', 'aaab', 'aab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 365: No counterexamples found, skipped.
Early stopping at epoch 566. Loss did not improve for 10 epochs.
Generate examples Step 566, Loss 0.47470175943992754
Epoch: 366
Negative Examples
['b', 'baaab']
Neg Neg
Positive Examples
['aaaaabab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 366: No counterexamples found, skipped.
Early stopping at epoch 491. Loss did not improve for 10 epochs.
Generate examples Step 491, Loss 0.7515323966802135
Epoch: 367
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aab', 'aabaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 367: No counterexamples found, skipped.
Early stopping at epoch 569. Loss did not improve for 10 epochs.
Generate examples Step 569, Loss 0.4941322289537965
Epoch: 368
Negative Examples
['b', 'baab', 'babaab', 'babbaab', 'bbbbaab']
Neg Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 368: No counterexamples found, skipped.
Early stopping at epoch 409. Loss did not improve for 10 epochs.
Generate examples Step 409, Loss 0.606511858287381
Epoch: 369
Negative Examples
['aabbaaab', 'b', 'babaab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 369: No counterexamples found, skipped.
Early stopping at epoch 466. Loss did not improve for 10 epochs.
Generate examples Step 466, Loss 0.7020737276087481
Epoch: 370
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 370: No counterexamples found, skipped.
Early stopping at epoch 550. Loss did not improve for 10 epochs.
Generate examples Step 550, Loss 0.5736806095998647
Epoch: 371
Negative Examples
['b', 'baabaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'aabab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 371: No counterexamples found, skipped.
Early stopping at epoch 457. Loss did not improve for 10 epochs.
Generate examples Step 457, Loss 0.7442843508967666
Epoch: 372
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'abaabab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 372: No counterexamples found, skipped.
Early stopping at epoch 462. Loss did not improve for 10 epochs.
Generate examples Step 462, Loss 0.6889261521286377
Epoch: 373
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaaabab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 373: No counterexamples found, skipped.
Early stopping at epoch 431. Loss did not improve for 10 epochs.
Generate examples Step 431, Loss 0.556592860845504
Epoch: 374
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 374: No counterexamples found, skipped.
Early stopping at epoch 537. Loss did not improve for 10 epochs.
Generate examples Step 537, Loss 0.8515377348240424
Epoch: 375
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 375: No counterexamples found, skipped.
Early stopping at epoch 413. Loss did not improve for 10 epochs.
Generate examples Step 413, Loss 0.9204722920765623
Epoch: 376
Negative Examples
['b']
Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 376: No counterexamples found, skipped.
Early stopping at epoch 401. Loss did not improve for 10 epochs.
Generate examples Step 401, Loss 0.6351490374191187
Epoch: 377
Negative Examples
['b', 'baab']
Neg Neg
Positive Examples
['aaaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab', 'abaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 377: No counterexamples found, skipped.
Early stopping at epoch 501. Loss did not improve for 10 epochs.
Generate examples Step 501, Loss 0.4002279666849817
Epoch: 378
Negative Examples
['b', 'babaab']
Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 378: No counterexamples found, skipped.
Early stopping at epoch 448. Loss did not improve for 10 epochs.
Generate examples Step 448, Loss 0.5586477806812405
Epoch: 379
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 379: No counterexamples found, skipped.
Early stopping at epoch 587. Loss did not improve for 10 epochs.
Generate examples Step 587, Loss 0.9020362159832805
Epoch: 380
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaabaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 380: No counterexamples found, skipped.
Early stopping at epoch 474. Loss did not improve for 10 epochs.
Generate examples Step 474, Loss 0.4818402142587461
Epoch: 381
Negative Examples
['b', 'baab', 'baabaab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 381: No counterexamples found, skipped.
Early stopping at epoch 445. Loss did not improve for 10 epochs.
Generate examples Step 445, Loss 0.3510489996372317
Epoch: 382
Negative Examples
['baaab', 'baabaab', 'babaab']
Neg Neg Neg
Positive Examples
['aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 382: No counterexamples found, skipped.
Early stopping at epoch 394. Loss did not improve for 10 epochs.
Generate examples Step 394, Loss 0.6440577186738389
Epoch: 383
Negative Examples
['b']
Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aaabab', 'aab', 'aabaaaab', 'aabaab', 'ab', 'abaaaaab', 'abaab', 'abaabaab', 'abab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 383: No counterexamples found, skipped.
Early stopping at epoch 426. Loss did not improve for 10 epochs.
Generate examples Step 426, Loss 0.6222532850797059
Epoch: 384
Negative Examples
['b', 'baab', 'babaab']
Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 384: No counterexamples found, skipped.
Early stopping at epoch 423. Loss did not improve for 10 epochs.
Generate examples Step 423, Loss 0.6080375029441883
Epoch: 385
Negative Examples
['b', 'babaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 385: No counterexamples found, skipped.
Early stopping at epoch 443. Loss did not improve for 10 epochs.
Generate examples Step 443, Loss 0.6311983059722561
Epoch: 386
Negative Examples
['b']
Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 386: No counterexamples found, skipped.
Early stopping at epoch 562. Loss did not improve for 10 epochs.
Generate examples Step 562, Loss 0.47261469648426424
Epoch: 387
Negative Examples
['b', 'baabaab', 'bbbbaab']
Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 387: No counterexamples found, skipped.
Early stopping at epoch 388. Loss did not improve for 10 epochs.
Generate examples Step 388, Loss 0.6038559934550508
Epoch: 388
Negative Examples
['aabbaaab', 'b', 'baab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaaaab', 'abaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 388: No counterexamples found, skipped.
Early stopping at epoch 430. Loss did not improve for 10 epochs.
Generate examples Step 430, Loss 0.5292749667665522
Epoch: 389
Negative Examples
['b', 'baaaaab', 'baab', 'babaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 389: No counterexamples found, skipped.
Early stopping at epoch 420. Loss did not improve for 10 epochs.
Generate examples Step 420, Loss 0.544744651313349
Epoch: 390
Negative Examples
['b', 'baab', 'babaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaaab', 'aaaab', 'aaab', 'aab', 'aabaaaab', 'aabaab', 'aababaab', 'ab', 'abaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 390: No counterexamples found, skipped.
Early stopping at epoch 497. Loss did not improve for 10 epochs.
Generate examples Step 497, Loss 0.6096377294944472
Epoch: 391
Negative Examples
['b']
Neg
Positive Examples
['aaaaaaab', 'aaaaaab', 'aaaab', 'aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaab', 'abaab', 'abaabaab', 'ababaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 391: No counterexamples found, skipped.
Early stopping at epoch 489. Loss did not improve for 10 epochs.
Generate examples Step 489, Loss 0.6675407328775951
Epoch: 392
Negative Examples
['ababaaab', 'b', 'baab']
Neg Neg Neg
Positive Examples
['aaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abaab', 'abaabaab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ababaaab', 'aaabab', 'abaaab', 'aabababab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.6437531113624573
Train Epoch 1, Loss 0.1808488517999649
Train Epoch 2, Loss 0.07655860483646393
Accuracy at epoch 392: 0.9345703125, total training samples: 3948
Early stopping at epoch 384. Loss did not improve for 10 epochs.
Generate examples Step 384, Loss 0.4662421610254746
Epoch: 393
Negative Examples
['b', 'bab', 'bbbaab']
Neg Neg Neg
Positive Examples
['aaaaabab', 'aab', 'ab', 'abaaab', 'abaab', 'abab', 'ababab', 'ababbaab', 'abbaabab', 'abbabab', 'abbbaab', 'baaaab', 'baaab', 'babaaab', 'bababab', 'bbaaaaab', 'bbaab', 'bbabaaab', 'bbbabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['ababbaab', 'aaaaaaabb', 'aaaabb', 'aaaababb', 'abbaabab', 'ababababb', 'aabb', 'aaabaaabb', 'abbabab', 'aaabaaabb', 'aabaaaabb', 'aaaababb', 'abbbaab', 'abaaababb', 'abaababb', 'aaabaabb', 'baaaab', 'aaaaabb', 'aaaaaabb', 'abaaababb', 'baaab', 'abaababb', 'abaaababb', 'aabaababb', 'babaaab', 'aaabababb', 'abaabaabb', 'aaaaaabb', 'bababab', 'aabababb', 'abaababb', 'abaabb', 'bbaaaaab', 'ababaabb', 'aababb', 'aabaaaabb', 'bbaab', 'aaaaaaabb', 'abababb', 'abaabb', 'bbabaaab', 'aababb', 'abaabaabb', 'ababababb', 'bbbabab', 'aaaabb', 'aababaabb', 'abaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.28445718437433243
Train Epoch 1, Loss 0.09184157475829124
Train Epoch 2, Loss 0.053244397044181824
Accuracy at epoch 393: 0.982421875, total training samples: 3996
Early stopping at epoch 378. Loss did not improve for 10 epochs.
Generate examples Step 378, Loss 0.8992600385935137
Epoch: 394
Negative Examples
['b', 'bbbbaab']
Neg Neg
Positive Examples
['aaaaaab', 'aaaab', 'aaaabaab', 'aaaabab', 'aaab', 'aaabaaab', 'aaabaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
[]

Round 394: No counterexamples found, skipped.
Early stopping at epoch 430. Loss did not improve for 10 epochs.
Generate examples Step 430, Loss 0.8256293455713586
Epoch: 395
Negative Examples
['abaab', 'b', 'babbaab', 'bbbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaaab', 'aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'ab']
Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaab', 'abababab', 'ab', 'aaabaab']
Pos Pos Pos Pos
Train Epoch 0, Loss 1.0581692457199097
Train Epoch 1, Loss 0.6621258854866028
Train Epoch 2, Loss 0.3356863260269165
Accuracy at epoch 395: 0.9619140625, total training samples: 4000
Early stopping at epoch 468. Loss did not improve for 10 epochs.
Generate examples Step 468, Loss 0.4835086961163641
Epoch: 396
Negative Examples
['aa', 'aabbbaab', 'ababbab', 'abbab', 'b', 'baaaaab', 'baaaab', 'baabab', 'babaab']
Neg Neg Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaab', 'aaabaab', 'aab', 'aabbab', 'ab', 'abaab', 'abab', 'ababaab', 'ababab', 'baab', 'bab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbab', 'aaaaababb', 'abaaabb', 'aaabb', 'baab', 'aaaaaabb', 'abaaaaabb', 'aababaabb', 'bab', 'ababaaabb', 'aaaababb', 'abababb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.20857053995132446
Train Epoch 1, Loss 0.1049252524971962
Train Epoch 2, Loss 0.05910971760749817
Accuracy at epoch 396: 0.990234375, total training samples: 4012
Early stopping at epoch 521. Loss did not improve for 10 epochs.
Generate examples Step 521, Loss 0.8064656980421351
Epoch: 397
Negative Examples
['aabbaaab', 'abaab', 'ababaab', 'ababab', 'b', 'bbbaab', 'bbbbaab']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaaaaab', 'aaaab', 'aaab', 'aaabaab', 'aab', 'aabab', 'aababaab', 'ab', 'abaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaab', 'abaaaaab', 'abaab', 'abaabab', 'ababaab', 'abaaaaaab', 'aaaabab', 'ababaaab', 'ababab', 'abaaaabab', 'aaaaab', 'aabaaaaab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Train Epoch 0, Loss 0.6191868782043457
Train Epoch 1, Loss 0.2098047137260437
Train Epoch 2, Loss 0.10032594203948975
Accuracy at epoch 397: 0.9697265625, total training samples: 4024
Early stopping at epoch 530. Loss did not improve for 10 epochs.
Generate examples Step 530, Loss 0.6213645111145049
Epoch: 398
Negative Examples
['abaaaaa', 'ababaa', 'abbab', 'abbbab', 'b', 'baab', 'bbaab']
Neg Neg Neg Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aab', 'aabaab', 'aabbaaab', 'ab', 'abaab', 'abab', 'ababbaab', 'baaaab', 'baaab', 'baabaab', 'baabab', 'babaabab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['aabbaaab', 'abb', 'aabaababb', 'aabaabb', 'ababbaab', 'aababb', 'aaaaabb', 'aaabb', 'baaaab', 'aabaababb', 'aabaabb', 'abb', 'baaab', 'aaabb', 'abb', 'abaaaaabb', 'baabaab', 'aabababb', 'ababb', 'abaaabb', 'baabab', 'aaaabaabb', 'aaabaabb', 'aaaabb', 'babaabab', 'aababb', 'abaaaaabb', 'aaaaaaabb']
Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg Neg
Train Epoch 0, Loss 0.4131746292114258
Train Epoch 1, Loss 0.1569250077009201
Train Epoch 2, Loss 0.06296254694461823
Accuracy at epoch 398: 0.9921875, total training samples: 4052
Early stopping at epoch 542. Loss did not improve for 10 epochs.
Generate examples Step 542, Loss 0.9864940287658522
Epoch: 399
Negative Examples
['abaaab', 'abbbaab', 'b', 'bbbaab']
Neg Neg Neg Neg
Positive Examples
['aaaab', 'aaaabaab', 'aaab', 'aaabaab', 'aab', 'aabaab', 'aababaab', 'ab', 'abaaaaab', 'abab']
Pos Pos Pos Pos Pos Pos Pos Pos Pos Pos
Counterexamples
['abaaab', 'aabaabaab', 'ababaab', 'abaabab']
Pos Pos Pos Pos
Train Epoch 0, Loss 0.8806191682815552
Train Epoch 1, Loss 0.2919367253780365
Train Epoch 2, Loss 0.1289484202861786
Accuracy at epoch 399: 0.9814453125, total training samples: 4056
