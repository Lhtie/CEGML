['ccbc', 'babb', 'cbaaaaac', 'bbbba', 'baba', 'bbcc', 'aaca', 'baac', 'baaacaac', 'cabbbbbb', 'bbbccac', 'bbccc', 'aaacbbac', 'acbb', 'cabbc', 'abbbac']
Train Epoch 0, Loss 0.6980591416358948
Train Epoch 1, Loss 0.690117359161377
Train Epoch 2, Loss 0.6824361681938171
Accuracy at epoch 0: 0.669921875
['cbbcbbb', 'abcaacba', 'bacbbac', 'abba', 'ccabccbb', 'baba', 'abcacac', 'acbcab', 'baba', 'baba', 'cbbbcccc', 'cccaa', 'abaaac', 'acbbcbb', 'baabbb', 'abbbaac']
Train Epoch 0, Loss 0.6719446778297424
Train Epoch 1, Loss 0.658525824546814
Train Epoch 2, Loss 0.6439372301101685
Accuracy at epoch 1: 0.66015625
['acbb', 'bbaaba', 'aaaabbba', 'bcaa', 'bccbaba', 'bcabcbba', 'baacbcc', 'ccab', 'baaac', 'acbc', 'cbbaa', 'bcabaaac', 'baba', 'aacbab', 'acbcb', 'cabca']
Train Epoch 0, Loss 0.6473534107208252
Train Epoch 1, Loss 0.6312932968139648
Train Epoch 2, Loss 0.6137735843658447
Accuracy at epoch 2: 0.625
['baacaba', 'bbabb', 'bbaaa', 'ccbbca', 'abba', 'abcbaa', 'caacabb', 'babbb', 'acacacb', 'aaab', 'cbcbcc', 'abaac', 'cbcabc', 'bccca', 'acbac', 'accabc']
Train Epoch 0, Loss 0.6319853663444519
Train Epoch 1, Loss 0.613736629486084
Train Epoch 2, Loss 0.5939047336578369
Accuracy at epoch 3: 0.6953125
['abba', 'cccc', 'abaccba', 'acacb', 'bacaba', 'caaba', 'baaba', 'abcccac', 'abaccaac', 'bcbcc', 'cccaacca', 'bcba', 'bcccacab', 'ccbc', 'acbcbcc', 'bbcca']
Train Epoch 0, Loss 0.6245332360267639
Train Epoch 1, Loss 0.6035176515579224
Train Epoch 2, Loss 0.582737147808075
Accuracy at epoch 4: 0.7109375
['cbcaccac', 'acaccaa', 'cbaa', 'abbba', 'bbcbca', 'babbcccc', 'baba', 'cabcccb', 'abbbca', 'cccbcc', 'bcccba', 'babaaba', 'abbcca', 'abbbcb', 'abbbbbac', 'bcbc']
Train Epoch 0, Loss 0.5964439511299133
Train Epoch 1, Loss 0.5618122816085815
Train Epoch 2, Loss 0.5282682180404663
Accuracy at epoch 5: 0.693359375
['aacbbcba', 'acacbac', 'accacc', 'cabaaab', 'ccaacba', 'baaccbb', 'cabbbc', 'bbbbacac', 'ccacc', 'cbcb', 'bbba', 'bbcaaaa', 'ccac', 'aaccaa', 'aaba', 'abbbbcac']
Train Epoch 0, Loss 0.721997857093811
Train Epoch 1, Loss 0.4807443618774414
Train Epoch 2, Loss 0.31769755482673645
Accuracy at epoch 6: 0.5
['baba', 'acacca', 'bcba', 'acbccbc', 'abcaaaba', 'ababbcba', 'bacba', 'aacc', 'cbbcabac', 'bccac', 'babbacac', 'aaaab', 'acca', 'babccc', 'baacb', 'abcac']
Train Epoch 0, Loss 0.8453729748725891
Train Epoch 1, Loss 0.6949043869972229
Train Epoch 2, Loss 0.610241174697876
Accuracy at epoch 7: 0.681640625
['bbbcaca', 'cacbb', 'ccbbcccb', 'ccbcb', 'cabbabb', 'bbaaaaa', 'acabcac', 'aabaa', 'abcc', 'ccbb', 'cbcbbcaa', 'abcbbca', 'acab', 'acccb', 'bcca', 'ccab']
Train Epoch 0, Loss 0.5154717564582825
Train Epoch 1, Loss 0.3748573660850525
Train Epoch 2, Loss 0.26657673716545105
Accuracy at epoch 8: 0.51953125
['cbbab', 'bbabc', 'ababbbaa', 'bbbcaa', 'abacc', 'abaaba', 'bbcc', 'cbaccbac', 'acbacc', 'cbaaaa', 'bcacaba', 'baccccba', 'bccbabcb', 'aacabc', 'bcccbaab', 'cbaac']
Train Epoch 0, Loss 0.8719196319580078
Train Epoch 1, Loss 0.7525209784507751
Train Epoch 2, Loss 0.6814378499984741
Accuracy at epoch 9: 0.6484375
['baab', 'aabbcacb', 'cbccbc', 'ccccb', 'ccbbcc', 'caccbab', 'ccaabba', 'accaaccb', 'abcbbcba', 'abcacaaa', 'cbbbcab', 'babaabb', 'abaccac', 'cbbb', 'abbbaba', 'aacbc']
Train Epoch 0, Loss 0.5548170804977417
Train Epoch 1, Loss 0.5123996734619141
Train Epoch 2, Loss 0.4824705123901367
Accuracy at epoch 10: 0.62890625
['bacbbba', 'babbac', 'bcbcbaca', 'baba', 'ccbaba', 'acccbc', 'cbca', 'acca', 'abcacbc', 'bbabbaa', 'aabb', 'aabba', 'bbbbbbb', 'abba', 'cccab', 'baaaccb']
Train Epoch 0, Loss 0.6455677151679993
Train Epoch 1, Loss 0.6061735153198242
Train Epoch 2, Loss 0.5845779180526733
Accuracy at epoch 11: 0.67578125
['cabccc', 'babbbaa', 'baccac', 'cbbbbab', 'abbbbbba', 'abcac', 'ababcacb', 'baaaba', 'baaaac', 'cbcbcc', 'cccccbaa', 'ccbccba', 'bccac', 'caccb', 'abcba', 'cbcba']
Train Epoch 0, Loss 0.5249385237693787
Train Epoch 1, Loss 0.4642735421657562
Train Epoch 2, Loss 0.4176197648048401
Accuracy at epoch 12: 0.71484375
['babc', 'bccabcca', 'abab', 'bcbacbb', 'baac', 'bbcaba', 'baaaac', 'bacba', 'acaab', 'ababacca', 'bbabcc', 'ccaabbca', 'bcbbaabb', 'bcabacbc', 'cbbacaac', 'abba']
Train Epoch 0, Loss 0.6165766716003418
Train Epoch 1, Loss 0.5598939657211304
Train Epoch 2, Loss 0.5314692258834839
Accuracy at epoch 13: 0.681640625
['cbacc', 'ababa', 'bbcac', 'cacabca', 'ccbaccb', 'baacb', 'baacaba', 'abacac', 'bbaabacb', 'bcbc', 'caba', 'baacba', 'abbbac', 'baac', 'bcaccbb', 'acaa']
Train Epoch 0, Loss 0.532375156879425
Train Epoch 1, Loss 0.475350558757782
Train Epoch 2, Loss 0.4548121392726898
Accuracy at epoch 14: 0.76171875
['abaac', 'cbcb', 'bacaba', 'cacc', 'baac', 'cbca', 'abccaac', 'aabaa', 'bbcbca', 'ccbabaa', 'acbaacba', 'bacb', 'cbab', 'abccbaca', 'abcac', 'baacac']
Train Epoch 0, Loss 0.4300287365913391
Train Epoch 1, Loss 0.39235731959342957
Train Epoch 2, Loss 0.3616839647293091
Accuracy at epoch 15: 0.75390625
['abcbbc', 'aaab', 'caaac', 'abba', 'bbcccca', 'bacccac', 'ccccbaa', 'abca', 'acaaabb', 'accab', 'aacc', 'baba', 'cbccca', 'bbcb', 'bacaac', 'abbcab']
Train Epoch 0, Loss 0.5480222105979919
Train Epoch 1, Loss 0.4931528866291046
Train Epoch 2, Loss 0.46375083923339844
Accuracy at epoch 16: 0.767578125
['abba', 'caaa', 'bbabcb', 'cacbb', 'abaaaba', 'abaacb', 'aaacb', 'bccbc', 'acababca', 'abbbbbac', 'bcbbab', 'accaaca', 'baccac', 'bacabcac', 'cccab', 'accaaccb']
Train Epoch 0, Loss 0.41967764496803284
Train Epoch 1, Loss 0.386322021484375
Train Epoch 2, Loss 0.35975906252861023
Accuracy at epoch 17: 0.79296875
['baba', 'bacac', 'abccac', 'baccabac', 'acca', 'bccc', 'accaccb', 'ccaaccc', 'cabb', 'bcab', 'ccabccc', 'cbbbabc', 'abaaba', 'aaccabb', 'abba', 'cbcba']
Train Epoch 0, Loss 0.4022727906703949
Train Epoch 1, Loss 0.34233102202415466
Train Epoch 2, Loss 0.2910439372062683
Accuracy at epoch 18: 0.79296875
['bacac', 'cacbba', 'abccaabc', 'aabbba', 'bcbaca', 'bacbbaba', 'bbcacbca', 'aabaaaab', 'aaaacba', 'abaacba', 'abcba', 'bacbcac', 'baaaa', 'abcbbaac', 'bacaab', 'babacaba']
Train Epoch 0, Loss 0.7741641402244568
Train Epoch 1, Loss 0.6635242104530334
Train Epoch 2, Loss 0.5897409915924072
Accuracy at epoch 19: 0.78515625
['accac', 'cacaaac', 'acbcaacb', 'acccaac', 'bcbcccba', 'cbccba', 'abcabb', 'caccca', 'bbab', 'baccaba', 'bbbb', 'aabbbaa', 'bacba', 'bccc', 'babbcba', 'aacaabc']
Train Epoch 0, Loss 0.4907575845718384
Train Epoch 1, Loss 0.418886661529541
Train Epoch 2, Loss 0.39700230956077576
Accuracy at epoch 20: 0.771484375
['bccbccbc', 'babbba', 'abac', 'babbac', 'ccaa', 'aacbbcc', 'bcabcc', 'bbac', 'accca', 'babac', 'cbcaaabc', 'acabaaab', 'babacab', 'ccacacbc', 'baabbac', 'abaaca']
Train Epoch 0, Loss 0.6318543553352356
Train Epoch 1, Loss 0.5115079283714294
Train Epoch 2, Loss 0.4184471666812897
Accuracy at epoch 21: 0.82421875
['baacccac', 'bbcc', 'cccccba', 'cbaacacb', 'aacccaac', 'baaccac', 'aacaa', 'bccabab', 'bacbbac', 'bbabca', 'ccba', 'abcba', 'abccccc', 'bcbaabb', 'cbbacbba', 'bbbcaa']
Train Epoch 0, Loss 0.5852077603340149
Train Epoch 1, Loss 0.4698987603187561
Train Epoch 2, Loss 0.4502277076244354
Accuracy at epoch 22: 0.748046875
['bbaac', 'abcba', 'ababa', 'bccabbbc', 'cacccab', 'bacccab', 'cacca', 'cacca', 'cbbca', 'aaabbcaa', 'ccbcc', 'bcca', 'bccbaca', 'aacca', 'acacbcb', 'ccbbbc']
Train Epoch 0, Loss 0.40067175030708313
Train Epoch 1, Loss 0.3107094168663025
Train Epoch 2, Loss 0.2756362855434418
Accuracy at epoch 23: 0.7421875
['ccabaa', 'abca', 'baacba', 'cbaa', 'babb', 'ccbaa', 'aaacccb', 'acccc', 'baccbbba', 'abbaba', 'baccbaa', 'bbabba', 'bbcca', 'bbacaca', 'abbca', 'bbaaaa']
Train Epoch 0, Loss 0.6736565828323364
Train Epoch 1, Loss 0.493153840303421
Train Epoch 2, Loss 0.382418155670166
Accuracy at epoch 24: 0.697265625
['cabcbab', 'bcbbacb', 'abab', 'abaaba', 'ccccc', 'accbcaa', 'acbab', 'aabcb', 'cbcbbb', 'ccbba', 'bcaccab', 'bbcb', 'bcbacc', 'bbcaa', 'bbbcacaa', 'bacba']
Train Epoch 0, Loss 0.4477592706680298
Train Epoch 1, Loss 0.33721914887428284
Train Epoch 2, Loss 0.2568138539791107
Accuracy at epoch 25: 0.83984375
['acaacbaa', 'bbbcbbac', 'acacbccb', 'acbab', 'cccbcba', 'bcaaab', 'baabaca', 'babbcbc', 'acaac', 'bbaac', 'babcabac', 'cbbbabc', 'ababa', 'acaba', 'bcbbacc', 'abacaa']
Train Epoch 0, Loss 0.37738555669784546
Train Epoch 1, Loss 0.2701966464519501
Train Epoch 2, Loss 0.22609183192253113
Accuracy at epoch 26: 0.568359375
['abbabbcc', 'bcabbcca', 'bcbabba', 'babbcab', 'baccacac', 'cbccacc', 'abbbcaba', 'cbcca', 'abbbcca', 'ccbc', 'caab', 'bcba', 'aaacbb', 'cabcaaab', 'bbabcaa', 'ccba']
Train Epoch 0, Loss 1.2713404893875122
Train Epoch 1, Loss 0.9845045804977417
Train Epoch 2, Loss 0.7522865533828735
Accuracy at epoch 27: 0.78125
['bbbbcba', 'baccba', 'abac', 'ccbc', 'bbaaaabb', 'ccaca', 'baba', 'bbaca', 'babca', 'baccb', 'aaacaa', 'baab', 'baccaac', 'abbca', 'ccccc', 'abbacac']
Train Epoch 0, Loss 0.6441810131072998
Train Epoch 1, Loss 0.5609546303749084
Train Epoch 2, Loss 0.49968063831329346
Accuracy at epoch 28: 0.818359375
['abcccac', 'bacaacb', 'aaccbcac', 'bbcba', 'bcbc', 'bcbac', 'baac', 'bbca', 'baba', 'aabcbbb', 'bcaaaabc', 'abacbac', 'ccbc', 'ccabaa', 'baabbac', 'babc']
Train Epoch 0, Loss 0.5981625914573669
Train Epoch 1, Loss 0.5544164180755615
Train Epoch 2, Loss 0.5232698917388916
Accuracy at epoch 29: 0.734375
['aabb', 'abaacba', 'accb', 'acaacbca', 'baccbcbc', 'bcca', 'abbb', 'cbba', 'bcba', 'babcaab', 'abcac', 'bacaaba', 'aacacbba', 'cababcb', 'babbabc', 'aacab']
Train Epoch 0, Loss 0.47935134172439575
Train Epoch 1, Loss 0.38929641246795654
Train Epoch 2, Loss 0.37277695536613464
Accuracy at epoch 30: 0.8125
['baccaac', 'abacacac', 'bcccaac', 'cacaac', 'abccb', 'abccba', 'bacac', 'accaa', 'ccaaba', 'ababab', 'baccacac', 'acabc', 'baaccab', 'cacbcabb', 'caacb', 'accbbb']
Train Epoch 0, Loss 0.4621410667896271
Train Epoch 1, Loss 0.41184964776039124
Train Epoch 2, Loss 0.3771826922893524
Accuracy at epoch 31: 0.724609375
['abac', 'abaa', 'baccaa', 'acac', 'abba', 'abbbccac', 'bbabb', 'bccb', 'aacaa', 'babbba', 'baccacca', 'abcac', 'ccaaca', 'bbaccaab', 'bacabbab', 'abbbcba']
Train Epoch 0, Loss 0.5599029064178467
Train Epoch 1, Loss 0.4693135917186737
Train Epoch 2, Loss 0.43719181418418884
Accuracy at epoch 32: 0.802734375
['abacccac', 'baaacba', 'bacaaaba', 'bbac', 'bacaba', 'cccca', 'cacccba', 'aaba', 'ccbab', 'abbbccac', 'cbcc', 'abbbbbb', 'abaccac', 'acabc', 'ccaabb', 'bcbbcac']
Train Epoch 0, Loss 0.5322579145431519
Train Epoch 1, Loss 0.475509375333786
Train Epoch 2, Loss 0.4594060480594635
Accuracy at epoch 33: 0.8125
['bbccabbb', 'baacba', 'cbccb', 'bcccbb', 'abacacac', 'baabbcba', 'cbacbb', 'bacac', 'caba', 'cacb', 'ccbbcc', 'bbbcabc', 'abaabbac', 'abbcaa', 'abab', 'abccac']
Train Epoch 0, Loss 0.3420589864253998
Train Epoch 1, Loss 0.29087045788764954
Train Epoch 2, Loss 0.27134841680526733
Accuracy at epoch 34: 0.83984375
['acccac', 'bcacca', 'cbba', 'baaccba', 'bccca', 'aacc', 'caabbcca', 'bcca', 'ccabaaab', 'bcbaacb', 'bbbab', 'bcba', 'cbcbbcb', 'bbacbc', 'bccaacab', 'bcbba']
Train Epoch 0, Loss 0.44545072317123413
Train Epoch 1, Loss 0.2936716377735138
Train Epoch 2, Loss 0.2828761637210846
Accuracy at epoch 35: 0.81640625
['acaa', 'bbbba', 'ccbcaa', 'cbbbac', 'baaba', 'baacba', 'ccabb', 'abbac', 'abbbcba', 'cbcccc', 'baaaac', 'bbbc', 'baaba', 'bacac', 'ccacbb', 'cabcbbc']
Train Epoch 0, Loss 0.45359140634536743
Train Epoch 1, Loss 0.3519982397556305
Train Epoch 2, Loss 0.3270909786224365
Accuracy at epoch 36: 0.763671875
['abba', 'baacac', 'bccb', 'bbcb', 'acbab', 'bcbac', 'acacbcca', 'bbab', 'bcaaccc', 'cbaccbcb', 'acccac', 'caaab', 'bacbbcbc', 'baacaa', 'bccab', 'ccab']
Train Epoch 0, Loss 0.2788066565990448
Train Epoch 1, Loss 0.2310257852077484
Train Epoch 2, Loss 0.21465598046779633
Accuracy at epoch 37: 0.837890625
['accbc', 'aabaa', 'bbcbcb', 'ccbac', 'bcbbbb', 'acac', 'baccaba', 'ababa', 'bacbccb', 'cabbaca', 'baba', 'cbbcac', 'caaaac', 'abccac', 'aacccb', 'acbaa']
Train Epoch 0, Loss 0.5865073800086975
Train Epoch 1, Loss 0.4816462993621826
Train Epoch 2, Loss 0.4359648823738098
Accuracy at epoch 38: 0.787109375
['abaa', 'abac', 'bbcbca', 'bbccac', 'bacbcaba', 'baaccbbc', 'acaaaaa', 'aaabca', 'bcba', 'cbabb', 'cacbbacc', 'ccbc', 'cbac', 'ccabbbac', 'cbcacbcb', 'abcac']
Train Epoch 0, Loss 0.5169799327850342
Train Epoch 1, Loss 0.4084796905517578
Train Epoch 2, Loss 0.38094285130500793
Accuracy at epoch 39: 0.79296875
['baba', 'baaba', 'baaaaba', 'bacaab', 'baab', 'aabbba', 'ccbaaba', 'acaccc', 'acbc', 'baacaba', 'abaaccba', 'cbcb', 'abccaba', 'baabc', 'cccaa', 'abac']
Train Epoch 0, Loss 0.5564281344413757
Train Epoch 1, Loss 0.5079221129417419
Train Epoch 2, Loss 0.4791580140590668
Accuracy at epoch 40: 0.814453125
['babbac', 'bcaaabcc', 'aacc', 'aacc', 'abcaac', 'bacbcab', 'abcabc', 'ccbcbba', 'abbaac', 'babbaac', 'babbbbba', 'ccbabcaa', 'bcaba', 'cacab', 'ccccbca', 'bacbac']
Train Epoch 0, Loss 0.3546941876411438
Train Epoch 1, Loss 0.3512150049209595
Train Epoch 2, Loss 0.3095146715641022
Accuracy at epoch 41: 0.818359375
['babcbab', 'abcca', 'ccccaac', 'baacba', 'ccba', 'bbbabb', 'bbacbcbb', 'bababb', 'abcbb', 'baca', 'aacccbbb', 'cbbbcab', 'abbbcb', 'abac', 'abac', 'acabb']
Train Epoch 0, Loss 0.22863167524337769
Train Epoch 1, Loss 0.19707928597927094
Train Epoch 2, Loss 0.14943909645080566
Accuracy at epoch 42: 0.787109375
['cbcccaca', 'bbbbaba', 'abcba', 'bacacb', 'abcacbb', 'ccbcacc', 'abca', 'babcacca', 'abcba', 'cacbb', 'abbaab', 'caaca', 'bcccc', 'abba', 'abaaac', 'cbcc']
Train Epoch 0, Loss 0.2911396622657776
Train Epoch 1, Loss 0.24614326655864716
Train Epoch 2, Loss 0.17838014662265778
Accuracy at epoch 43: 0.783203125
['aaaacab', 'bcac', 'baaaaaca', 'bbcccccc', 'baaba', 'cccbc', 'accccbba', 'abcb', 'cbaaab', 'acabca', 'bbbcbbcb', 'caccbcc', 'cabacaaa', 'baacaaac', 'accab', 'acbb']
Train Epoch 0, Loss 0.2658389210700989
Train Epoch 1, Loss 0.23912668228149414
Train Epoch 2, Loss 0.2075289934873581
Accuracy at epoch 44: 0.8203125
['abcb', 'aacabccb', 'cacb', 'caac', 'abaac', 'cacbaaac', 'bccc', 'aabaaa', 'bcba', 'bbcaaa', 'abaac', 'ccbabaa', 'abaaac', 'aacabcca', 'cacaa', 'abcaba']
Train Epoch 0, Loss 0.239454448223114
Train Epoch 1, Loss 0.23443953692913055
Train Epoch 2, Loss 0.20344318449497223
Accuracy at epoch 45: 0.755859375
['caacbb', 'baaaccba', 'cccaabc', 'bacc', 'baaba', 'bcbbacb', 'baccbbc', 'bccbab', 'acbbcca', 'abcccc', 'abccccba', 'babbac', 'bcbbabca', 'acbacbcb', 'acaacab', 'ababbaba']
Train Epoch 0, Loss 0.3899901509284973
Train Epoch 1, Loss 0.32181403040885925
Train Epoch 2, Loss 0.28830987215042114
Accuracy at epoch 46: 0.798828125
['bbcb', 'bcba', 'cacc', 'ababa', 'acbca', 'acaaca', 'bbbcbac', 'baab', 'cbbcaaa', 'abccac', 'abcbbcac', 'bbcbcca', 'bbacaca', 'cbaaacb', 'abbbaba', 'abcba']
Train Epoch 0, Loss 0.21890708804130554
Train Epoch 1, Loss 0.20122013986110687
Train Epoch 2, Loss 0.14324383437633514
Accuracy at epoch 47: 0.837890625
['acccaab', 'abac', 'abacba', 'cabcba', 'cbcbcc', 'acbaabb', 'bbccabb', 'cbbc', 'bbaca', 'bbbccc', 'baccabc', 'aabc', 'aabbb', 'bacbbbba', 'abaac', 'caabccaa']
Train Epoch 0, Loss 0.4654584527015686
Train Epoch 1, Loss 0.30336037278175354
Train Epoch 2, Loss 0.2651704251766205
Accuracy at epoch 48: 0.6875
['babbba', 'bbccbccc', 'bcbacaca', 'bbca', 'cbccc', 'bacba', 'abba', 'aaba', 'ccbbacb', 'bbbca', 'bbbabcc', 'abccc', 'baaba', 'aacbbbc', 'bbac', 'aabc']
Train Epoch 0, Loss 0.6638758778572083
Train Epoch 1, Loss 0.4827270805835724
Train Epoch 2, Loss 0.4472964406013489
Accuracy at epoch 49: 0.83203125
['ccac', 'aacbc', 'abaaac', 'baaac', 'cabbbabb', 'bbababb', 'ccaabbcb', 'bcbcbca', 'cbbbaa', 'abcac', 'bacccba', 'acaca', 'cccca', 'ccababac', 'ccbbcc', 'bcbb']
Train Epoch 0, Loss 0.387349396944046
Train Epoch 1, Loss 0.34773069620132446
Train Epoch 2, Loss 0.3293915092945099
Accuracy at epoch 50: 0.841796875
['caaba', 'aabacabb', 'baaaaba', 'abaaac', 'abcabc', 'aabc', 'abbaba', 'abbbb', 'acabaa', 'baccac', 'abbabc', 'abcbc', 'baaaba', 'abaaba', 'baac', 'acbaac']
Train Epoch 0, Loss 0.9455083012580872
Train Epoch 1, Loss 0.7116590738296509
Train Epoch 2, Loss 0.5596723556518555
Accuracy at epoch 51: 0.654296875
['abaaba', 'aabac', 'baacac', 'bbcaacc', 'baaca', 'bccac', 'baaba', 'bbaabc', 'bacbbba', 'cacaaaa', 'aacb', 'bacba', 'aabb', 'bcbbabc', 'abcbbaac', 'abaccca']
Train Epoch 0, Loss 0.6563052535057068
Train Epoch 1, Loss 0.5257771015167236
Train Epoch 2, Loss 0.4451257288455963
Accuracy at epoch 52: 0.814453125
['bcbcb', 'cabcc', 'abcaa', 'cbcc', 'cbbac', 'abaac', 'baacabab', 'acccbbba', 'cccabc', 'acac', 'abbabb', 'baaac', 'bbcaac', 'babacba', 'abacccb', 'bbbcbcbc']
Train Epoch 0, Loss 0.5886300802230835
Train Epoch 1, Loss 0.47680196166038513
Train Epoch 2, Loss 0.37975287437438965
Accuracy at epoch 53: 0.830078125
['baaba', 'abac', 'cbac', 'abbbaaac', 'aabcaaa', 'bccab', 'cabbcb', 'aacbc', 'cccac', 'cbacb', 'cbacbac', 'baccaaac', 'cacbcbbb', 'baacbab', 'aacbccc', 'baacb']
Train Epoch 0, Loss 0.4666271209716797
Train Epoch 1, Loss 0.39582911133766174
Train Epoch 2, Loss 0.3371378183364868
Accuracy at epoch 54: 0.8359375
['aaccbb', 'abbaca', 'bcca', 'aabca', 'acccba', 'bccabab', 'bbcca', 'cbbcc', 'caaac', 'bacbabab', 'abbcacb', 'cccacbca', 'abccaca', 'bbcbca', 'aabbca', 'cabbb']
Train Epoch 0, Loss 0.21774141490459442
Train Epoch 1, Loss 0.13706719875335693
Train Epoch 2, Loss 0.08113859593868256
Accuracy at epoch 55: 0.6640625
['aacba', 'ccbabc', 'ccca', 'baba', 'baccba', 'cbbac', 'baacaaba', 'bbcac', 'babacbbc', 'cbcbccb', 'ccaccbc', 'abacba', 'bcab', 'bacba', 'bbbbb', 'cbcbcbbc']
Train Epoch 0, Loss 0.7141328454017639
Train Epoch 1, Loss 0.50090092420578
Train Epoch 2, Loss 0.43877050280570984
Accuracy at epoch 56: 0.8359375
['aaab', 'caacac', 'acaa', 'cbaaabba', 'cbcaa', 'cbcaaaa', 'cbbab', 'aabc', 'bbbbbb', 'abac', 'abbbaa', 'cabbbbb', 'aaaaab', 'bbccc', 'ccbaab', 'acacaca']
Train Epoch 0, Loss 0.5148487687110901
Train Epoch 1, Loss 0.39266785979270935
Train Epoch 2, Loss 0.3055637776851654
Accuracy at epoch 57: 0.732421875
['ccbbb', 'ccbca', 'acbca', 'acccab', 'bacaacba', 'baccac', 'baabcb', 'abaccaac', 'cabaacbb', 'cacacc', 'bccc', 'cbcab', 'cbcca', 'abacacc', 'bcbaaac', 'ccaabbc']
Train Epoch 0, Loss 0.7790513634681702
Train Epoch 1, Loss 0.48644065856933594
Train Epoch 2, Loss 0.3045988082885742
Accuracy at epoch 58: 0.83203125
['babbabbb', 'aaaacaa', 'aaaaaca', 'cccc', 'acbbcac', 'cccabc', 'abacaba', 'bbac', 'cccabab', 'cbaa', 'acacaab', 'abbbabab', 'bcabbb', 'cacaaaba', 'bbca', 'bccaa']
Train Epoch 0, Loss 0.4314768314361572
Train Epoch 1, Loss 0.3395999073982239
Train Epoch 2, Loss 0.2818814218044281
Accuracy at epoch 59: 0.74609375
['baac', 'abcac', 'bacbbcac', 'bcaaaac', 'bbcacaac', 'aabbcc', 'caaba', 'abbbbaac', 'ababa', 'bbcbaab', 'abaac', 'cbcb', 'abaac', 'cbcacabc', 'acac', 'acacb']
Train Epoch 0, Loss 0.5592339038848877
Train Epoch 1, Loss 0.4883266091346741
Train Epoch 2, Loss 0.434306263923645
Accuracy at epoch 60: 0.748046875
['cacbcbc', 'abaacbcb', 'ccccb', 'acccb', 'bacba', 'cbcbac', 'aabba', 'abab', 'accaccc', 'abaacba', 'ccbaaa', 'abaac', 'bbabc', 'bcaa', 'ababbac', 'cbbcbaba']
Train Epoch 0, Loss 0.3365786075592041
Train Epoch 1, Loss 0.31073349714279175
Train Epoch 2, Loss 0.29950252175331116
Accuracy at epoch 61: 0.83984375
['bbbba', 'bcccb', 'caccbc', 'bbaca', 'abcbaac', 'acccacb', 'acabc', 'baac', 'cbbcc', 'baaaaba', 'cbabb', 'bbaca', 'babb', 'bacaac', 'cacb', 'abbbcccc']
Train Epoch 0, Loss 0.2792619466781616
Train Epoch 1, Loss 0.2623298764228821
Train Epoch 2, Loss 0.22782489657402039
Accuracy at epoch 62: 0.802734375
['abbaaa', 'abbbac', 'acacbbbb', 'cbbbbcc', 'bbccaccb', 'aaacc', 'bbcb', 'bbabc', 'abcbbba', 'cbbcc', 'cabacaa', 'baaac', 'bccacca', 'aacc', 'acbba', 'baaaa']
Train Epoch 0, Loss 0.6564160585403442
Train Epoch 1, Loss 0.4597867727279663
Train Epoch 2, Loss 0.4051368236541748
Accuracy at epoch 63: 0.8359375
['baccac', 'cabbccc', 'aabb', 'bbba', 'baacba', 'cccacca', 'acbacca', 'bbac', 'cacc', 'bacbc', 'bacab', 'bbcbab', 'cbcbbb', 'acacca', 'ccccbbaa', 'aabcaaaa']
Train Epoch 0, Loss 0.35837775468826294
Train Epoch 1, Loss 0.3017450273036957
Train Epoch 2, Loss 0.25488248467445374
Accuracy at epoch 64: 0.8125
['cabbb', 'cccacaab', 'cccbbabc', 'baabcc', 'ccbabaca', 'ccbc', 'baccaabc', 'abbbcbc', 'caaca', 'abbbac', 'bbca', 'bacbcaab', 'abcb', 'abccaac', 'bacbbaba', 'abcbcaa']
Train Epoch 0, Loss 0.5149163007736206
Train Epoch 1, Loss 0.40930259227752686
Train Epoch 2, Loss 0.39997464418411255
Accuracy at epoch 65: 0.818359375
['ccba', 'aaabcb', 'cccabcca', 'abcacbbb', 'abcba', 'abcaba', 'bbaa', 'baaaaba', 'babcbcb', 'ccbaccb', 'aabcaaa', 'cbbc', 'acbabaa', 'baccaac', 'aabaca', 'aaba']
Train Epoch 0, Loss 0.4426502287387848
Train Epoch 1, Loss 0.36869004368782043
Train Epoch 2, Loss 0.3402644991874695
Accuracy at epoch 66: 0.861328125
['bcabcbb', 'aaaaaba', 'baabcbb', 'cbbabccc', 'abba', 'aaaccba', 'baabccc', 'aabcabc', 'abaac', 'acccbc', 'ccabb', 'cabca', 'bbbbc', 'caaacc', 'bacbbb', 'bacccac']
Train Epoch 0, Loss 0.5801491737365723
Train Epoch 1, Loss 0.5146282911300659
Train Epoch 2, Loss 0.48005422949790955
Accuracy at epoch 67: 0.734375
['cbbcb', 'aaaccaca', 'ccaaca', 'abcbc', 'ababaaa', 'bbaababc', 'bbbba', 'baaaaab', 'bcbaaac', 'acca', 'cbbaabcb', 'baacac', 'abaaa', 'baaaaba', 'bbcbbb', 'aacbaca']
Train Epoch 0, Loss 0.43288150429725647
Train Epoch 1, Loss 0.3793174922466278
Train Epoch 2, Loss 0.33296966552734375
Accuracy at epoch 68: 0.826171875
['accbc', 'abcca', 'baacc', 'aacc', 'bacaaba', 'cabbcca', 'abaab', 'abcc', 'bacba', 'cbccabba', 'bbac', 'acacbcb', 'baacbac', 'ccbabaa', 'cccab', 'aaaba']
Train Epoch 0, Loss 0.5544558167457581
Train Epoch 1, Loss 0.39031463861465454
Train Epoch 2, Loss 0.3269406855106354
Accuracy at epoch 69: 0.84765625
['acabca', 'bbaa', 'abba', 'cccbbba', 'babbc', 'bbcbcba', 'bcbc', 'ccbb', 'abcca', 'baaaac', 'ccaba', 'bacaacba', 'bbcbab', 'baaba', 'ccbc', 'caababb']
Train Epoch 0, Loss 0.39969611167907715
Train Epoch 1, Loss 0.2756056487560272
Train Epoch 2, Loss 0.21755772829055786
Accuracy at epoch 70: 0.7734375
['abaaba', 'aacaaa', 'bccb', 'babbcac', 'cabcccac', 'cbbc', 'bbccac', 'abac', 'bbcbcab', 'accc', 'bbacc', 'bbcaaa', 'abaac', 'abcaacbb', 'aaab', 'cacaa']
Train Epoch 0, Loss 0.32264915108680725
Train Epoch 1, Loss 0.2512427270412445
Train Epoch 2, Loss 0.25483182072639465
Accuracy at epoch 71: 0.8359375
['ccaa', 'abbbaac', 'abccc', 'ababba', 'abccac', 'caaaaaa', 'aabac', 'baccaba', 'abcaba', 'acaab', 'bbcaaab', 'babcccb', 'abaacac', 'acbaacbc', 'caacbab', 'baac']
Train Epoch 0, Loss 0.7066709399223328
Train Epoch 1, Loss 0.6118979454040527
Train Epoch 2, Loss 0.5318623185157776
Accuracy at epoch 72: 0.884765625
['bccbca', 'abaacba', 'bbacab', 'caaaac', 'ccccaaca', 'bccc', 'bcbcc', 'cbab', 'aaacbcaa', 'aaaa', 'acaabc', 'baacbbac', 'aaaca', 'abaaac', 'aaca', 'acbaabcb']
Train Epoch 0, Loss 0.38589298725128174
Train Epoch 1, Loss 0.34541380405426025
Train Epoch 2, Loss 0.30847883224487305
Accuracy at epoch 73: 0.76171875
['ccbbcbcc', 'cbabc', 'accabc', 'aabccbac', 'cbab', 'cabcbca', 'ccbcb', 'aaba', 'abaaccba', 'bacba', 'abcaac', 'aaccab', 'cbbc', 'bacab', 'caabaca', 'bacaaa']
Train Epoch 0, Loss 0.4597187340259552
Train Epoch 1, Loss 0.32606902718544006
Train Epoch 2, Loss 0.29155513644218445
Accuracy at epoch 74: 0.849609375
['baaccc', 'acab', 'abcba', 'aacc', 'abbbcac', 'cbacabc', 'ccccaaa', 'aacca', 'bcbbbca', 'abaacac', 'cbcacaba', 'ababab', 'accab', 'abaaa', 'abaccba', 'bcbbcb']
Train Epoch 0, Loss 0.16617262363433838
Train Epoch 1, Loss 0.13835088908672333
Train Epoch 2, Loss 0.12121836841106415
Accuracy at epoch 75: 0.810546875
['caccbcaa', 'aaabcaa', 'bcbbaab', 'aacab', 'bccacac', 'babc', 'baccac', 'aaba', 'abaaaba', 'aacc', 'cbbc', 'cccca', 'abba', 'bacac', 'cabc', 'acbaaba']
Train Epoch 0, Loss 0.5929298400878906
Train Epoch 1, Loss 0.4702422618865967
Train Epoch 2, Loss 0.38491135835647583
Accuracy at epoch 76: 0.76953125
['bbcaca', 'cbcccaab', 'abac', 'abcbaccb', 'bbccbcb', 'baaa', 'bcaa', 'bcaa', 'abcccaac', 'baacac', 'ababa', 'bbcbccbc', 'caaccbab', 'abaaac', 'bbbccb', 'baac']
Train Epoch 0, Loss 0.45796817541122437
Train Epoch 1, Loss 0.3459828495979309
Train Epoch 2, Loss 0.2773192226886749
Accuracy at epoch 77: 0.830078125
['ccbccbbc', 'abccbbba', 'aacacc', 'babbcaac', 'ccbbccc', 'baaaba', 'cbcaca', 'aaaacbab', 'abbaacac', 'baba', 'acaccb', 'aabc', 'bcac', 'cabbab', 'cacaccca', 'caaccccc']
Train Epoch 0, Loss 0.485319584608078
Train Epoch 1, Loss 0.4299147129058838
Train Epoch 2, Loss 0.395844429731369
Accuracy at epoch 78: 0.86328125
['abaaba', 'baac', 'caaab', 'acaabcab', 'ccbcca', 'abccaac', 'cbaac', 'bcbcbbb', 'cbbbbb', 'bbbccbc', 'bacac', 'aaac', 'abca', 'bbbbcbcc', 'cbaa', 'bacaac']
Train Epoch 0, Loss 0.38623207807540894
Train Epoch 1, Loss 0.33206477761268616
Train Epoch 2, Loss 0.31624889373779297
Accuracy at epoch 79: 0.869140625
['aacaa', 'aacaac', 'acaac', 'cbbc', 'aaba', 'aabbcab', 'bcaba', 'baac', 'abbacb', 'cbbacabc', 'aabac', 'abcacb', 'ccbcc', 'bbcbca', 'baccac', 'baaba']
Train Epoch 0, Loss 0.5434045195579529
Train Epoch 1, Loss 0.4403953552246094
Train Epoch 2, Loss 0.41049301624298096
Accuracy at epoch 80: 0.8046875
['abbaca', 'aaccca', 'bbbacabc', 'bbcabba', 'bbcac', 'bbcaaab', 'abcbb', 'cabbab', 'cccccba', 'baba', 'cbcab', 'acaacba', 'ababcaba', 'aaccb', 'bcbbaaac', 'bbca']
Train Epoch 0, Loss 0.4458329379558563
Train Epoch 1, Loss 0.3740556538105011
Train Epoch 2, Loss 0.319107323884964
Accuracy at epoch 81: 0.6875
['bcccb', 'aaaabcb', 'bbbcb', 'aaba', 'baaaac', 'aacaaca', 'abcaac', 'baaab', 'caccabcc', 'baac', 'baba', 'aaab', 'cabaaccb', 'ababa', 'baabbba', 'abbbcaab']
Train Epoch 0, Loss 0.4874497056007385
Train Epoch 1, Loss 0.35740965604782104
Train Epoch 2, Loss 0.27001065015792847
Accuracy at epoch 82: 0.837890625
['bccbba', 'aaca', 'baaac', 'abba', 'bccbcb', 'aaccccbb', 'acabc', 'abbbccb', 'cbbabbc', 'cbacbcba', 'bbca', 'cbcaaa', 'abba', 'baaac', 'abbcbca', 'abac']
Train Epoch 0, Loss 0.4677940309047699
Train Epoch 1, Loss 0.3010856509208679
Train Epoch 2, Loss 0.2096785455942154
Accuracy at epoch 83: 0.857421875
['abaaba', 'acacab', 'cbacc', 'cbcaaba', 'acaca', 'baccaab', 'bcab', 'caccc', 'bccbc', 'aaabbcc', 'acac', 'babba', 'abaa', 'abaacaac', 'baacaaba', 'bbaccbbc']
Train Epoch 0, Loss 0.2543264329433441
Train Epoch 1, Loss 0.16502615809440613
Train Epoch 2, Loss 0.13626524806022644
Accuracy at epoch 84: 0.69140625
['abbcac', 'aaab', 'cabccba', 'cabbb', 'baabaacb', 'abccbbcc', 'baba', 'aabbba', 'babbca', 'bcbc', 'abac', 'abbbcaaa', 'ccbac', 'abcabbcb', 'baccacba', 'abaaaba']
Train Epoch 0, Loss 0.6842364072799683
Train Epoch 1, Loss 0.5910521149635315
Train Epoch 2, Loss 0.5245013236999512
Accuracy at epoch 85: 0.77734375
['aabca', 'abaccac', 'aaabbcac', 'bbcbc', 'cbbbbcaa', 'aaccabc', 'accccc', 'bccbbccc', 'aababcb', 'bacc', 'babbccc', 'aabcacba', 'ccbcb', 'cccbc', 'ababa', 'bbbaaca']
Train Epoch 0, Loss 0.4427136182785034
Train Epoch 1, Loss 0.40518054366111755
Train Epoch 2, Loss 0.3718070685863495
Accuracy at epoch 86: 0.84765625
['cccccbcc', 'aaabbcc', 'bcbacb', 'caacbcba', 'acba', 'cacbba', 'cabc', 'abaccac', 'caaabbcb', 'bbbbbca', 'babbaba', 'acacbaa', 'bcacccaa', 'abcac', 'ccbb', 'bbabbaab']
Train Epoch 0, Loss 0.17396335303783417
Train Epoch 1, Loss 0.15698999166488647
Train Epoch 2, Loss 0.1432265192270279
Accuracy at epoch 87: 0.853515625
['aabb', 'cbcc', 'babacaa', 'bbcaa', 'acca', 'aaaccb', 'bcbba', 'ababbaba', 'babc', 'abbba', 'baacbbba', 'abcaaba', 'ababbcac', 'abaaa', 'baaaba', 'cabbcaac']
Train Epoch 0, Loss 0.4738902747631073
Train Epoch 1, Loss 0.3411695063114166
Train Epoch 2, Loss 0.3934042751789093
Accuracy at epoch 88: 0.673828125
['abcbbaca', 'abaabbb', 'abccccba', 'abccac', 'baaaaba', 'acbc', 'abbccbac', 'cbacca', 'baacb', 'abac', 'abbac', 'ccca', 'bbacba', 'acabcb', 'accb', 'abccca']
Train Epoch 0, Loss 0.8081648349761963
Train Epoch 1, Loss 0.6122251152992249
Train Epoch 2, Loss 0.5154627561569214
Accuracy at epoch 89: 0.884765625
['abccccba', 'ccacbaa', 'babbac', 'baac', 'bacc', 'cbcbab', 'bccbab', 'abbbbba', 'cccabc', 'abaaba', 'cbacacc', 'baccbbac', 'cbcbaac', 'baccac', 'abcacbaa', 'cccba']
Train Epoch 0, Loss 0.43471741676330566
Train Epoch 1, Loss 0.34488967061042786
Train Epoch 2, Loss 0.3025307059288025
Accuracy at epoch 90: 0.818359375
['caac', 'baba', 'accac', 'aacbabc', 'cbcbba', 'accc', 'bacaccac', 'abbbac', 'caccbcba', 'bccba', 'cabaa', 'abba', 'baccba', 'bbcabac', 'bacbaba', 'baaaaccb']
Train Epoch 0, Loss 0.723676323890686
Train Epoch 1, Loss 0.6297972202301025
Train Epoch 2, Loss 0.5696434378623962
Accuracy at epoch 91: 0.87890625
['baabbc', 'bbabba', 'babab', 'babab', 'aaab', 'aaacb', 'cbab', 'cccbbbcb', 'bcbaaaca', 'aaac', 'babcab', 'aaca', 'abacaba', 'acbabbaa', 'bcbcabbb', 'cabcaac']
Train Epoch 0, Loss 0.4232338070869446
Train Epoch 1, Loss 0.32422348856925964
Train Epoch 2, Loss 0.29769769310951233
Accuracy at epoch 92: 0.87109375
['ccbabba', 'cacb', 'bbbaabab', 'abaaaaac', 'baabbcc', 'babbcaba', 'bcab', 'caacbac', 'baccac', 'aaacccb', 'ababba', 'aacaabca', 'acaa', 'ababa', 'bccacacc', 'baacccac']
Train Epoch 0, Loss 0.2595370411872864
Train Epoch 1, Loss 0.22072646021842957
Train Epoch 2, Loss 0.19644588232040405
Accuracy at epoch 93: 0.8671875
['babaca', 'bccab', 'aabbacb', 'baba', 'baaba', 'ccbaccb', 'abacabbb', 'cabbaca', 'acbaaabc', 'aabc', 'bacaacc', 'cbacba', 'abaa', 'ababccc', 'aaca', 'babcb']
Train Epoch 0, Loss 0.3956618010997772
Train Epoch 1, Loss 0.3521821200847626
Train Epoch 2, Loss 0.3225371837615967
Accuracy at epoch 94: 0.853515625
['baabbcba', 'abcaabb', 'acccba', 'ccbbcca', 'ccaaaac', 'bbcccbca', 'abbb', 'abbbaaba', 'ababa', 'abaac', 'bacaac', 'baba', 'abbaaaca', 'abccba', 'baba', 'bccab']
Train Epoch 0, Loss 0.16920961439609528
Train Epoch 1, Loss 0.12514843046665192
Train Epoch 2, Loss 0.10972476750612259
Accuracy at epoch 95: 0.880859375
['bccccaa', 'cbcb', 'acaa', 'abacaaac', 'cbacaac', 'abcac', 'abcba', 'acbbc', 'cbabac', 'bacba', 'bcbaabc', 'aacbcb', 'bccbcb', 'abcaac', 'ccbc', 'bccaa']
Train Epoch 0, Loss 0.21516717970371246
Train Epoch 1, Loss 0.19208049774169922
Train Epoch 2, Loss 0.1598014086484909
Accuracy at epoch 96: 0.82421875
['abaaca', 'abbaacb', 'abacac', 'ccbccbb', 'abcaaac', 'bacbabb', 'ccaabc', 'bccbbcaa', 'baaba', 'baccc', 'bccb', 'accbac', 'aabb', 'cacaaac', 'ccbb', 'abcc']
Train Epoch 0, Loss 0.09571234881877899
Train Epoch 1, Loss 0.06823993474245071
Train Epoch 2, Loss 0.06613986194133759
Accuracy at epoch 97: 0.822265625
['baac', 'bcabaab', 'baccbbac', 'cababba', 'baacba', 'acbbcbb', 'abcacaac', 'cbaabccc', 'bacbaa', 'abbbacba', 'abacac', 'abbabaa', 'abaacb', 'cccca', 'caaa', 'bbcbbbaa']
Train Epoch 0, Loss 0.5442248582839966
Train Epoch 1, Loss 0.37606027722358704
Train Epoch 2, Loss 0.26426902413368225
Accuracy at epoch 98: 0.85546875
['abcba', 'acac', 'acaacc', 'cccabbaa', 'aabcacca', 'acaacaa', 'aaccac', 'bcbcb', 'cbaccb', 'acaaaacb', 'bbababba', 'caabbab', 'cacb', 'cacccbbc', 'caacbbb', 'aaabaacb']
Train Epoch 0, Loss 0.3608491122722626
Train Epoch 1, Loss 0.25293615460395813
Train Epoch 2, Loss 0.17714925110340118
Accuracy at epoch 99: 0.75390625
['aacabba', 'cabaca', 'acbabbb', 'aaaacbaa', 'abccba', 'bcabbc', 'cbcc', 'abcbbac', 'abcbbcba', 'bbbcaa', 'baacacba', 'aababc', 'bbab', 'ccbbcabb', 'acccab', 'accbb']
Train Epoch 0, Loss 0.7079398036003113
Train Epoch 1, Loss 0.451448917388916
Train Epoch 2, Loss 0.37941911816596985
Accuracy at epoch 100: 0.81640625
['ababba', 'cabbc', 'baabcbab', 'bbcbbb', 'acbb', 'baabbba', 'abba', 'cacbacbc', 'cbbabbb', 'baba', 'abaac', 'bacabbba', 'caabccc', 'ccbab', 'cbbcaa', 'baaba']
Train Epoch 0, Loss 0.3055339455604553
Train Epoch 1, Loss 0.21374273300170898
Train Epoch 2, Loss 0.16324803233146667
Accuracy at epoch 101: 0.884765625
['acccab', 'abbc', 'abcc', 'acbbcc', 'abcabaca', 'aaccaab', 'baaaacac', 'bbabb', 'acbaabc', 'bcabb', 'bbcbcbcb', 'bbabbccc', 'cbbb', 'abccba', 'abaaaaba', 'cacbbcbb']
Train Epoch 0, Loss 0.2849081754684448
Train Epoch 1, Loss 0.22697322070598602
Train Epoch 2, Loss 0.18413569033145905
Accuracy at epoch 102: 0.775390625
['bccca', 'bccabb', 'bccc', 'bccaaa', 'bacaac', 'cccaabbc', 'bcbb', 'ccbba', 'acaba', 'cabacacc', 'baba', 'babbaaac', 'bccc', 'bacccb', 'ccccbaba', 'abcabba']
Train Epoch 0, Loss 0.31225842237472534
Train Epoch 1, Loss 0.23077858984470367
Train Epoch 2, Loss 0.18462203443050385
Accuracy at epoch 103: 0.7578125
['abca', 'cacb', 'abcacaca', 'acaaaac', 'acaaa', 'aacba', 'bbbabacc', 'accbbb', 'cacabcaa', 'aaccbb', 'cabbbab', 'acaa', 'baacaccc', 'aaac', 'ccbabbb', 'bbcbcbc']
Train Epoch 0, Loss 0.3023534417152405
Train Epoch 1, Loss 0.12056966871023178
Train Epoch 2, Loss 0.05606485903263092
Accuracy at epoch 104: 0.5
['cccc', 'acaacbbb', 'abcabbb', 'abaccac', 'bacb', 'bbacb', 'bbcaa', 'acbaabab', 'cabbbcc', 'cbcccaca', 'cccc', 'cbbcbac', 'baaaaac', 'baccccab', 'aaaab', 'bbbabba']
Train Epoch 0, Loss 0.9550908207893372
Train Epoch 1, Loss 0.5045936703681946
Train Epoch 2, Loss 0.20996232330799103
Accuracy at epoch 105: 0.787109375
['cbccc', 'bccbbbca', 'ccbac', 'bcabcbca', 'bbabacc', 'abcbca', 'babbaba', 'bacac', 'baaaaba', 'babb', 'bbacacb', 'bbbc', 'baacaaba', 'bacaba', 'baacac', 'aaabbbca']
Train Epoch 0, Loss 0.28158167004585266
Train Epoch 1, Loss 0.1751493215560913
Train Epoch 2, Loss 0.13711237907409668
Accuracy at epoch 106: 0.8046875
['cccbcaab', 'baba', 'caabcb', 'abacac', 'babaa', 'abba', 'abcaccac', 'ccaab', 'aacc', 'bbac', 'ababbcba', 'abcacc', 'bacacba', 'bacab', 'abbbcaac', 'acbb']
Train Epoch 0, Loss 0.141094371676445
Train Epoch 1, Loss 0.10917697101831436
Train Epoch 2, Loss 0.09302676469087601
Accuracy at epoch 107: 0.857421875
['babbc', 'baacbc', 'aaabaabb', 'bcabb', 'baccba', 'babbac', 'cbbaabab', 'abccacbc', 'abac', 'baacba', 'bcbacac', 'cccaabcb', 'bbbbacaa', 'bcaba', 'cbbccbb', 'bbbac']
Train Epoch 0, Loss 0.8616361021995544
Train Epoch 1, Loss 0.6860252618789673
Train Epoch 2, Loss 0.5662744045257568
Accuracy at epoch 108: 0.76171875
['abaccc', 'bcbbacaa', 'bbaac', 'bacab', 'baccc', 'abaabbac', 'abaaba', 'abcccba', 'aaccbb', 'bcacaa', 'cbbbcbab', 'acacabcb', 'bacacba', 'bbaa', 'babc', 'aacbaa']
Train Epoch 0, Loss 0.497842401266098
Train Epoch 1, Loss 0.3904115855693817
Train Epoch 2, Loss 0.3555135428905487
Accuracy at epoch 109: 0.802734375
['baaa', 'abccaa', 'ccaa', 'aaccbb', 'cacacc', 'bcbbca', 'abbc', 'abbbbc', 'abacbccc', 'aacaaa', 'bbcabca', 'abccaa', 'cacbcbc', 'bbbcacb', 'cbaa', 'abcc']
Train Epoch 0, Loss 0.6042301654815674
Train Epoch 1, Loss 0.3153383135795593
Train Epoch 2, Loss 0.17713335156440735
Accuracy at epoch 110: 0.53515625
['abcbb', 'acbbcb', 'bacaacac', 'baccaca', 'cbcbaccb', 'bbbbaab', 'abcaaacb', 'abbcccaa', 'abaa', 'aaccb', 'abaaac', 'aababcac', 'bbbcabab', 'abac', 'acab', 'bacacac']
Train Epoch 0, Loss 1.2295441627502441
Train Epoch 1, Loss 0.8555553555488586
Train Epoch 2, Loss 0.5974050760269165
Accuracy at epoch 111: 0.84375
['abcaaa', 'cabcbac', 'acbbc', 'abcac', 'baaaac', 'aabaab', 'babacaa', 'caca', 'aacbaba', 'ccbabb', 'baac', 'cbbc', 'babca', 'bcbacbcc', 'baac', 'bcbaaaa']
Train Epoch 0, Loss 0.4616883397102356
Train Epoch 1, Loss 0.3287884294986725
Train Epoch 2, Loss 0.2618415057659149
Accuracy at epoch 112: 0.734375
['accc', 'acbaa', 'bcbbac', 'bbaa', 'babbcac', 'abcbbcba', 'acacc', 'aaabb', 'cabcbb', 'abacccac', 'abaccba', 'cababa', 'ccacc', 'aacbaac', 'acbaab', 'baccbccb']
Train Epoch 0, Loss 0.40044865012168884
Train Epoch 1, Loss 0.26863357424736023
Train Epoch 2, Loss 0.19620852172374725
Accuracy at epoch 113: 0.85546875
['baba', 'abba', 'abacbbb', 'cccc', 'cccccba', 'accc', 'cccaa', 'baacbaaa', 'bacac', 'abcba', 'caccaba', 'cccb', 'bacaac', 'cbcca', 'cccbcbcb', 'acaab']
Train Epoch 0, Loss 0.22291840612888336
Train Epoch 1, Loss 0.15091243386268616
Train Epoch 2, Loss 0.1184510886669159
Accuracy at epoch 114: 0.849609375
['caca', 'bacbbaac', 'aaccca', 'aaabb', 'cbac', 'acaabb', 'bbaca', 'baaccbc', 'bbbcabb', 'abbbba', 'acabcac', 'bcbabc', 'cbbc', 'bacba', 'cbcbcbc', 'baaccabb']
Train Epoch 0, Loss 0.5398504734039307
Train Epoch 1, Loss 0.4075641334056854
Train Epoch 2, Loss 0.3261013627052307
Accuracy at epoch 115: 0.8203125
['ccbcbbb', 'abaacba', 'accbaa', 'ccacaaa', 'aacbab', 'bccab', 'cbacb', 'caccc', 'bbcacabb', 'babbac', 'ccabc', 'caabcaca', 'bcbbabab', 'abcaac', 'aaca', 'abcccaac']
Train Epoch 0, Loss 0.43125632405281067
Train Epoch 1, Loss 0.28470733761787415
Train Epoch 2, Loss 0.13756480813026428
Accuracy at epoch 116: 0.875
['caaa', 'ccbcc', 'abaaccac', 'abacca', 'babc', 'aaaca', 'abaaaba', 'bbcabca', 'caab', 'abacbaa', 'abba', 'babbab', 'aacbca', 'bbcbcaba', 'ccaa', 'babbaac']
Train Epoch 0, Loss 0.4094645380973816
Train Epoch 1, Loss 0.27906128764152527
Train Epoch 2, Loss 0.22594138979911804
Accuracy at epoch 117: 0.845703125
['cabaa', 'abcc', 'bbbccbbb', 'cabb', 'abaabcbc', 'abacbcaa', 'ccbbcaa', 'cccacacc', 'abacb', 'baacba', 'baca', 'babbb', 'abaacc', 'bcabbbaa', 'aabc', 'aaaa']
Train Epoch 0, Loss 0.3224585950374603
Train Epoch 1, Loss 0.2612614333629608
Train Epoch 2, Loss 0.21122099459171295
Accuracy at epoch 118: 0.712890625
['babb', 'bcacb', 'abccac', 'cbbb', 'cbba', 'abaacaaa', 'acaa', 'baaaaac', 'bbbbccb', 'baba', 'abcac', 'baaaacba', 'abbbba', 'acbabbc', 'caabbcb', 'baacbbba']
Train Epoch 0, Loss 0.5750638246536255
Train Epoch 1, Loss 0.39866361021995544
Train Epoch 2, Loss 0.29103630781173706
Accuracy at epoch 119: 0.87109375
['bcccb', 'baaa', 'acbaaaba', 'acccbbbb', 'caaac', 'abccbbba', 'bbabbcb', 'abac', 'aabccc', 'babab', 'abbbbbba', 'baaaaba', 'cbacb', 'ccabb', 'baaac', 'bacaac']
Train Epoch 0, Loss 0.4599199593067169
Train Epoch 1, Loss 0.3019498288631439
Train Epoch 2, Loss 0.2478831261396408
Accuracy at epoch 120: 0.85546875
['accbaa', 'cbacacb', 'abcba', 'cbacccaa', 'abbbba', 'cbbbbaab', 'bcaa', 'cbcaca', 'cccab', 'babcc', 'aaac', 'bbbcbbaa', 'cbbc', 'abbcbc', 'abaaaaba', 'cccc']
Train Epoch 0, Loss 0.33877429366111755
Train Epoch 1, Loss 0.28412914276123047
Train Epoch 2, Loss 0.24843265116214752
Accuracy at epoch 121: 0.849609375
['baccba', 'abbac', 'acbcac', 'cababcc', 'abacc', 'bbccbb', 'abccc', 'aabb', 'ccabba', 'acaa', 'acacaccc', 'aacabab', 'ccabc', 'babba', 'abaabcbc', 'abacccac']
Train Epoch 0, Loss 0.4745352566242218
Train Epoch 1, Loss 0.35005608201026917
Train Epoch 2, Loss 0.30824458599090576
Accuracy at epoch 122: 0.765625
['abac', 'aabacbc', 'abcacbc', 'caccbaa', 'cbcaacaa', 'aacbaa', 'abbbba', 'babccbb', 'bcabba', 'cccbb', 'baaccb', 'bbabab', 'caaabbb', 'babbc', 'bbbc', 'cbbabcbb']
Train Epoch 0, Loss 0.5997186899185181
Train Epoch 1, Loss 0.4945683181285858
Train Epoch 2, Loss 0.41873201727867126
Accuracy at epoch 123: 0.775390625
['cabcab', 'baccaac', 'cccbbc', 'baaac', 'bccb', 'caccaca', 'aacaca', 'ccaacbb', 'baaaabc', 'accabbac', 'abca', 'cbbabb', 'acbc', 'bbcc', 'cababa', 'caaaabb']
Train Epoch 0, Loss 0.3633705973625183
Train Epoch 1, Loss 0.22502368688583374
Train Epoch 2, Loss 0.20309698581695557
Accuracy at epoch 124: 0.828125
['aaac', 'bcaab', 'babbaaac', 'bbbca', 'babcc', 'abba', 'acbbb', 'acaccc', 'aacab', 'ccaaaaac', 'bacaccba', 'baaaaaba', 'abbbcaac', 'cbccbcab', 'caaac', 'acbcbab']
Train Epoch 0, Loss 0.24812377989292145
Train Epoch 1, Loss 0.17056290805339813
Train Epoch 2, Loss 0.1288795918226242
Accuracy at epoch 125: 0.83203125
['aacaab', 'bcaaacc', 'baaacba', 'abbbac', 'baabbaac', 'ccbccccb', 'acbca', 'aacbac', 'ccacc', 'cbcbaacb', 'bcaaa', 'accaaabc', 'bbbaa', 'acccca', 'baacbab', 'cbbaacac']
Train Epoch 0, Loss 0.2973290681838989
Train Epoch 1, Loss 0.18652069568634033
Train Epoch 2, Loss 0.12793168425559998
Accuracy at epoch 126: 0.673828125
['caaccc', 'cbcab', 'abac', 'cccc', 'cbcaacbc', 'abcaba', 'bacbc', 'aaaacbcb', 'abca', 'bcaaac', 'accca', 'cacbbcc', 'aaba', 'ababacbb', 'babbaac', 'bbcccbc']
Train Epoch 0, Loss 0.4615454077720642
Train Epoch 1, Loss 0.24522067606449127
Train Epoch 2, Loss 0.20196960866451263
Accuracy at epoch 127: 0.904296875
['bcccb', 'aabaabc', 'aabccb', 'bcbbbb', 'abacaba', 'cccb', 'cbcbaaba', 'caacbb', 'abacc', 'cbbcbc', 'bbbacbcc', 'ccaab', 'ccbaaa', 'ccaa', 'accac', 'aaacaba']
Train Epoch 0, Loss 0.35005906224250793
Train Epoch 1, Loss 0.2679530680179596
Train Epoch 2, Loss 0.2381681501865387
Accuracy at epoch 128: 0.67578125
['cbcccac', 'abbb', 'abac', 'bccbbb', 'acaaacac', 'aaccab', 'aaca', 'baac', 'abac', 'aabb', 'abba', 'baaaba', 'abaaac', 'bccbaaba', 'ccbcc', 'bbac']
Train Epoch 0, Loss 0.39660409092903137
Train Epoch 1, Loss 0.22708065807819366
Train Epoch 2, Loss 0.20309193432331085
Accuracy at epoch 129: 0.828125
['aacaca', 'cccabca', 'bcacc', 'ccbcbb', 'abbbcc', 'abac', 'abaccba', 'babc', 'abcba', 'acaaba', 'cacbba', 'bbaa', 'abaaacba', 'abacaaba', 'cbbbbbc', 'bcaacc']
Train Epoch 0, Loss 0.25713783502578735
Train Epoch 1, Loss 0.1880594938993454
Train Epoch 2, Loss 0.14114069938659668
Accuracy at epoch 130: 0.779296875
['bbaa', 'baaac', 'baaccba', 'abba', 'aabcbba', 'baac', 'acaac', 'cbab', 'baccbabc', 'bbccbaac', 'bbcabaab', 'accac', 'bacaccba', 'bbbb', 'cbabbbca', 'cbbbcc']
Train Epoch 0, Loss 0.5205581784248352
Train Epoch 1, Loss 0.3754250705242157
Train Epoch 2, Loss 0.31377193331718445
Accuracy at epoch 131: 0.865234375
['aabc', 'caba', 'bcbabb', 'babc', 'baababa', 'babcba', 'baacccb', 'cccbccc', 'abccba', 'ccaccbba', 'bccaaca', 'bcaccbbc', 'cbbc', 'cacca', 'bcbcca', 'ccbcbc']
Train Epoch 0, Loss 0.48233678936958313
Train Epoch 1, Loss 0.3700367510318756
Train Epoch 2, Loss 0.27180320024490356
Accuracy at epoch 132: 0.818359375
['cccaabca', 'bbacbab', 'ccac', 'bcacbbaa', 'ccca', 'baacaac', 'aaabbca', 'bbbab', 'bbba', 'acccc', 'baba', 'baac', 'baccccac', 'aabcaaa', 'cacacaca', 'abbbbcbc']
Train Epoch 0, Loss 0.672498345375061
Train Epoch 1, Loss 0.4269341230392456
Train Epoch 2, Loss 0.3432430624961853
Accuracy at epoch 133: 0.87109375
['bcccab', 'ccbbbcca', 'acbac', 'abcbbba', 'baaccac', 'ccaaab', 'ccbbca', 'cbcb', 'babbbbac', 'baacaba', 'bbaabaac', 'cacbba', 'bcab', 'cbabbbc', 'aacb', 'abccba']
Train Epoch 0, Loss 0.21740390360355377
Train Epoch 1, Loss 0.18332655727863312
Train Epoch 2, Loss 0.16061262786388397
Accuracy at epoch 134: 0.90625
['abaacac', 'ababbcba', 'abbcbc', 'acbbbbcc', 'bacacbba', 'baba', 'ccccb', 'cbca', 'abba', 'cbaacab', 'caacacc', 'baabbac', 'ccbbcac', 'bbbcaac', 'baaacac', 'cbbca']
Train Epoch 0, Loss 0.3771027624607086
Train Epoch 1, Loss 0.2740165889263153
Train Epoch 2, Loss 0.2683165669441223
Accuracy at epoch 135: 0.787109375
['aabcbc', 'bbabbab', 'baaaa', 'baccaac', 'caabaaab', 'bcabba', 'bacc', 'cacb', 'abbcbaab', 'abbbccba', 'cbcbaaab', 'baaabcb', 'baacbccb', 'aacabba', 'accaa', 'ccbba']
Train Epoch 0, Loss 0.928207516670227
Train Epoch 1, Loss 0.7064476013183594
Train Epoch 2, Loss 0.5042202472686768
Accuracy at epoch 136: 0.861328125
['bcbbbb', 'bcab', 'abccaac', 'acccb', 'aabb', 'acabaaa', 'abacaa', 'abcbbba', 'abac', 'cccaaccb', 'bbaacbac', 'cbccc', 'aaccb', 'caca', 'abba', 'bbbcab']
Train Epoch 0, Loss 0.35709553956985474
Train Epoch 1, Loss 0.26061639189720154
Train Epoch 2, Loss 0.21658718585968018
Accuracy at epoch 137: 0.857421875
['baaac', 'bbbcbcaa', 'abbb', 'ccbca', 'acbaa', 'bbaba', 'abbcabc', 'cabbab', 'ccbcc', 'abcabbba', 'babbc', 'cbabbc', 'baccac', 'baacbacc', 'aaca', 'baacb']
Train Epoch 0, Loss 0.46487751603126526
Train Epoch 1, Loss 0.39858171343803406
Train Epoch 2, Loss 0.358885794878006
Accuracy at epoch 138: 0.8359375
['aabbaca', 'cbbcb', 'cabaac', 'abbbcabb', 'acacacbb', 'bcaaba', 'bbbbaa', 'baac', 'acbc', 'abaccaa', 'bacbbba', 'aacbbc', 'abcbcc', 'acbcb', 'abbc', 'cbcbbc']
Train Epoch 0, Loss 0.407026082277298
Train Epoch 1, Loss 0.3267936408519745
Train Epoch 2, Loss 0.2623080909252167
Accuracy at epoch 139: 0.810546875
['abbcaaaa', 'bcacab', 'cbcc', 'bacac', 'baac', 'aababa', 'cbabca', 'ccbacc', 'ccaacbcc', 'bacbbcac', 'abcacba', 'bbaa', 'abcabbba', 'bacbcbb', 'baba', 'abcac']
Train Epoch 0, Loss 0.3309381306171417
Train Epoch 1, Loss 0.27623334527015686
Train Epoch 2, Loss 0.2376597374677658
Accuracy at epoch 140: 0.849609375
['caacbbc', 'bcbbcabc', 'ccacca', 'ccaaaacb', 'abbcc', 'cacc', 'cabbbbbb', 'bcacaba', 'acacbaba', 'bbca', 'acaa', 'bbcab', 'cacbaab', 'aabaaabc', 'caaaabb', 'babbba']
Train Epoch 0, Loss 0.6233927607536316
Train Epoch 1, Loss 0.35944101214408875
Train Epoch 2, Loss 0.28871384263038635
Accuracy at epoch 141: 0.87109375
['bcac', 'abcccaac', 'ccacaba', 'bbcabccc', 'bcbcbbc', 'caaabcb', 'cbaaaaa', 'cbababc', 'abcac', 'cabaccbb', 'abcacaba', 'bcacb', 'cacbb', 'baaba', 'babb', 'bbbcbaba']
Train Epoch 0, Loss 0.28455790877342224
Train Epoch 1, Loss 0.19351127743721008
Train Epoch 2, Loss 0.14488214254379272
Accuracy at epoch 142: 0.859375
['bccab', 'baca', 'bbcab', 'caaabb', 'abac', 'abcaaba', 'abab', 'aaaabacb', 'baabaacc', 'cabac', 'abcaaac', 'cacbbbba', 'bbbccc', 'babab', 'babbaac', 'acacba']
Train Epoch 0, Loss 0.13763314485549927
Train Epoch 1, Loss 0.08743907511234283
Train Epoch 2, Loss 0.06936376541852951
Accuracy at epoch 143: 0.82421875
['baccac', 'cbbbcbc', 'bacaaba', 'bcaabcbc', 'acbbac', 'ccaab', 'abcb', 'cccc', 'ababa', 'acabb', 'aacbbc', 'babb', 'abcba', 'abbaccca', 'abbaabb', 'cbba']
Train Epoch 0, Loss 0.8397180438041687
Train Epoch 1, Loss 0.4519804120063782
Train Epoch 2, Loss 0.3607127070426941
Accuracy at epoch 144: 0.89453125
['bccca', 'cbbba', 'baacba', 'bbbba', 'aabbbbac', 'cbbccaa', 'babbccac', 'cacaa', 'caacaccc', 'acacbb', 'ababbac', 'babbb', 'bacbbcac', 'aabcacac', 'baaacbb', 'aaab']
Train Epoch 0, Loss 0.44389691948890686
Train Epoch 1, Loss 0.3428169786930084
Train Epoch 2, Loss 0.28396815061569214
Accuracy at epoch 145: 0.91015625
['cbccbbb', 'acaaacc', 'abcaaaac', 'ccbac', 'cbac', 'abccac', 'bcbac', 'cbbbccaa', 'bacacba', 'cccca', 'baacaca', 'abaacc', 'ccaabac', 'abba', 'aaaa', 'ccbcacbc']
Train Epoch 0, Loss 0.18649491667747498
Train Epoch 1, Loss 0.1349862515926361
Train Epoch 2, Loss 0.11964920163154602
Accuracy at epoch 146: 0.912109375
['aacca', 'cacbabbb', 'bacabb', 'cacb', 'acaa', 'aaaaa', 'bbaaacab', 'bacaa', 'bbbcbcb', 'abaaccbb', 'babcbcab', 'abaccba', 'bcaaccba', 'acaacbca', 'cbbccaca', 'acbacbc']
Train Epoch 0, Loss 0.34895649552345276
Train Epoch 1, Loss 0.18330511450767517
Train Epoch 2, Loss 0.12029875069856644
Accuracy at epoch 147: 0.810546875
['babbacac', 'bbacaac', 'cbacc', 'bccbaa', 'acbc', 'aaabcc', 'bacaaac', 'abcaac', 'caaabcbc', 'abaa', 'babbaba', 'cccccabb', 'babbc', 'caaabaac', 'babaa', 'ccbaab']
Train Epoch 0, Loss 0.3169848620891571
Train Epoch 1, Loss 0.3014673888683319
Train Epoch 2, Loss 0.27762559056282043
Accuracy at epoch 148: 0.86328125
['abbbacba', 'abaaba', 'ccacc', 'aaba', 'bcbac', 'bcca', 'cacab', 'caccb', 'abaaacac', 'abccbcc', 'bacbab', 'bcbaccbc', 'abbb', 'abbc', 'cabcacbc', 'baba']
Train Epoch 0, Loss 0.2283966839313507
Train Epoch 1, Loss 0.17524582147598267
Train Epoch 2, Loss 0.141905277967453
Accuracy at epoch 149: 0.736328125
['abccccba', 'aacaacc', 'bcbac', 'babbaac', 'acacba', 'abcbcb', 'cabc', 'abba', 'cacb', 'cccac', 'cbbbbbba', 'cbcaacbb', 'ccbacbc', 'bbbcc', 'cbcbcc', 'babbac']
Train Epoch 0, Loss 0.7062721848487854
Train Epoch 1, Loss 0.4765128493309021
Train Epoch 2, Loss 0.3167840540409088
Accuracy at epoch 150: 0.908203125
['abcacac', 'bbcaabac', 'bbcaacaa', 'abaac', 'bcbbabab', 'baccac', 'abcb', 'acacb', 'ccbca', 'babbbbba', 'abab', 'cbbbacaa', 'ccbcaaa', 'bbaabbba', 'aaaa', 'cabcca']
Train Epoch 0, Loss 0.4825022220611572
Train Epoch 1, Loss 0.34384143352508545
Train Epoch 2, Loss 0.24427272379398346
Accuracy at epoch 151: 0.76953125
['abbbccc', 'bacac', 'bcccbcbc', 'abbb', 'bbabca', 'bacbbcc', 'abccba', 'cbacca', 'abcb', 'bbaa', 'abbbb', 'bbaaaccc', 'ccbaaa', 'cbabbba', 'bbcacb', 'abbacc']
Train Epoch 0, Loss 0.39284276962280273
Train Epoch 1, Loss 0.19619226455688477
Train Epoch 2, Loss 0.12418211996555328
Accuracy at epoch 152: 0.888671875
['cbac', 'abccbba', 'acba', 'bbaabc', 'babc', 'abac', 'abcccaba', 'cbbb', 'baabbcb', 'bbbcccbb', 'abcabbcb', 'ababcccb', 'acacc', 'caacc', 'bbaccb', 'baba']
Train Epoch 0, Loss 0.43013036251068115
Train Epoch 1, Loss 0.3408794105052948
Train Epoch 2, Loss 0.31604865193367004
Accuracy at epoch 153: 0.8828125
['aabb', 'acacacaa', 'aacabaa', 'abcccac', 'caab', 'bbabcc', 'cccac', 'ccbcbacc', 'abcca', 'acbbcc', 'abccacba', 'acbb', 'bacaac', 'cabbabb', 'caba', 'bacaba']
Train Epoch 0, Loss 0.25037336349487305
Train Epoch 1, Loss 0.1687028408050537
Train Epoch 2, Loss 0.1327405869960785
Accuracy at epoch 154: 0.90234375
['acbccc', 'cbbabcb', 'babbacb', 'abacaca', 'acacccc', 'abba', 'ccbccbac', 'bbca', 'acaaacab', 'abcac', 'acabb', 'abac', 'cacabcbb', 'bbacbcc', 'caacc', 'aaccb']
Train Epoch 0, Loss 0.06953968107700348
Train Epoch 1, Loss 0.043483536690473557
Train Epoch 2, Loss 0.030151546001434326
Accuracy at epoch 155: 0.87109375
['ccbaaca', 'abacac', 'cccccca', 'bcbcc', 'baaacaac', 'aaca', 'ccca', 'acab', 'ccaab', 'bcabaa', 'aabacb', 'aaba', 'cbcacc', 'cccbcc', 'ccbcbca', 'bbabb']
Train Epoch 0, Loss 0.14490965008735657
Train Epoch 1, Loss 0.09506703168153763
Train Epoch 2, Loss 0.06266101449728012
Accuracy at epoch 156: 0.833984375
['cbbbcaaa', 'baabbbcc', 'bbbc', 'bacba', 'cbcbaba', 'bccaabaa', 'cbaca', 'bbaaccb', 'bacba', 'bacaaac', 'baaba', 'ccbaba', 'cbca', 'ccccaac', 'cbaaca', 'bbccbcbc']
Train Epoch 0, Loss 0.4999553859233856
Train Epoch 1, Loss 0.21883806586265564
Train Epoch 2, Loss 0.1761467158794403
Accuracy at epoch 157: 0.86328125
['aaaacbc', 'ccabb', 'abacac', 'cccaccb', 'abacc', 'bbaa', 'ccabca', 'cabb', 'baaca', 'aaccbaba', 'acbab', 'cabcacb', 'cbcbcbcc', 'abbaaaa', 'bacbbcac', 'aaab']
Train Epoch 0, Loss 0.32039034366607666
Train Epoch 1, Loss 0.221191868185997
Train Epoch 2, Loss 0.25807294249534607
Accuracy at epoch 158: 0.796875
['acbb', 'aabc', 'bcbca', 'cbbaca', 'baacaac', 'ccbaacb', 'abcbab', 'cbaacbc', 'bbaacaaa', 'bbbab', 'cccabac', 'baaba', 'aacac', 'cbacabb', 'babbaaba', 'babba']
Train Epoch 0, Loss 0.46909570693969727
Train Epoch 1, Loss 0.3828360438346863
Train Epoch 2, Loss 0.3071143627166748
Accuracy at epoch 159: 0.72265625
['cbac', 'abba', 'bbbb', 'acbcbcc', 'abbcaab', 'abbbcaac', 'cbaabca', 'baabc', 'bcbabccb', 'acaa', 'bababa', 'bacc', 'abcbbcba', 'aaacb', 'cbcccbaa', 'acacba']
Train Epoch 0, Loss 0.3110467791557312
Train Epoch 1, Loss 0.23149074614048004
Train Epoch 2, Loss 0.21258048713207245
Accuracy at epoch 160: 0.830078125
['abac', 'abbbcac', 'bcabc', 'bccc', 'acacba', 'acaaac', 'abaaba', 'aabcb', 'abacbbba', 'baacba', 'cbcc', 'cababc', 'cbbcaa', 'baccaac', 'ababbcba', 'acbcb']
Train Epoch 0, Loss 0.20990893244743347
Train Epoch 1, Loss 0.13312040269374847
Train Epoch 2, Loss 0.08903644233942032
Accuracy at epoch 161: 0.888671875
['abaca', 'accbba', 'cacccbc', 'bbacacbb', 'cbbcacb', 'abac', 'caacbcac', 'bcbacac', 'aaccacac', 'abcb', 'bcca', 'babcaab', 'aaacba', 'abcaaaac', 'bccbccb', 'aaca']
Train Epoch 0, Loss 0.1732211858034134
Train Epoch 1, Loss 0.1134406179189682
Train Epoch 2, Loss 0.07816363871097565
Accuracy at epoch 162: 0.73828125
['aaba', 'aaaacaaa', 'cbba', 'bacbbbc', 'bacaba', 'bcacca', 'abcba', 'cbbcb', 'cacaac', 'bbcacc', 'cacccccb', 'ccaab', 'cbcbcacb', 'cacbb', 'abba', 'bacabcc']
Train Epoch 0, Loss 0.7341373562812805
Train Epoch 1, Loss 0.4093669354915619
Train Epoch 2, Loss 0.3625848591327667
Accuracy at epoch 163: 0.880859375
['bbbcbbcb', 'cccab', 'aaac', 'bcccc', 'bbcbcbaa', 'bccabacb', 'abccca', 'abbbca', 'babbcaac', 'abcaac', 'cacaabbc', 'baacccac', 'ababa', 'cbbcbbb', 'ccbbabba', 'cababcb']
Train Epoch 0, Loss 0.2631497085094452
Train Epoch 1, Loss 0.17784428596496582
Train Epoch 2, Loss 0.13973265886306763
Accuracy at epoch 164: 0.830078125
['cbbcbc', 'bcbacaa', 'ccabbc', 'aabbbb', 'cbaacb', 'baacccac', 'bbcbcc', 'accabab', 'abcccbc', 'abcaccba', 'bcbac', 'abcc', 'abbc', 'cbbcb', 'bacac', 'caac']
Train Epoch 0, Loss 0.3584476113319397
Train Epoch 1, Loss 0.17977364361286163
Train Epoch 2, Loss 0.23922771215438843
Accuracy at epoch 165: 0.91015625
['cabc', 'bbacbcbb', 'aaccaccc', 'abbba', 'cccbacac', 'abbcac', 'ccaaccc', 'cccacbb', 'aabbcb', 'ccbb', 'aaabbac', 'abbbba', 'babbcba', 'cbacacab', 'babcbacc', 'aaccacb']
Train Epoch 0, Loss 0.28972700238227844
Train Epoch 1, Loss 0.2403322011232376
Train Epoch 2, Loss 0.21616072952747345
Accuracy at epoch 166: 0.81640625
['cccbaaa', 'baaac', 'acbbcaab', 'bacac', 'baac', 'accbacca', 'abac', 'ccacbca', 'abac', 'bbbaac', 'abacba', 'bbaacbbc', 'aaca', 'abbcaabb', 'abcbccbb', 'ababa']
Train Epoch 0, Loss 0.47403159737586975
Train Epoch 1, Loss 0.34469208121299744
Train Epoch 2, Loss 0.27498072385787964
Accuracy at epoch 167: 0.9140625
['baaabb', 'bbccac', 'bcbaa', 'abbbbac', 'caba', 'acaabc', 'abcba', 'bcabbbcb', 'accab', 'acbcb', 'bbccccb', 'bbaa', 'bacab', 'aacca', 'bacca', 'bbaccb']
Train Epoch 0, Loss 0.24164319038391113
Train Epoch 1, Loss 0.10997691005468369
Train Epoch 2, Loss 0.09198661893606186
Accuracy at epoch 168: 0.744140625
['ccbcbb', 'babcacbc', 'abccabaa', 'abca', 'cccacabb', 'caabbbcc', 'cabaaa', 'acaacaa', 'baaccba', 'babacab', 'baaba', 'bbbbab', 'cbbb', 'bcbccccb', 'babbcba', 'abcbbaac']
Train Epoch 0, Loss 0.17153939604759216
Train Epoch 1, Loss 0.12715664505958557
Train Epoch 2, Loss 0.09044374525547028
Accuracy at epoch 169: 0.802734375
['cbabaa', 'aacccb', 'bccaccc', 'ccccbab', 'cabab', 'babbba', 'acbbbb', 'ccabcca', 'ccaa', 'accca', 'abba', 'ccabb', 'aabbb', 'cbaacc', 'aaaca', 'bcba']
Train Epoch 0, Loss 0.17493925988674164
Train Epoch 1, Loss 0.059699565172195435
Train Epoch 2, Loss 0.03709879890084267
Accuracy at epoch 170: 0.87890625
['abccaaba', 'acbaabc', 'aacbcbab', 'acbba', 'baaba', 'babbcaac', 'ccbcaaa', 'bacacbb', 'abaaba', 'bbabc', 'abbaa', 'abbcbab', 'baaba', 'cbacac', 'abbcbcac', 'aabbc']
Train Epoch 0, Loss 0.6239374279975891
Train Epoch 1, Loss 0.6103863716125488
Train Epoch 2, Loss 0.43543049693107605
Accuracy at epoch 171: 0.85546875
['ccabcc', 'abbbabaa', 'abba', 'cbbacac', 'accca', 'acccbabb', 'cbaacbbb', 'acbaabca', 'cbbbac', 'abaaba', 'bccaaa', 'caaa', 'bacaac', 'aaaaccac', 'bcbcc', 'bccbcca']
Train Epoch 0, Loss 0.3165851831436157
Train Epoch 1, Loss 0.20297634601593018
Train Epoch 2, Loss 0.17635244131088257
Accuracy at epoch 172: 0.888671875
['bacaac', 'bcccca', 'cccba', 'cccaccba', 'cbbacbca', 'abcccaac', 'abcacaba', 'baacb', 'bbaa', 'abaac', 'cabaa', 'bbbbacca', 'bbacac', 'accb', 'bcbabaa', 'acacbcac']
Train Epoch 0, Loss 0.3088326156139374
Train Epoch 1, Loss 0.1870412826538086
Train Epoch 2, Loss 0.21301846206188202
Accuracy at epoch 173: 0.90234375
['abac', 'baacabc', 'aaccba', 'cccc', 'abacaba', 'bccbbaaa', 'abaa', 'cacb', 'baccb', 'ccccc', 'cbcabc', 'bccc', 'cacc', 'bccbacc', 'cacaccbb', 'bacba']
Train Epoch 0, Loss 0.4057868421077728
Train Epoch 1, Loss 0.329967200756073
Train Epoch 2, Loss 0.293376624584198
Accuracy at epoch 174: 0.892578125
['abac', 'aabbacb', 'bcac', 'cbabb', 'baac', 'abaacaab', 'abac', 'abac', 'ccbabbac', 'accbabcc', 'abaabbca', 'cbcabc', 'bababcba', 'aabbc', 'bacaacba', 'ccaabc']
Train Epoch 0, Loss 0.31685125827789307
Train Epoch 1, Loss 0.25933128595352173
Train Epoch 2, Loss 0.2171422392129898
Accuracy at epoch 175: 0.888671875
['cccbc', 'ccabaab', 'caab', 'abcbbbc', 'bacbcb', 'bcbbccc', 'abcabac', 'bacacbcb', 'baba', 'cbcb', 'cccb', 'bcbccca', 'cbacabb', 'abccac', 'baacacbc', 'ccbaacba']
Train Epoch 0, Loss 0.21006956696510315
Train Epoch 1, Loss 0.15701702237129211
Train Epoch 2, Loss 0.1292748600244522
Accuracy at epoch 176: 0.87890625
['ccbb', 'ccbbbb', 'bbabcb', 'baacac', 'caaaccaa', 'abbbba', 'ccbb', 'abccaba', 'ccbaaa', 'acaa', 'baaba', 'baacac', 'cbaab', 'bacab', 'baaaccac', 'accbac']
Train Epoch 0, Loss 0.3817403316497803
Train Epoch 1, Loss 0.21816010773181915
Train Epoch 2, Loss 0.1405930519104004
Accuracy at epoch 177: 0.876953125
['abbbba', 'abbbaaac', 'baaac', 'ccac', 'abcbbb', 'caca', 'bacca', 'aabab', 'cccacbb', 'acbbcac', 'ccaccaab', 'babcacba', 'abcbcba', 'cbacbbb', 'bccabaa', 'bbaa']
Train Epoch 0, Loss 0.23488864302635193
Train Epoch 1, Loss 0.14037902653217316
Train Epoch 2, Loss 0.07396433502435684
Accuracy at epoch 178: 0.734375
['abab', 'abcbc', 'baba', 'bacac', 'bccccaab', 'bcbcbb', 'aaca', 'acabbc', 'abcac', 'caaacbc', 'babbcc', 'ccaccbc', 'babbcaac', 'baabbaac', 'cbcbba', 'acbbac']
Train Epoch 0, Loss 0.6029309034347534
Train Epoch 1, Loss 0.17109934985637665
Train Epoch 2, Loss 0.09400566667318344
Accuracy at epoch 179: 0.87890625
['caabba', 'bbaabbb', 'baaba', 'bccabbbb', 'baccbab', 'accacc', 'bacaaaa', 'acaacbab', 'baaaaac', 'cbbbbcba', 'abcca', 'acabab', 'bbbaa', 'acbc', 'bbba', 'aacabcb']
Train Epoch 0, Loss 0.2050076276063919
Train Epoch 1, Loss 0.11832619458436966
Train Epoch 2, Loss 0.07800403982400894
Accuracy at epoch 180: 0.7109375
['bcccc', 'babbb', 'abcba', 'cbabbc', 'bacac', 'acca', 'cbcbc', 'caaa', 'bacacac', 'baaccba', 'baaba', 'bccbb', 'bccabbbc', 'babcbbb', 'cccb', 'bcbabbac']
Train Epoch 0, Loss 0.617634117603302
Train Epoch 1, Loss 0.14301927387714386
Train Epoch 2, Loss 0.07634851336479187
Accuracy at epoch 181: 0.912109375
['bcbaccbb', 'cbca', 'bccaaaab', 'babc', 'aacabcbb', 'abac', 'ccbcaa', 'bacaba', 'aacb', 'ccbacbab', 'bbac', 'bacacba', 'aacc', 'bbabb', 'cccbc', 'acbbb']
Train Epoch 0, Loss 0.26824790239334106
Train Epoch 1, Loss 0.1949249655008316
Train Epoch 2, Loss 0.1770755648612976
Accuracy at epoch 182: 0.90625
['abbab', 'bbcbaa', 'bbbacc', 'acbbbbcb', 'baaaba', 'bcacab', 'bccc', 'accc', 'acaa', 'ccbb', 'accac', 'aaaaaac', 'acabcbcb', 'bcaccbb', 'bcabaa', 'baac']
Train Epoch 0, Loss 0.26287272572517395
Train Epoch 1, Loss 0.1975623518228531
Train Epoch 2, Loss 0.16106918454170227
Accuracy at epoch 183: 0.802734375
['acbbbcb', 'bacba', 'bbacac', 'baac', 'babaaca', 'abaacbc', 'baacba', 'aacaacb', 'ccab', 'bcaaccb', 'cbcc', 'abbbbbb', 'aabcbcb', 'cabb', 'bacabbba', 'bacacac']
Train Epoch 0, Loss 1.0144386291503906
Train Epoch 1, Loss 0.34087687730789185
Train Epoch 2, Loss 0.29377806186676025
Accuracy at epoch 184: 0.904296875
['ccbccccc', 'acaaaabb', 'acca', 'aaabc', 'bbaccc', 'aaacaba', 'baba', 'caabbcca', 'abcacba', 'aabbcbb', 'abcaac', 'baccba', 'bcaa', 'cabcbbc', 'bacaa', 'baccac']
Train Epoch 0, Loss 0.4534637928009033
Train Epoch 1, Loss 0.3613339364528656
Train Epoch 2, Loss 0.29039284586906433
Accuracy at epoch 185: 0.83984375
['cbbc', 'abacaba', 'cbabbc', 'abaaaba', 'abbbccac', 'babcbc', 'aaaa', 'abbb', 'cbcaabc', 'bbbabbcb', 'baaba', 'bbaacc', 'bccbac', 'baba', 'bcbcacc', 'aaaaacac']
Train Epoch 0, Loss 0.3421652317047119
Train Epoch 1, Loss 0.25376275181770325
Train Epoch 2, Loss 0.22792963683605194
Accuracy at epoch 186: 0.91015625
['bacaab', 'cbccaab', 'bcab', 'ccbcc', 'acbaabcb', 'bccabb', 'bcaab', 'bcaabbca', 'aabcaca', 'bbcabb', 'bcaab', 'bacacac', 'caccbab', 'bacaaac', 'bbcac', 'acaca']
Train Epoch 0, Loss 0.1840919703245163
Train Epoch 1, Loss 0.10990915447473526
Train Epoch 2, Loss 0.059171516448259354
Accuracy at epoch 187: 0.900390625
['aaccbab', 'aabaa', 'bbaccc', 'bbbba', 'aabcb', 'cbccccb', 'ccbbcb', 'aaccaaba', 'babac', 'bbabb', 'baba', 'aabba', 'cacbbccc', 'cbcaabbc', 'cbcc', 'accaacb']
Train Epoch 0, Loss 0.2812694013118744
Train Epoch 1, Loss 0.17688201367855072
Train Epoch 2, Loss 0.10984471440315247
Accuracy at epoch 188: 0.798828125
['cbcbc', 'bacaaaba', 'caccb', 'cacaacbc', 'cbaccc', 'acbbca', 'baac', 'babbccba', 'baaac', 'bcbcaa', 'cbbbacbb', 'acab', 'bccb', 'bcabbbb', 'bcaaaa', 'ccbab']
Train Epoch 0, Loss 0.15951964259147644
Train Epoch 1, Loss 0.27496808767318726
Train Epoch 2, Loss 0.06129690632224083
Accuracy at epoch 189: 0.8515625
['abaac', 'accabab', 'abaa', 'bbbcaacb', 'aaabbbcb', 'abaccba', 'abbbaba', 'caab', 'cbcb', 'abcac', 'ccab', 'bbcb', 'accc', 'cabac', 'ccaccaa', 'baaba']
Train Epoch 0, Loss 0.0682179257273674
Train Epoch 1, Loss 0.03623325750231743
Train Epoch 2, Loss 0.024179160594940186
Accuracy at epoch 190: 0.857421875
['caaba', 'aabcb', 'abccbb', 'ccbbaab', 'abccac', 'aabcaaba', 'abba', 'aaabbcb', 'abaaaba', 'bcbccccc', 'baaa', 'cabac', 'accbba', 'abcbb', 'bbaabcbb', 'aacbba']
Train Epoch 0, Loss 0.5733011960983276
Train Epoch 1, Loss 0.42174312472343445
Train Epoch 2, Loss 0.31831061840057373
Accuracy at epoch 191: 0.91015625
['baba', 'aaabbbcb', 'caaabc', 'bbac', 'caac', 'ccca', 'bcaaa', 'aaac', 'baabbcac', 'abaac', 'bcca', 'bbbaa', 'bacaba', 'bbabb', 'aacaaccb', 'cccbcbbb']
Train Epoch 0, Loss 0.244227796792984
Train Epoch 1, Loss 0.19158363342285156
Train Epoch 2, Loss 0.15764258801937103
Accuracy at epoch 192: 0.85546875
['bacaaaac', 'cccc', 'bcbbccba', 'babbcaba', 'bbcba', 'aabacac', 'caabab', 'abacac', 'bcbcbccb', 'cabcc', 'baaabbac', 'cbcabccc', 'bbbaabab', 'acacb', 'cccbca', 'cbcbab']
Train Epoch 0, Loss 0.20994654297828674
Train Epoch 1, Loss 0.13282930850982666
Train Epoch 2, Loss 0.11527209728956223
Accuracy at epoch 193: 0.75
['abac', 'caacabac', 'aacaab', 'abbcb', 'abcccba', 'bacccac', 'baaba', 'bacbba', 'babcb', 'baba', 'acbcba', 'cbbabacb', 'aaaaba', 'bbbcaab', 'ccaaaaa', 'cabcccbc']
Train Epoch 0, Loss 1.0986113548278809
Train Epoch 1, Loss 0.7288809418678284
Train Epoch 2, Loss 0.48606279492378235
Accuracy at epoch 194: 0.90234375
['bcabbcb', 'aabbc', 'bacac', 'bcacba', 'bacacba', 'acaaaccb', 'aacaabc', 'acbcbb', 'ccbacbb', 'bcbba', 'bbaa', 'bbbcbbb', 'acacaa', 'abaac', 'caacbca', 'baabbba']
Train Epoch 0, Loss 0.42291754484176636
Train Epoch 1, Loss 0.3096301257610321
Train Epoch 2, Loss 0.23753823339939117
Accuracy at epoch 195: 0.869140625
['aabc', 'bcbabcbc', 'bbabbb', 'cabbac', 'acac', 'abbac', 'cabcccb', 'aabba', 'cbcbbb', 'acccc', 'baacac', 'bbbaaac', 'babcbacb', 'accabac', 'ccccbca', 'cccbb']
Train Epoch 0, Loss 0.2652831971645355
Train Epoch 1, Loss 0.18869149684906006
Train Epoch 2, Loss 0.13416054844856262
Accuracy at epoch 196: 0.59375
['abaabbba', 'bbbaab', 'babb', 'abacba', 'abcaacac', 'cabccbac', 'babbccba', 'bcbcbacb', 'abcac', 'baba', 'abbbacac', 'aabb', 'abcaac', 'ccbaccab', 'baaba', 'acaabab']
Train Epoch 0, Loss 0.6164263486862183
Train Epoch 1, Loss 0.23199497163295746
Train Epoch 2, Loss 0.11348974704742432
Accuracy at epoch 197: 0.904296875
['acbc', 'aabacbaa', 'cbbb', 'abbc', 'ccbac', 'ababbac', 'bcab', 'cbccbcc', 'cbcbabbc', 'bcaaa', 'abccaaba', 'baacbbc', 'acbb', 'cacc', 'bcbccc', 'bcbb']
Train Epoch 0, Loss 0.20811790227890015
Train Epoch 1, Loss 0.10261761397123337
Train Epoch 2, Loss 0.20817464590072632
Accuracy at epoch 198: 0.84375
['cbacbbb', 'aacaaccb', 'cbab', 'bcacbcca', 'bbcc', 'aacbc', 'caabaacb', 'bbbbbcb', 'baac', 'bcbbacb', 'abcbaba', 'bcabcabb', 'ccccccca', 'caaa', 'babcbbb', 'abcaac']
Train Epoch 0, Loss 0.3689716160297394
Train Epoch 1, Loss 0.2360173463821411
Train Epoch 2, Loss 0.19309605658054352
Accuracy at epoch 199: 0.88671875
['bacabc', 'bbabaa', 'caac', 'bacac', 'aacaacba', 'abbcba', 'cbcaabbc', 'abcb', 'ababba', 'cbbbabbb', 'acabbcc', 'ccbbc', 'bcccab', 'abcccba', 'baac', 'baacccb']
Train Epoch 0, Loss 0.9838203191757202
Train Epoch 1, Loss 0.5737727880477905
Train Epoch 2, Loss 0.3992600739002228
Accuracy at epoch 200: 0.87890625
['caccca', 'cbcc', 'baaaba', 'aaacabaa', 'cbcc', 'abbbaac', 'baaac', 'aacbaa', 'abcbbba', 'bccabcaa', 'bcbacba', 'cabbca', 'bacaaba', 'baabaab', 'abba', 'abbaca']
Train Epoch 0, Loss 0.2767940163612366
Train Epoch 1, Loss 0.13196496665477753
Train Epoch 2, Loss 0.10147625207901001
Accuracy at epoch 201: 0.896484375
['baacacbb', 'accba', 'bcbc', 'accbb', 'bacbbabb', 'ccaccc', 'ccacb', 'acbbabb', 'cabcb', 'cccbbac', 'abac', 'aaacba', 'bbbbaab', 'cbaca', 'bacbb', 'baccba']
Train Epoch 0, Loss 0.5286656022071838
Train Epoch 1, Loss 0.22193942964076996
Train Epoch 2, Loss 0.15189486742019653
Accuracy at epoch 202: 0.876953125
['cbcacab', 'bacacacb', 'babb', 'bcbcba', 'baaac', 'abaaaac', 'acabcb', 'baaac', 'acbca', 'bcaacb', 'acbaaaca', 'ccbc', 'caabaa', 'acab', 'bacabbac', 'acabccb']
Train Epoch 0, Loss 0.08207772672176361
Train Epoch 1, Loss 0.03815270960330963
Train Epoch 2, Loss 0.018932383507490158
Accuracy at epoch 203: 0.875
['bcccbc', 'caba', 'bbaaa', 'cabbcbc', 'abacba', 'bbaa', 'abaaaaba', 'ababa', 'babbcaac', 'cacaba', 'abccaac', 'abbbabac', 'cccb', 'cbac', 'abccb', 'accbcc']
Train Epoch 0, Loss 0.45231199264526367
Train Epoch 1, Loss 0.31616440415382385
Train Epoch 2, Loss 0.21267320215702057
Accuracy at epoch 204: 0.8203125
['bacba', 'ccaacb', 'ccbba', 'babbac', 'abaacba', 'acbab', 'abac', 'aaac', 'abcac', 'aaacac', 'baba', 'abaac', 'abac', 'abaaaaba', 'ccbcbc', 'abacaa']
Train Epoch 0, Loss 0.8768341541290283
Train Epoch 1, Loss 0.6300344467163086
Train Epoch 2, Loss 0.4787903130054474
Accuracy at epoch 205: 0.892578125
['acbb', 'baccca', 'bbcb', 'cccac', 'ccabccbb', 'cccc', 'ababb', 'cbcccabc', 'acac', 'babbb', 'bbbab', 'bbbca', 'abac', 'bccb', 'caccac', 'bbbbcbac']
Train Epoch 0, Loss 0.21172736585140228
Train Epoch 1, Loss 0.1471683382987976
Train Epoch 2, Loss 0.14011678099632263
Accuracy at epoch 206: 0.861328125
['accbbca', 'aabbb', 'baba', 'ababbaba', 'acbab', 'ccbba', 'abba', 'baaaac', 'aaaacc', 'bcaa', 'bacabab', 'bbcaac', 'baaab', 'cbaaabb', 'babbacba', 'cbbacca']
Train Epoch 0, Loss 0.2141484022140503
Train Epoch 1, Loss 0.11667437106370926
Train Epoch 2, Loss 0.0835857093334198
Accuracy at epoch 207: 0.814453125
['abcbbac', 'caacb', 'cccb', 'bbcbcaac', 'bacaba', 'abbabc', 'aabcb', 'cccb', 'baba', 'bcac', 'aacba', 'aabc', 'abccac', 'babb', 'bcccaac', 'bbabbba']
Train Epoch 0, Loss 0.7882234454154968
Train Epoch 1, Loss 0.525335967540741
Train Epoch 2, Loss 0.4753653109073639
Accuracy at epoch 208: 0.888671875
['aaaac', 'baaac', 'cacb', 'abbbaba', 'bcbccccc', 'bacac', 'cacbb', 'bacbbba', 'cbbac', 'aaacaca', 'bacbbaac', 'cbbcbabb', 'cbbcaca', 'cabcaabc', 'abbaacab', 'cacc']
Train Epoch 0, Loss 0.21502090990543365
Train Epoch 1, Loss 0.1643708050251007
Train Epoch 2, Loss 0.14180202782154083
Accuracy at epoch 209: 0.876953125
['babac', 'bcaccb', 'acabca', 'babbccba', 'baba', 'baaac', 'bacac', 'aabbcbb', 'aacb', 'baacaaac', 'bbacac', 'cbcaaac', 'bccc', 'caaaa', 'acccabaa', 'caccc']
Train Epoch 0, Loss 0.291533499956131
Train Epoch 1, Loss 0.22290459275245667
Train Epoch 2, Loss 0.21079272031784058
Accuracy at epoch 210: 0.900390625
['bcba', 'ccbabb', 'baacbc', 'bbab', 'babbcba', 'abaac', 'abbc', 'abac', 'cabc', 'bcbcb', 'bacacba', 'cbbaacc', 'aabacacb', 'bacbb', 'abcacba', 'cbbcb']
Train Epoch 0, Loss 0.3269267678260803
Train Epoch 1, Loss 0.24287521839141846
Train Epoch 2, Loss 0.2085704356431961
Accuracy at epoch 211: 0.8984375
['bbbbaccc', 'cbcaacab', 'ababa', 'accbc', 'caca', 'abbaaa', 'baacabb', 'cabcbaca', 'abcca', 'bccabac', 'abba', 'baccac', 'abccaba', 'ccacb', 'acbba', 'acbcbcab']
Train Epoch 0, Loss 0.18587368726730347
Train Epoch 1, Loss 0.13687847554683685
Train Epoch 2, Loss 0.10709503293037415
Accuracy at epoch 212: 0.923828125
['cbabcab', 'baaacb', 'ccbcbccc', 'bbcbbb', 'bccac', 'aaaacca', 'baacbc', 'bbbaac', 'baba', 'bacaabb', 'abba', 'aaaacaab', 'bcaaca', 'cbccbccc', 'acbb', 'cabc']
Train Epoch 0, Loss 0.18524235486984253
Train Epoch 1, Loss 0.13337033987045288
Train Epoch 2, Loss 0.1034192368388176
Accuracy at epoch 213: 0.857421875
['acaca', 'caac', 'bcacbabc', 'abcb', 'bcca', 'abbc', 'babacc', 'abacbbc', 'babbaba', 'ccaabab', 'bacba', 'bbcbbcbb', 'cbbccc', 'bcccaaaa', 'bacbbac', 'ababbc']
Train Epoch 0, Loss 0.5050517916679382
Train Epoch 1, Loss 0.38782790303230286
Train Epoch 2, Loss 0.34367385506629944
Accuracy at epoch 214: 0.810546875
['cbbccab', 'aacbcaca', 'accabac', 'bcbcbcbb', 'bbbca', 'aacabaab', 'abbbaccc', 'bacaba', 'bacc', 'abac', 'acbaacba', 'babaa', 'ccaaac', 'abacaba', 'abbcc', 'baaba']
Train Epoch 0, Loss 0.24900799989700317
Train Epoch 1, Loss 0.1499844640493393
Train Epoch 2, Loss 0.12920410931110382
Accuracy at epoch 215: 0.876953125
['bbabaaab', 'cabcc', 'abcbacca', 'acbccaac', 'abbabb', 'aababbba', 'caacca', 'abccc', 'bccbcbc', 'acabbac', 'baaba', 'bacbbaac', 'bcacaba', 'abbbccba', 'bbaacb', 'ccbcbb']
Train Epoch 0, Loss 0.35360682010650635
Train Epoch 1, Loss 0.14862768352031708
Train Epoch 2, Loss 0.10248807817697525
Accuracy at epoch 216: 0.8359375
['ccccc', 'cbbba', 'cccaacb', 'abbaab', 'ccbba', 'abccac', 'abaaba', 'bacbbcac', 'bbacb', 'bbaca', 'acabbb', 'bacaba', 'aacaccc', 'baacc', 'abcccac', 'abcccac']
Train Epoch 0, Loss 0.918154239654541
Train Epoch 1, Loss 0.17432545125484467
Train Epoch 2, Loss 0.049874864518642426
Accuracy at epoch 217: 0.84375
['ccbac', 'abccacb', 'bbcbbab', 'baacaba', 'bbbb', 'bbbabb', 'cabbc', 'abbca', 'acbcbb', 'accbbb', 'bbacaaa', 'caacbc', 'aaacb', 'cbcccb', 'ccac', 'bbaabcca']
Train Epoch 0, Loss 0.08540672063827515
Train Epoch 1, Loss 0.060044169425964355
Train Epoch 2, Loss 0.04349188506603241
Accuracy at epoch 218: 0.8515625
['bcbc', 'baabbba', 'cbac', 'bacac', 'bbaac', 'aaabcba', 'bbcccbc', 'bbacba', 'acaba', 'ccaba', 'bcabb', 'cacacac', 'aacac', 'bcbbb', 'baac', 'aaabc']
Train Epoch 0, Loss 0.7402660250663757
Train Epoch 1, Loss 0.5595152378082275
Train Epoch 2, Loss 0.4186273217201233
Accuracy at epoch 219: 0.791015625
['ccabbaac', 'cbac', 'abcba', 'cbccc', 'aaabccb', 'bccbac', 'baccaaba', 'bbbaabab', 'babbac', 'bcaccb', 'bbaac', 'bcacbbbc', 'acabcbcb', 'baabbba', 'cccbba', 'cccac']
Train Epoch 0, Loss 0.6038501262664795
Train Epoch 1, Loss 0.33741095662117004
Train Epoch 2, Loss 0.17507962882518768
Accuracy at epoch 220: 0.8515625
['aaab', 'bbacaaca', 'bcccabcc', 'bcbbaaba', 'aabc', 'cabbcbaa', 'acabcb', 'cccbaa', 'aaac', 'abacba', 'baabacc', 'bbcb', 'abcaaba', 'aabbcba', 'bacbbba', 'bacac']
Train Epoch 0, Loss 0.586739182472229
Train Epoch 1, Loss 0.45549774169921875
Train Epoch 2, Loss 0.37600699067115784
Accuracy at epoch 221: 0.837890625
['bbbcacb', 'abaab', 'aaaacacc', 'accaba', 'abccacc', 'cacbb', 'babbb', 'cacca', 'bbac', 'baccbbac', 'bbaaab', 'ccaba', 'ccbc', 'ccbcbc', 'abab', 'baac']
Train Epoch 0, Loss 0.35328051447868347
Train Epoch 1, Loss 0.1105402484536171
Train Epoch 2, Loss 0.07887353748083115
Accuracy at epoch 222: 0.8984375
['bcccbaa', 'ababa', 'ccaaca', 'abbbbcab', 'bbcbcb', 'baaaa', 'baccaac', 'ababa', 'abac', 'abaccaba', 'bcaacb', 'abcccca', 'acacbccb', 'cabcaa', 'baccaaac', 'abca']
Train Epoch 0, Loss 0.09123388677835464
Train Epoch 1, Loss 0.06561971455812454
Train Epoch 2, Loss 0.04976791888475418
Accuracy at epoch 223: 0.86328125
['bcba', 'ccacacb', 'bababcbb', 'bbbaaab', 'acaababa', 'aabbc', 'bacaaaba', 'aacaa', 'bacabbb', 'ccab', 'abbab', 'babbba', 'bacba', 'caab', 'abac', 'bcbabb']
Train Epoch 0, Loss 0.3316965699195862
Train Epoch 1, Loss 0.28730395436286926
Train Epoch 2, Loss 0.20623832941055298
Accuracy at epoch 224: 0.896484375
['bbbb', 'aacca', 'baaaa', 'abaaba', 'abbbba', 'cbcca', 'aaaaa', 'baba', 'bccbcaaa', 'acbb', 'accbcb', 'abacaaac', 'baacac', 'abcbbba', 'abba', 'cccb']
Train Epoch 0, Loss 0.11513472348451614
Train Epoch 1, Loss 0.07519326359033585
Train Epoch 2, Loss 0.055200811475515366
Accuracy at epoch 225: 0.8515625
['caab', 'acaabc', 'bbbbaba', 'aaba', 'abacccc', 'aacba', 'abccc', 'aaaca', 'cacaaa', 'bccaaac', 'bbaa', 'accbacca', 'acaccabb', 'babbc', 'cabcbccc', 'ccbaccab']
Train Epoch 0, Loss 0.71844482421875
Train Epoch 1, Loss 0.46230584383010864
Train Epoch 2, Loss 0.2779310643672943
Accuracy at epoch 226: 0.57421875
['cbccca', 'acbc', 'abbba', 'baacba', 'bacccaba', 'bccbba', 'ccca', 'caaacb', 'baaccaba', 'abacac', 'acccbc', 'caca', 'bacbaa', 'cccaaaa', 'cbac', 'aaacbc']
Train Epoch 0, Loss 1.1008437871932983
Train Epoch 1, Loss 0.37734097242355347
Train Epoch 2, Loss 0.3402184247970581
Accuracy at epoch 227: 0.751953125
['cccbc', 'cccc', 'baacbcca', 'acaccbbc', 'abbac', 'bccccbb', 'ccbbb', 'bacba', 'cabaacc', 'baac', 'abac', 'bbbcb', 'bcbca', 'baacbcc', 'bacbbaac', 'bbbbcba']
Train Epoch 0, Loss 0.7248305678367615
Train Epoch 1, Loss 0.4489726424217224
Train Epoch 2, Loss 0.34584280848503113
Accuracy at epoch 228: 0.9140625
['baaba', 'abccba', 'bbacbb', 'bccabac', 'abcabbb', 'abccaaba', 'acbaa', 'ababa', 'bacba', 'aaacc', 'aaccb', 'aabbabc', 'bbcbab', 'babb', 'cccaccac', 'ccbbcaa']
Train Epoch 0, Loss 0.24818649888038635
Train Epoch 1, Loss 0.20664794743061066
Train Epoch 2, Loss 0.18165354430675507
Accuracy at epoch 229: 0.8984375
['acaaa', 'ababa', 'cbbaca', 'cacbab', 'baca', 'accc', 'abcbba', 'ccbcc', 'baabbcac', 'bbacaa', 'abbbaba', 'bbbab', 'baaac', 'aabababc', 'abba', 'baaba']
Train Epoch 0, Loss 0.3264091908931732
Train Epoch 1, Loss 0.2874312698841095
Train Epoch 2, Loss 0.25584402680397034
Accuracy at epoch 230: 0.916015625
['bacbca', 'baabb', 'cbcc', 'ccacab', 'baaba', 'abcca', 'cacbbb', 'baaacba', 'ababa', 'baaabb', 'baaabbba', 'cbbcbaaa', 'bcaccbac', 'abaac', 'bccc', 'baaa']
Train Epoch 0, Loss 0.24250663816928864
Train Epoch 1, Loss 0.15221236646175385
Train Epoch 2, Loss 0.1006845086812973
Accuracy at epoch 231: 0.796875
['babaa', 'aabbbcc', 'babc', 'caaabacb', 'abab', 'accabbcc', 'abcaba', 'accbbb', 'abaaba', 'cacbbbcb', 'baaac', 'abbbcba', 'caaabbc', 'ccbac', 'bbaacb', 'bacaac']
Train Epoch 0, Loss 0.2394021451473236
Train Epoch 1, Loss 0.13297797739505768
Train Epoch 2, Loss 0.13913634419441223
Accuracy at epoch 232: 0.927734375
['abacbccc', 'cccababb', 'aacaaac', 'aacaccbc', 'bacba', 'aaba', 'baaac', 'baba', 'bacaac', 'baaaca', 'bbccb', 'bcbbbaa', 'aaaaac', 'bacbc', 'baacaba', 'accbaa']
Train Epoch 0, Loss 0.47288817167282104
Train Epoch 1, Loss 0.3509633541107178
Train Epoch 2, Loss 0.33269327878952026
Accuracy at epoch 233: 0.767578125
['abbbcac', 'babbcb', 'baaba', 'bbabaab', 'ccabb', 'abbca', 'ccca', 'cccbbacc', 'ccbbcb', 'aaabca', 'bacbaa', 'bcbbac', 'aabbc', 'cbbac', 'ccbbcb', 'baabaccb']
Train Epoch 0, Loss 0.2410653531551361
Train Epoch 1, Loss 0.12154245376586914
Train Epoch 2, Loss 0.0601535439491272
Accuracy at epoch 234: 0.642578125
['abac', 'cacaacb', 'bbbbc', 'abcba', 'baacac', 'acacacca', 'acba', 'baaaaaac', 'abcca', 'acbcb', 'babbacac', 'accabacb', 'cbccabcb', 'abaaacc', 'caab', 'aaabbb']
Train Epoch 0, Loss 0.5409685969352722
Train Epoch 1, Loss 0.2997964322566986
Train Epoch 2, Loss 0.18083932995796204
Accuracy at epoch 235: 0.90234375
['cabb', 'cbac', 'bccbacba', 'ccbabab', 'abacac', 'baccba', 'cbbba', 'bbcb', 'bcac', 'abcaba', 'ccccaab', 'cabacb', 'cbaaabc', 'cbcbbccb', 'baba', 'cabcaab']
Train Epoch 0, Loss 0.07171118259429932
Train Epoch 1, Loss 0.06761283427476883
Train Epoch 2, Loss 0.040562573820352554
Accuracy at epoch 236: 0.9140625
['bacaab', 'caaacac', 'cbbcc', 'bbbbabc', 'abaaaaac', 'abaaba', 'bbaccabc', 'bcbbcb', 'cbaacab', 'cbbcaaca', 'caaba', 'aabbbbc', 'acccaa', 'accaaca', 'aaabcac', 'babbba']
Train Epoch 0, Loss 0.618015468120575
Train Epoch 1, Loss 0.4904783070087433
Train Epoch 2, Loss 0.43393591046333313
Accuracy at epoch 237: 0.849609375
['cbaa', 'acca', 'abbbba', 'cbbc', 'acccaac', 'bacccb', 'bbabbca', 'accbb', 'cbbc', 'cccab', 'aacaac', 'ccbc', 'bcbbc', 'caabbca', 'bcaabc', 'cacb']
Train Epoch 0, Loss 0.3859633505344391
Train Epoch 1, Loss 0.18753120303153992
Train Epoch 2, Loss 0.0820721834897995
Accuracy at epoch 238: 0.822265625
['ccababbb', 'cccbaacc', 'bcabc', 'bbcbab', 'bccbb', 'cbbc', 'bcccbba', 'abccbc', 'bccac', 'bbbaa', 'ababcc', 'cbca', 'cbccba', 'abaaba', 'baba', 'bccbcacc']
Train Epoch 0, Loss 0.0777880996465683
Train Epoch 1, Loss 0.045161984860897064
Train Epoch 2, Loss 0.031818028539419174
Accuracy at epoch 239: 0.865234375
['caabcbc', 'ccbcb', 'abbbaba', 'cbaac', 'aacbbc', 'ccca', 'abcaac', 'abaaba', 'bbcb', 'babbc', 'bababc', 'abcbc', 'aacabaaa', 'cabacaa', 'bcba', 'bbaba']
Train Epoch 0, Loss 0.6714599132537842
Train Epoch 1, Loss 0.5804115533828735
Train Epoch 2, Loss 0.4341396391391754
Accuracy at epoch 240: 0.884765625
['caaac', 'ccabcab', 'cabac', 'aacb', 'abab', 'aaba', 'accbab', 'aabcac', 'cbcacb', 'ccbabbcb', 'aacc', 'bbcbabbb', 'baccacac', 'abac', 'baaabb', 'ccaba']
Train Epoch 0, Loss 0.5900472402572632
Train Epoch 1, Loss 0.2916664481163025
Train Epoch 2, Loss 0.29010209441185
Accuracy at epoch 241: 0.908203125
['cbcab', 'ccababb', 'bbbacca', 'aabcbb', 'baccaca', 'abac', 'ccbbcab', 'baacac', 'ccbabb', 'ababbcac', 'acab', 'bcacccc', 'abaab', 'bccacc', 'baccbaac', 'accc']
Train Epoch 0, Loss 0.17153644561767578
Train Epoch 1, Loss 0.11362588405609131
Train Epoch 2, Loss 0.08399797230958939
Accuracy at epoch 242: 0.884765625
['abac', 'abcabac', 'ccaaab', 'cbbccbb', 'abcac', 'bacac', 'cacbc', 'baba', 'ccbcbcaa', 'babbcaba', 'bccc', 'bacbaba', 'cbaabaac', 'cbaabc', 'bbabbbc', 'aaba']
Train Epoch 0, Loss 0.4393005967140198
Train Epoch 1, Loss 0.31820055842399597
Train Epoch 2, Loss 0.27105608582496643
Accuracy at epoch 243: 0.76171875
['bacacaaa', 'ccbcbcc', 'babbc', 'babab', 'bcbcbc', 'cbbaca', 'acaca', 'baba', 'bccc', 'ccac', 'bcbbb', 'cbcca', 'bacbb', 'bacabccb', 'caaab', 'bcacaa']
Train Epoch 0, Loss 0.5651715993881226
Train Epoch 1, Loss 0.29008108377456665
Train Epoch 2, Loss 0.18032985925674438
Accuracy at epoch 244: 0.880859375
['abbbba', 'abaabca', 'ccaac', 'acabbc', 'aacbcacc', 'aacccca', 'baab', 'cacaabb', 'bcbaa', 'abbbccba', 'aabc', 'abbaabb', 'baccaac', 'aacbc', 'acabbc', 'baac']
Train Epoch 0, Loss 0.19801560044288635
Train Epoch 1, Loss 0.10537247359752655
Train Epoch 2, Loss 0.08332163840532303
Accuracy at epoch 245: 0.888671875
['baacbb', 'cacc', 'baac', 'cbbcb', 'ccbcba', 'aaccacab', 'abbbba', 'baacbaaa', 'cccaba', 'bbcc', 'babb', 'acbb', 'aaaaac', 'acbbc', 'bacaaba', 'abaccba']
Train Epoch 0, Loss 0.19269393384456635
Train Epoch 1, Loss 0.1290687471628189
Train Epoch 2, Loss 0.11692660301923752
Accuracy at epoch 246: 0.822265625
['bbcc', 'acacbaca', 'cacca', 'cbcc', 'baaacba', 'aabca', 'abcaaa', 'caccaa', 'caccac', 'caaca', 'baabb', 'accbccca', 'cbbba', 'bcccc', 'cbacabca', 'caab']
Train Epoch 0, Loss 0.12735296785831451
Train Epoch 1, Loss 0.05208505317568779
Train Epoch 2, Loss 0.02450978383421898
Accuracy at epoch 247: 0.705078125
['bccbbcbb', 'caba', 'baaabcab', 'cbaccc', 'abac', 'accba', 'abaac', 'bccaba', 'cabbaa', 'baaaac', 'acaaaabb', 'cabab', 'baaba', 'ccaaabaa', 'cacac', 'abcb']
Train Epoch 0, Loss 0.7392061352729797
Train Epoch 1, Loss 0.3784463703632355
Train Epoch 2, Loss 0.16567963361740112
Accuracy at epoch 248: 0.916015625
['baabc', 'bbabacbc', 'aaab', 'bccaba', 'cbbcbabc', 'cabc', 'abcbba', 'cbbbcab', 'cccbb', 'cabaccbb', 'abacacaa', 'abcbacbb', 'accaaac', 'baca', 'ccccbaa', 'bcacabcc']
Train Epoch 0, Loss 1.0271941423416138
Train Epoch 1, Loss 0.6866987347602844
Train Epoch 2, Loss 0.47652027010917664
Accuracy at epoch 249: 0.748046875
['ccaa', 'bbbca', 'ccaca', 'caaa', 'cbcac', 'accbbacb', 'babc', 'aabcbcc', 'aabaacca', 'bbbc', 'baaccbca', 'acccabb', 'acacacaa', 'acbbac', 'cccbbccc', 'cacbbbab']
Train Epoch 0, Loss 0.06288506835699081
Train Epoch 1, Loss 0.015031442977488041
Train Epoch 2, Loss 0.0068096378818154335
Accuracy at epoch 250: 0.568359375
['abaca', 'ccabbbc', 'bacba', 'abacba', 'baaaaba', 'cbcbbc', 'bbaaccb', 'cbbca', 'bbcbaab', 'cabc', 'bacaaaac', 'abcaaba', 'cbaccbaa', 'abaabbba', 'bcbcca', 'baab']
Train Epoch 0, Loss 1.7540255784988403
Train Epoch 1, Loss 0.8209238648414612
Train Epoch 2, Loss 0.2661532759666443
Accuracy at epoch 251: 0.8671875
['abac', 'abcaac', 'abaa', 'abaac', 'acaaa', 'aaab', 'acabcbbb', 'cacc', 'ccbcccba', 'baacc', 'acabc', 'abbbac', 'bbbcaabc', 'cacbabaa', 'accacc', 'cbbccb']
Train Epoch 0, Loss 0.4655389189720154
Train Epoch 1, Loss 0.2154298722743988
Train Epoch 2, Loss 0.20079270005226135
Accuracy at epoch 252: 0.89453125
['cabbbbab', 'baaacaba', 'aabccb', 'bababcaa', 'baac', 'aabbbb', 'baba', 'aaca', 'bbccabb', 'cccb', 'aaca', 'cbccaabc', 'abbbac', 'cbca', 'acbacca', 'cabbaac']
Train Epoch 0, Loss 0.16216233372688293
Train Epoch 1, Loss 0.10735515505075455
Train Epoch 2, Loss 0.10023560374975204
Accuracy at epoch 253: 0.890625
['acacba', 'abac', 'bcac', 'abba', 'aaacbb', 'bccc', 'babbbbc', 'bacba', 'acac', 'abaacac', 'ababbac', 'babbbcca', 'abcacbac', 'bcbcc', 'abaac', 'bcccabaa']
Train Epoch 0, Loss 0.48448675870895386
Train Epoch 1, Loss 0.34736889600753784
Train Epoch 2, Loss 0.2822730839252472
Accuracy at epoch 254: 0.90234375
['cbabbbc', 'bccc', 'cbbc', 'abaaaabc', 'cacb', 'abaacacb', 'aaabaca', 'ababa', 'babbaaac', 'abccb', 'cbaca', 'bbcabba', 'cacbacac', 'cbaba', 'ccbbaa', 'cbcabccb']
Train Epoch 0, Loss 0.3057512938976288
Train Epoch 1, Loss 0.22142982482910156
Train Epoch 2, Loss 0.21247540414333344
Accuracy at epoch 255: 0.9140625
['bbabb', 'abcccaba', 'abacaba', 'cabaa', 'baaa', 'ccabb', 'abccaba', 'bbaccbcc', 'cbccbaa', 'cacbbcb', 'bccc', 'abacc', 'bcbcbbb', 'abcaaba', 'abaac', 'bbabbc']
Train Epoch 0, Loss 0.6411327123641968
Train Epoch 1, Loss 0.3289426863193512
Train Epoch 2, Loss 0.29160502552986145
Accuracy at epoch 256: 0.9140625
['abcb', 'bbbba', 'caacbabc', 'bbcacb', 'cacbbb', 'abab', 'bcabba', 'abcbbac', 'babbaaba', 'cbccccab', 'cbbaac', 'ccabb', 'cbbaac', 'baabab', 'aabab', 'bcabc']
Train Epoch 0, Loss 0.29155370593070984
Train Epoch 1, Loss 0.1722436547279358
Train Epoch 2, Loss 0.08390658348798752
Accuracy at epoch 257: 0.89453125
['cacaaacc', 'caabcb', 'acbccaba', 'bcbaccbc', 'abccaaba', 'abcba', 'babbaba', 'bbabb', 'abaac', 'caacc', 'bcccac', 'bbaa', 'accbbcbb', 'ccccbab', 'abcbcbac', 'cbcabcc']
Train Epoch 0, Loss 0.06402049213647842
Train Epoch 1, Loss 0.08733169734477997
Train Epoch 2, Loss 0.04253809526562691
Accuracy at epoch 258: 0.8828125
['cacabaca', 'aacaac', 'abaccba', 'abcccb', 'caab', 'ccccbba', 'baccc', 'bbccaccb', 'cccca', 'abbcbcca', 'aabbaa', 'abcbbaac', 'bcacbba', 'aababaa', 'babbcba', 'baac']
Train Epoch 0, Loss 0.21928976476192474
Train Epoch 1, Loss 0.13837510347366333
Train Epoch 2, Loss 0.1097555086016655
Accuracy at epoch 259: 0.88671875
['abac', 'bcbbccca', 'bccaccab', 'cabcc', 'abcac', 'bbacb', 'aabba', 'acbc', 'ccbbb', 'caababab', 'bbaaa', 'bbaaabab', 'abbbcaac', 'aaaaac', 'acacabac', 'babc']
Train Epoch 0, Loss 0.4607734978199005
Train Epoch 1, Loss 0.2926631569862366
Train Epoch 2, Loss 0.2793637216091156
Accuracy at epoch 260: 0.91015625
['ababa', 'baaacac', 'bbbbbc', 'ccbc', 'abcaabcc', 'caac', 'acaa', 'abbbba', 'cbbabb', 'cbcb', 'aabaa', 'abaac', 'aabcc', 'abbbcc', 'abba', 'acabbca']
Train Epoch 0, Loss 0.2323882132768631
Train Epoch 1, Loss 0.17307166755199432
Train Epoch 2, Loss 0.11813946068286896
Accuracy at epoch 261: 0.765625
['baaa', 'abccac', 'aaabbba', 'ccbb', 'cbaa', 'cacbabaa', 'abcac', 'abac', 'abccaac', 'baccba', 'baaacaac', 'caac', 'caca', 'caba', 'acabcb', 'aaacab']
Train Epoch 0, Loss 1.592085838317871
Train Epoch 1, Loss 0.6428358554840088
Train Epoch 2, Loss 0.2729650139808655
Accuracy at epoch 262: 0.9296875
['aacaacb', 'caabaaac', 'baba', 'caaccacc', 'ccbcca', 'cacbbca', 'baacba', 'bcbbcbaa', 'abaac', 'bccca', 'cacccc', 'bcaca', 'cbaaaa', 'abcbacb', 'aacbabc', 'abcbbac']
Train Epoch 0, Loss 0.17595912516117096
Train Epoch 1, Loss 0.13569220900535583
Train Epoch 2, Loss 0.12151924520730972
Accuracy at epoch 263: 0.892578125
['abbbaaa', 'bbccab', 'baaacc', 'caacc', 'babbaba', 'accabbcb', 'abccca', 'bababa', 'acaa', 'ccbaaacc', 'acba', 'cabbc', 'abaaca', 'bcaaaba', 'babbcac', 'abac']
Train Epoch 0, Loss 0.271478533744812
Train Epoch 1, Loss 0.18023498356342316
Train Epoch 2, Loss 0.14803652465343475
Accuracy at epoch 264: 0.884765625
['bcabcbbc', 'caaacbcc', 'ccacaba', 'bcbcba', 'acbaaba', 'abacbbac', 'baaccba', 'caca', 'baccaba', 'abcaabaa', 'bbbb', 'abac', 'bbcca', 'abbbc', 'bcbb', 'bbac']
Train Epoch 0, Loss 0.7320693135261536
Train Epoch 1, Loss 0.1857820302248001
Train Epoch 2, Loss 0.19840767979621887
Accuracy at epoch 265: 0.90625
['bacac', 'aaccccc', 'cacbbc', 'baabbba', 'baaba', 'cbbccbc', 'cbcac', 'bccaba', 'ccaabaac', 'abcccaba', 'aacb', 'abac', 'baacac', 'abba', 'bacbccca', 'aacaa']
Train Epoch 0, Loss 0.15047086775302887
Train Epoch 1, Loss 0.08961262553930283
Train Epoch 2, Loss 0.05640220269560814
Accuracy at epoch 266: 0.9296875
['cbcbabca', 'ccbac', 'abcaaca', 'bcacb', 'cccbcbb', 'baacba', 'ababbabc', 'acbab', 'bacccaac', 'cbaaa', 'baaaba', 'aacbbac', 'babb', 'bccbba', 'abbaabcc', 'abcccaa']
Train Epoch 0, Loss 0.577806830406189
Train Epoch 1, Loss 0.7655531167984009
Train Epoch 2, Loss 0.39854103326797485
Accuracy at epoch 267: 0.90625
['abcbca', 'bbcaaaa', 'ababbac', 'abaaccba', 'accc', 'bbbacc', 'bacaacac', 'bbbb', 'aacacc', 'bbbbbbc', 'cacbcb', 'bcbabb', 'baccacac', 'bcacb', 'ccbcabb', 'babbacba']
Train Epoch 0, Loss 0.27875927090644836
Train Epoch 1, Loss 0.2096855491399765
Train Epoch 2, Loss 0.20451568067073822
Accuracy at epoch 268: 0.931640625
['abacc', 'ccacc', 'cbbba', 'bcabbcab', 'ccaaacc', 'ababcab', 'aacc', 'baac', 'bbccbc', 'acaa', 'bacacac', 'caac', 'ababa', 'bbcbcab', 'bacac', 'cbbabbb']
Train Epoch 0, Loss 0.21169443428516388
Train Epoch 1, Loss 0.07006057351827621
Train Epoch 2, Loss 0.04512186720967293
Accuracy at epoch 269: 0.884765625
['abbabcb', 'baaba', 'caab', 'abcb', 'baccaba', 'bccb', 'abccba', 'ccab', 'ccbab', 'caba', 'bccaaba', 'ccacc', 'bbbaac', 'abba', 'baba', 'acbcc']
Train Epoch 0, Loss 0.6500871181488037
Train Epoch 1, Loss 0.20928074419498444
Train Epoch 2, Loss 0.16229379177093506
Accuracy at epoch 270: 0.931640625
['aabcbaab', 'bacccba', 'baacaba', 'aaaca', 'bbbccbc', 'baabcb', 'cabc', 'bcbabcc', 'cbacaaac', 'accbbabc', 'bccbaba', 'babbbabb', 'aabbb', 'cbcbacaa', 'ccabaa', 'bacaac']
Train Epoch 0, Loss 0.20896460115909576
Train Epoch 1, Loss 0.17784316837787628
Train Epoch 2, Loss 0.1502666175365448
Accuracy at epoch 271: 0.91796875
['aabccc', 'abbcbaca', 'aaabcb', 'cbcaaabc', 'acbccc', 'cbacaac', 'cbabaa', 'baba', 'cbcaccbb', 'abacaba', 'caabccc', 'cbbbbb', 'baba', 'baccbaa', 'bcaac', 'bbbbacab']
Train Epoch 0, Loss 0.10372719168663025
Train Epoch 1, Loss 0.047888707369565964
Train Epoch 2, Loss 0.030588410794734955
Accuracy at epoch 272: 0.92578125
['ccabba', 'ccbbbaca', 'acabba', 'bbccbc', 'babcca', 'aaabcbb', 'baabbac', 'caabaaaa', 'abbbaba', 'bcbb', 'abaaaaba', 'abcbbaac', 'babbcaac', 'ccaaaa', 'bacb', 'bbbc']
Train Epoch 0, Loss 0.07659955322742462
Train Epoch 1, Loss 0.024860352277755737
Train Epoch 2, Loss 0.01334124244749546
Accuracy at epoch 273: 0.7890625
['acccbb', 'baaba', 'bbbb', 'ccbabb', 'baaabc', 'baaac', 'abcccaba', 'ccbbba', 'abbcbcb', 'cbba', 'cccbaaba', 'bbcbab', 'babcb', 'abacba', 'caaabcc', 'cbac']
Train Epoch 0, Loss 0.8192184567451477
Train Epoch 1, Loss 0.6622970700263977
Train Epoch 2, Loss 0.49386149644851685
Accuracy at epoch 274: 0.9140625
['babaab', 'bbcacab', 'bbabbcb', 'bbccc', 'aaaabab', 'cbaaabbb', 'acbac', 'abcbcbc', 'caabaaa', 'ababaab', 'bbcaaca', 'cbbab', 'bbacbbab', 'bcacccb', 'bbbcccba', 'cbaaa']
Train Epoch 0, Loss 0.41576895117759705
Train Epoch 1, Loss 0.09684831649065018
Train Epoch 2, Loss 0.010023701936006546
Accuracy at epoch 275: 0.6953125
['cbbcb', 'bcacbc', 'acaccc', 'bacaab', 'abcaccac', 'caaca', 'accbcb', 'caabc', 'abba', 'bcaccab', 'abaacac', 'baaabcca', 'bbaaabb', 'cccabbb', 'baaccaac', 'bbbbbaac']
Train Epoch 0, Loss 0.8326012492179871
Train Epoch 1, Loss 0.13422414660453796
Train Epoch 2, Loss 0.0919167697429657
Accuracy at epoch 276: 0.869140625
['cabac', 'bcbbcc', 'accccb', 'ccccaac', 'acbb', 'caabcb', 'bbbbc', 'cabbcc', 'bbbc', 'bbbbbb', 'bcaac', 'abbbcaba', 'baaba', 'bccaabb', 'abba', 'aabb']
Train Epoch 0, Loss 0.07745824009180069
Train Epoch 1, Loss 0.030885927379131317
Train Epoch 2, Loss 0.018717283383011818
Accuracy at epoch 277: 0.783203125
['aabacc', 'baca', 'baaba', 'bbaccabb', 'cccabbc', 'ccbbab', 'baaba', 'cbaca', 'bbbacbb', 'cbaaacca', 'cacacb', 'baacaab', 'babacb', 'aacab', 'caabbbc', 'ccaba']
Train Epoch 0, Loss 0.011531660333275795
Train Epoch 1, Loss 0.013552742078900337
Train Epoch 2, Loss 0.007119716145098209
Accuracy at epoch 278: 0.78125
['acbbbab', 'acbacbc', 'accbbac', 'baaba', 'baba', 'baaaabb', 'bacbbac', 'babbaba', 'babcbb', 'ccbcbca', 'bacab', 'ccaab', 'babbabbc', 'cbab', 'acaabc', 'baabcb']
Train Epoch 0, Loss 0.948923647403717
Train Epoch 1, Loss 1.0584120750427246
Train Epoch 2, Loss 0.7229170799255371
Accuracy at epoch 279: 0.845703125
['caaac', 'ccabb', 'abacac', 'aabaaa', 'cbcaaa', 'cacbca', 'bacbbaac', 'caccabc', 'abaaccac', 'abbbbbba', 'cbba', 'cabbcbaa', 'abcaba', 'bcaac', 'bbcccb', 'bacac']
Train Epoch 0, Loss 0.4049547016620636
Train Epoch 1, Loss 0.1958272010087967
Train Epoch 2, Loss 0.06034679710865021
Accuracy at epoch 280: 0.85546875
['acbabbb', 'accabcba', 'cbcbbba', 'cbcccba', 'aacca', 'ababbaba', 'bacaaaa', 'ccaa', 'abac', 'abcbbba', 'bbabb', 'cabb', 'bccbc', 'cbaabacb', 'abaaccba', 'acccc']
Train Epoch 0, Loss 0.2942364811897278
Train Epoch 1, Loss 0.15366749465465546
Train Epoch 2, Loss 0.11134939640760422
Accuracy at epoch 281: 0.88671875
['ccaaaaac', 'baabcc', 'acbbbc', 'abbbac', 'bbab', 'aaaacaba', 'abcbcca', 'cacbbb', 'baaacbb', 'cabaa', 'abbbac', 'cbbaccab', 'baabbcba', 'baab', 'acbcba', 'abbbac']
Train Epoch 0, Loss 0.22733163833618164
Train Epoch 1, Loss 0.16031381487846375
Train Epoch 2, Loss 0.09280925989151001
Accuracy at epoch 282: 0.771484375
['baac', 'bacba', 'cbacacb', 'ababa', 'abbab', 'aabb', 'baaca', 'bbabcaa', 'acaaa', 'bbaaaba', 'bccbcbbc', 'cbbccbb', 'ababbba', 'aacab', 'abaacba', 'cbacbcaa']
Train Epoch 0, Loss 0.46585121750831604
Train Epoch 1, Loss 0.3781486749649048
Train Epoch 2, Loss 0.31071770191192627
Accuracy at epoch 283: 0.83984375
['baaba', 'abcacc', 'cbabb', 'abab', 'ccabcca', 'cbccc', 'baaaaaa', 'abbacba', 'cacc', 'abbac', 'cccacbac', 'bbbbbbcc', 'caacccbc', 'abbbacba', 'baac', 'baacac']
Train Epoch 0, Loss 0.42054483294487
Train Epoch 1, Loss 0.3341342806816101
Train Epoch 2, Loss 0.2973237633705139
Accuracy at epoch 284: 0.90625
['bacac', 'cccb', 'cacbcbcb', 'cbab', 'abcba', 'bbcbc', 'acacbac', 'caab', 'abab', 'acbbbac', 'cacbc', 'bcab', 'abac', 'baba', 'abccbbba', 'cabbbc']
Train Epoch 0, Loss 0.09332127124071121
Train Epoch 1, Loss 0.07022248953580856
Train Epoch 2, Loss 0.04827655479311943
Accuracy at epoch 285: 0.91796875
['abcba', 'abaa', 'cabc', 'abba', 'abca', 'caac', 'abcaaa', 'bcbb', 'cacbbc', 'abbcbb', 'bbaaa', 'babac', 'bcbbbac', 'bbacabcb', 'bbcacbac', 'cbacabca']
Train Epoch 0, Loss 0.23638732731342316
Train Epoch 1, Loss 0.11677075922489166
Train Epoch 2, Loss 0.10633150488138199
Accuracy at epoch 286: 0.85546875
['acaabac', 'cbbc', 'bbcabcc', 'babbac', 'bbacccb', 'abbbac', 'aabcacac', 'baaac', 'cbcab', 'baaacbaa', 'baaba', 'baaaaa', 'abaaac', 'bbaaa', 'bcbb', 'cccbaab']
Train Epoch 0, Loss 0.438896507024765
Train Epoch 1, Loss 0.25983530282974243
Train Epoch 2, Loss 0.2764754295349121
Accuracy at epoch 287: 0.90625
['cbabb', 'acccaa', 'cabcca', 'baaba', 'babbccab', 'ccbcbcb', 'baaaabba', 'bacaba', 'ccbab', 'bcabc', 'cabcbac', 'aabbacab', 'baac', 'babacaa', 'acaba', 'abaab']
Train Epoch 0, Loss 0.2822161316871643
Train Epoch 1, Loss 0.19053514301776886
Train Epoch 2, Loss 0.1303010731935501
Accuracy at epoch 288: 0.900390625
['cabbba', 'baccac', 'cacc', 'aaba', 'baacba', 'abcac', 'cabaaca', 'ababa', 'baccac', 'aaabbcbb', 'cbcb', 'acca', 'bbabcca', 'baccba', 'bacbbac', 'acaac']
Train Epoch 0, Loss 0.21667037904262543
Train Epoch 1, Loss 0.16074687242507935
Train Epoch 2, Loss 0.11978942900896072
Accuracy at epoch 289: 0.7890625
['caacacc', 'abcaaa', 'abac', 'abaaaaba', 'ccbcacbc', 'abcb', 'ccbabb', 'abaab', 'cbabbcbb', 'accaabb', 'abba', 'accaabb', 'abbbccc', 'baaacaba', 'bcab', 'acabc']
Train Epoch 0, Loss 0.7498037815093994
Train Epoch 1, Loss 0.4018515348434448
Train Epoch 2, Loss 0.21385249495506287
Accuracy at epoch 290: 0.89453125
['abcba', 'baaacaac', 'abbcb', 'abaccbb', 'abccaac', 'abccbc', 'abbcaba', 'babcab', 'aacac', 'abaaaac', 'ccacc', 'abaccba', 'abaccba', 'aabaaab', 'abcac', 'baac']
Train Epoch 0, Loss 0.4643157124519348
Train Epoch 1, Loss 0.2973479628562927
Train Epoch 2, Loss 0.18759015202522278
Accuracy at epoch 291: 0.7890625
['ccbbcaaa', 'cabccba', 'ccba', 'bbaca', 'acacaab', 'aaaacbaa', 'cbba', 'aabb', 'aaacaba', 'abcaaac', 'babb', 'acbcbbb', 'bbabca', 'abccba', 'ababbba', 'cabb']
Train Epoch 0, Loss 0.2959984540939331
Train Epoch 1, Loss 0.10484900325536728
Train Epoch 2, Loss 0.07616596668958664
Accuracy at epoch 292: 0.900390625
['bbcbcccb', 'accccacc', 'abba', 'bcbcbbc', 'bcbb', 'baaaba', 'cbabaac', 'cacacc', 'cbbccc', 'bcbbcb', 'cbba', 'ababa', 'bcbcbb', 'abcbbcba', 'bcbac', 'abaaa']
Train Epoch 0, Loss 0.19114722311496735
Train Epoch 1, Loss 0.09512309730052948
Train Epoch 2, Loss 0.05829978361725807
Accuracy at epoch 293: 0.8828125
['aacac', 'bbabb', 'ccaab', 'aaabcbb', 'ccabb', 'bacacac', 'accacc', 'ababa', 'accb', 'baaccba', 'bcbbc', 'ccbccb', 'aabb', 'abbbb', 'babbaba', 'accbb']
Train Epoch 0, Loss 0.2147950679063797
Train Epoch 1, Loss 0.12169322371482849
Train Epoch 2, Loss 0.10398121178150177
Accuracy at epoch 294: 0.896484375
['abac', 'caabaaba', 'baaaac', 'cccbbc', 'abccaaac', 'caacc', 'baabcaac', 'aabccbcc', 'caaaac', 'aacacabc', 'babbba', 'baacba', 'acbc', 'abbbacba', 'acbba', 'cbccabb']
Train Epoch 0, Loss 0.28769826889038086
Train Epoch 1, Loss 0.16205137968063354
Train Epoch 2, Loss 0.10674985498189926
Accuracy at epoch 295: 0.87890625
['bcaababa', 'abacac', 'abcbcbac', 'bbbcb', 'bcaacaa', 'cbcc', 'bacacaac', 'abccbbca', 'ababb', 'baaac', 'aacbcacb', 'caaaca', 'acbc', 'bbaccaca', 'abcaac', 'bacbb']
Train Epoch 0, Loss 0.8710103631019592
Train Epoch 1, Loss 0.4654063284397125
Train Epoch 2, Loss 0.21484987437725067
Accuracy at epoch 296: 0.8984375
['bbbcb', 'baaaba', 'bcca', 'acac', 'aabac', 'bccac', 'cbbacb', 'acababb', 'babbaba', 'ccccbcb', 'bcacaa', 'bbaccb', 'bacac', 'baccac', 'babbc', 'abaacb']
Train Epoch 0, Loss 0.30505505204200745
Train Epoch 1, Loss 0.1904992312192917
Train Epoch 2, Loss 0.1412191540002823
Accuracy at epoch 297: 0.876953125
['babab', 'cacbabc', 'ccbaca', 'abac', 'abbbcb', 'bacaccac', 'ccacc', 'aaccbaab', 'bbaabbc', 'babb', 'abcbbac', 'aaca', 'ccaccaa', 'ccca', 'bcaaba', 'bcabbb']
Train Epoch 0, Loss 0.3386057913303375
Train Epoch 1, Loss 0.14913378655910492
Train Epoch 2, Loss 0.0886639654636383
Accuracy at epoch 298: 0.908203125
['baacaac', 'baaccac', 'babbaac', 'cbaabca', 'bacba', 'aaab', 'bcbbb', 'accccca', 'baac', 'babac', 'abbb', 'cbabaa', 'cbcacb', 'bacbbba', 'bacaca', 'ccaa']
Train Epoch 0, Loss 0.3766305446624756
Train Epoch 1, Loss 0.0939868688583374
Train Epoch 2, Loss 0.08133722841739655
Accuracy at epoch 299: 0.904296875
